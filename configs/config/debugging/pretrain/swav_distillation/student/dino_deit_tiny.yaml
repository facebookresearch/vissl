# @package _global_
config:
  MODEL:
    TRUNK:
      NAME: vision_transformer
      VISION_TRANSFORMERS:
        IMAGE_SIZE: 224
        PATCH_SIZE: 16
        NUM_LAYERS: 12
        NUM_HEADS: 3
        HIDDEN_DIM: 192
        MLP_DIM: 768
        CLASSIFIER: token
        DROPOUT_RATE: 0
        ATTENTION_DROPOUT_RATE: 0
        QKV_BIAS: True
        DROP_PATH_RATE: 0.1 # stochastic depth dropout probability
        QK_SCALE: False
    HEAD:
      PARAMS: [
        ["dino_head", {
          "in_dim": 192,
          "num_clusters": [65536],
          "normalize_last_layer": false,
        }],
      ]
