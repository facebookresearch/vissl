{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/facebookresearch/vissl/blob/v0.1.6/tutorials/Benchmark_Linear_Image_Classification_on_ImageNet_1K_V0_1_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL8iG7SJ7Hrk"
      },
      "outputs": [],
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates. All rights reserved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XzxTZfKwFNo"
      },
      "source": [
        "# Benchmark Linear Image Classification on ImageNet-1K\n",
        "\n",
        "In this tutorial, we look at a simple example of how to use VISSL to run a linear image classification benchmark for [ResNet-50 Torchvision pre-trained model](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L16). This benchmark freezes the model trunk and attaches a linear head on top of the trunk features.\n",
        "\n",
        "You can make a copy of this tutorial by `File -> Open in playground mode` and make changes there. Please do NOT request access to this tutorial.\n",
        "\n",
        "**NOTE:** Please ensure your Collab Notebook has a GPU available. To ensure this, simply follow: `Edit -> Notebook Settings -> select GPU.`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VohdWhBSw69e"
      },
      "source": [
        "## Install VISSL\n",
        "\n",
        "Installing VISSL is straightfoward. We will install VISSL from source using pip, following the instructions from [here](https://github.com/facebookresearch/vissl/blob/master/INSTALL.md#install-vissl-pip-package). Note, you can also install VISSL in a conda environment or from our conda/pip binaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5ISg59KTOqU"
      },
      "outputs": [],
      "source": [
        "# Install pytorch version 1.8\n",
        "!pip install torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install Apex by checking system settings: cuda version, pytorch version, and python version\n",
        "import sys\n",
        "import torch\n",
        "version_str=\"\".join([\n",
        "    f\"py3{sys.version_info.minor}_cu\",\n",
        "    torch.version.cuda.replace(\".\",\"\"),\n",
        "    f\"_pyt{torch.__version__[0:5:2]}\"\n",
        "])\n",
        "print(version_str)\n",
        "\n",
        "# install apex (pre-compiled with optimizer C++ extensions and CUDA kernels)\n",
        "!pip install apex -f https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/{version_str}/download.html\n",
        "\n",
        "# # clone vissl repository and checkout latest version.\n",
        "!git clone --recursive https://github.com/facebookresearch/vissl.git\n",
        "\n",
        "%cd vissl/\n",
        "\n",
        "!git checkout v0.1.6\n",
        "!git checkout -b v0.1.6\n",
        "\n",
        "# install vissl dependencies\n",
        "!pip install --progress-bar off -r requirements.txt\n",
        "!pip install opencv-python\n",
        "\n",
        "# update classy vision install to commit compatible with v0.1.6\n",
        "!pip uninstall -y classy_vision\n",
        "!pip install classy-vision@https://github.com/facebookresearch/ClassyVision/tarball/4785d5ee19d3bcedd5b28c1eb51ea1f59188b54d\n",
        "\n",
        "# Update fairscale to commit compatible with v0.1.6\n",
        "!pip uninstall -y fairscale\n",
        "!pip install fairscale@https://github.com/facebookresearch/fairscale/tarball/df7db85cef7f9c30a5b821007754b96eb1f977b6\n",
        "\n",
        "# install vissl dev mode (e stands for editable)\n",
        "!pip install -e .[dev]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Fxe3MWxqsI"
      },
      "source": [
        "VISSL should be successfuly installed by now and all the dependencies should be available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np6atgoOTPrA"
      },
      "outputs": [],
      "source": [
        "import vissl\n",
        "import tensorboard\n",
        "import apex\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxMXLYLpsJXj"
      },
      "source": [
        "## Download the ResNet-50 weights from Torchvision\n",
        "\n",
        "We download the weights from the [torchvision ResNet50 model](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L16):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mv0quZwFsWxs"
      },
      "outputs": [],
      "source": [
        "!wget https://download.pytorch.org/models/resnet50-19c8e357.pth -P /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0hng2EPY7pr"
      },
      "source": [
        "## Creating a custom data\n",
        "\n",
        "For the purpose of this tutorial, since we don't have ImageNet on the disk, we will create a dummy dataset by copying an image from COCO dataset in ImageNet dataset folder style as below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-sy6nD-RfwB"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/dummy_data/train/class1\n",
        "!mkdir -p /content/dummy_data/train/class2\n",
        "!mkdir -p /content/dummy_data/val/class1\n",
        "!mkdir -p /content/dummy_data/val/class2\n",
        "\n",
        "# create 2 classes in train and add 5 images per class\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img5.jpg\n",
        "\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img5.jpg\n",
        "\n",
        "# create 2 classes in val and add 5 images per class\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img5.jpg\n",
        "\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img5.jpg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPGCiTsXZeW3"
      },
      "source": [
        "## Using the custom data in VISSL\n",
        "\n",
        "Next step for us is to register the dummy data we created above with VISSL. Registering the dataset involves telling VISSL about the dataset name and the paths for the dataset. For this, we create a simple json file with the metadata and save it to `configs/config/dataset_catalog.py` file.\n",
        "\n",
        "**NOTE**: VISSL uses the specific `dataset_catalog.json` under the path `configs/config/dataset_catalog.json`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Q6LCqaWjl1"
      },
      "outputs": [],
      "source": [
        "json_data = {\n",
        "    \"dummy_data_folder\": {\n",
        "      \"train\": [\n",
        "        \"/content/dummy_data/train\", \"/content/dummy_data/train\"\n",
        "      ],\n",
        "      \"val\": [\n",
        "        \"/content/dummy_data/val\", \"/content/dummy_data/val\"\n",
        "      ]\n",
        "    }\n",
        "}\n",
        "\n",
        "# use VISSL's api to save or you can use your custom code.\n",
        "from vissl.utils.io import save_file\n",
        "save_file(json_data, \"/content/vissl/configs/config/dataset_catalog.json\", append_to_json=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otN1pB32cBHK"
      },
      "source": [
        "Next, we verify that the dataset is registered with VISSL. For that we query VISSL's dataset catalog as below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZBhH-s5bcHd",
        "outputId": "0b6b40da-9751-43ec-9766-6e78a1619e35"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:fvcore.common.file_io:** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['dummy_data_folder']\n",
            "{'train': ['/content/dummy_data/train', '/content/dummy_data/train'], 'val': ['/content/dummy_data/val', '/content/dummy_data/val']}\n"
          ]
        }
      ],
      "source": [
        "from vissl.data.dataset_catalog import VisslDatasetCatalog\n",
        "\n",
        "# list all the datasets that exist in catalog\n",
        "print(VisslDatasetCatalog.list())\n",
        "\n",
        "# get the metadata of dummy_data_folder dataset\n",
        "print(VisslDatasetCatalog.get(\"dummy_data_folder\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaUMDwMdzYHN"
      },
      "source": [
        "## Training linear classifier on trunk output\n",
        "\n",
        "VISSL provides yaml configuration files for all benchmark tasks including linear image classification on ImageNet [here](https://github.com/facebookresearch/vissl/tree/master/configs/config/benchmark). \n",
        "\n",
        "\n",
        "VISSL provides yaml configuration files that reproduces training of all self-supervised approaches [here](https://github.com/facebookresearch/vissl/tree/master/configs/config/pretrain). For the purpose of this tutorial, we will use the config file for training SimCLR approach on 1-gpu.\n",
        "\n",
        "VISSL provides a [helper python tool](https://github.com/facebookresearch/vissl/blob/main/tools/run_distributed_engines.py) that allows you to train models based on our configuration system. This tool allows:\n",
        "- training and feature extraction.\n",
        "- training on 1-gpu, multi-gpu, or even multi-machine using Pytorch DDP or Fairscale FSDP.\n",
        "- allows training and feature extraction both using VISSL. \n",
        "- also allows training on 1-gpu or multi-gpu. \n",
        "- can be used to launch multi-machine distributed training.\n",
        "\n",
        "We are ready to train the linear classifier now. For the purpose of this tutorial, we will use synthetic dataset and train on dummy images. VISSL supports training on wide range of datasets and allows adding custom datasets. Please see VISSL documentation on how to use the datasets. To train on ImageNet instead: assuming your ImageNet dataset folder path is `/path/to/my/imagenet/folder/`, you can add the following command line \n",
        "input to your training command: \n",
        "```\n",
        "config.DATA.TRAIN.DATASET_NAMES=[imagenet1k_folder] \\\n",
        "config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "config.DATA.TRAIN.DATA_PATHS=[\"/path/to/my/imagenet/folder/train\"] \\\n",
        "config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM7IigSpONW0"
      },
      "source": [
        "The training command looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v0HvauIj9S2",
        "outputId": "8ea324ad-9c7b-45d2-81d8-339f6efe2a00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "####### overrides: ['hydra.verbose=true', 'config=test/integration_test/quick_eval_in1k_linear_imagefolder_head.yaml', 'config.DATA.TRAIN.DATA_SOURCES=[disk_folder]', 'config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]', 'config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2', 'config.DATA.TRAIN.DATA_LIMIT=-1', 'config.DATA.TEST.DATA_SOURCES=[disk_folder]', 'config.DATA.TEST.LABEL_SOURCES=[disk_folder]', 'config.DATA.TEST.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TEST.BATCHSIZE_PER_REPLICA=2', 'config.DATA.TEST.DATA_LIMIT=-1', 'config.DISTRIBUTED.NUM_NODES=1', 'config.DISTRIBUTED.NUM_PROC_PER_NODE=1', 'config.CHECKPOINT.DIR=/content/checkpoints', 'config.MODEL.WEIGHTS_INIT.PARAMS_FILE=/content/resnet50-19c8e357.pth', 'config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=trunk._feature_blocks.', 'config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=', 'hydra.verbose=true']\n",
            "INFO 2021-10-18 00:36:58,691 distributed_launcher.py: 184: Spawning process for node_id: 0, local_rank: 0, dist_rank: 0, dist_run_id: localhost:60789\n",
            "INFO 2021-10-18 00:36:58,692 train.py:  94: Env set for rank: 0, dist_rank: 0\n",
            "INFO 2021-10-18 00:36:58,692 env.py:  50: CLICOLOR:\t1\n",
            "INFO 2021-10-18 00:36:58,692 env.py:  50: CLOUDSDK_CONFIG:\t/content/.config\n",
            "INFO 2021-10-18 00:36:58,692 env.py:  50: CLOUDSDK_PYTHON:\tpython3\n",
            "INFO 2021-10-18 00:36:58,692 env.py:  50: COLAB_GPU:\t1\n",
            "INFO 2021-10-18 00:36:58,692 env.py:  50: CUDA_VERSION:\t11.1.1\n",
            "INFO 2021-10-18 00:36:58,693 env.py:  50: CUDNN_VERSION:\t8.0.5.39\n",
            "INFO 2021-10-18 00:36:58,693 env.py:  50: DATALAB_SETTINGS_OVERRIDES:\t{\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=\\\"172.28.0.2\\\"\"],\"debugAdapterMultiplexerPath\":\"/usr/local/bin/dap_multiplexer\",\"enableLsp\":true}\n",
            "INFO 2021-10-18 00:36:58,693 env.py:  50: DEBIAN_FRONTEND:\tnoninteractive\n",
            "INFO 2021-10-18 00:36:58,693 env.py:  50: ENV:\t/root/.bashrc\n",
            "INFO 2021-10-18 00:36:58,693 env.py:  50: GCE_METADATA_TIMEOUT:\t0\n",
            "INFO 2021-10-18 00:36:58,693 env.py:  50: GCS_READ_CACHE_BLOCK_SIZE_MB:\t16\n",
            "INFO 2021-10-18 00:36:58,693 env.py:  50: GIT_PAGER:\tcat\n",
            "INFO 2021-10-18 00:36:58,694 env.py:  50: GLIBCPP_FORCE_NEW:\t1\n",
            "INFO 2021-10-18 00:36:58,694 env.py:  50: GLIBCXX_FORCE_NEW:\t1\n",
            "INFO 2021-10-18 00:36:58,694 env.py:  50: HOME:\t/root\n",
            "INFO 2021-10-18 00:36:58,694 env.py:  50: HOSTNAME:\t3df825104503\n",
            "INFO 2021-10-18 00:36:58,694 env.py:  50: JPY_PARENT_PID:\t67\n",
            "INFO 2021-10-18 00:36:58,694 env.py:  50: LANG:\ten_US.UTF-8\n",
            "INFO 2021-10-18 00:36:58,694 env.py:  50: LAST_FORCED_REBUILD:\t20211007\n",
            "INFO 2021-10-18 00:36:58,694 env.py:  50: LD_LIBRARY_PATH:\t/usr/lib64-nvidia\n",
            "INFO 2021-10-18 00:36:58,695 env.py:  50: LD_PRELOAD:\t/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4\n",
            "INFO 2021-10-18 00:36:58,695 env.py:  50: LIBRARY_PATH:\t/usr/local/cuda/lib64/stubs\n",
            "INFO 2021-10-18 00:36:58,695 env.py:  50: LOCAL_RANK:\t0\n",
            "INFO 2021-10-18 00:36:58,695 env.py:  50: MPLBACKEND:\tmodule://ipykernel.pylab.backend_inline\n",
            "INFO 2021-10-18 00:36:58,695 env.py:  50: NCCL_VERSION:\t2.7.8\n",
            "INFO 2021-10-18 00:36:58,695 env.py:  50: NO_GCE_CHECK:\tTrue\n",
            "INFO 2021-10-18 00:36:58,695 env.py:  50: NVIDIA_DRIVER_CAPABILITIES:\tcompute,utility\n",
            "INFO 2021-10-18 00:36:58,695 env.py:  50: NVIDIA_REQUIRE_CUDA:\tcuda>=11.1 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 brand=tesla,driver>=450,driver<451\n",
            "INFO 2021-10-18 00:36:58,696 env.py:  50: NVIDIA_VISIBLE_DEVICES:\tall\n",
            "INFO 2021-10-18 00:36:58,696 env.py:  50: OLDPWD:\t/\n",
            "INFO 2021-10-18 00:36:58,696 env.py:  50: PAGER:\tcat\n",
            "INFO 2021-10-18 00:36:58,696 env.py:  50: PATH:\t/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n",
            "INFO 2021-10-18 00:36:58,696 env.py:  50: PWD:\t/content/vissl\n",
            "INFO 2021-10-18 00:36:58,696 env.py:  50: PYDEVD_USE_FRAME_EVAL:\tNO\n",
            "INFO 2021-10-18 00:36:58,696 env.py:  50: PYTHONPATH:\t/env/python\n",
            "INFO 2021-10-18 00:36:58,696 env.py:  50: PYTHONWARNINGS:\tignore:::pip._internal.cli.base_command\n",
            "INFO 2021-10-18 00:36:58,697 env.py:  50: RANK:\t0\n",
            "INFO 2021-10-18 00:36:58,697 env.py:  50: SHELL:\t/bin/bash\n",
            "INFO 2021-10-18 00:36:58,697 env.py:  50: SHLVL:\t1\n",
            "INFO 2021-10-18 00:36:58,697 env.py:  50: TBE_CREDS_ADDR:\t172.28.0.1:8008\n",
            "INFO 2021-10-18 00:36:58,697 env.py:  50: TERM:\txterm-color\n",
            "INFO 2021-10-18 00:36:58,697 env.py:  50: TF_FORCE_GPU_ALLOW_GROWTH:\ttrue\n",
            "INFO 2021-10-18 00:36:58,697 env.py:  50: WORLD_SIZE:\t1\n",
            "INFO 2021-10-18 00:36:58,697 env.py:  50: _:\t/usr/bin/python3\n",
            "INFO 2021-10-18 00:36:58,698 env.py:  50: __EGL_VENDOR_LIBRARY_DIRS:\t/usr/lib64-nvidia:/usr/share/glvnd/egl_vendor.d/\n",
            "INFO 2021-10-18 00:36:58,698 misc.py: 161: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-10-18 00:36:58,698 train.py: 105: Setting seed....\n",
            "INFO 2021-10-18 00:36:58,698 misc.py: 173: MACHINE SEED: 2\n",
            "INFO 2021-10-18 00:36:58,699 hydra_config.py: 131: Training with config:\n",
            "INFO 2021-10-18 00:36:58,708 hydra_config.py: 140: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,\n",
            "                'AUTO_RESUME': True,\n",
            "                'BACKEND': 'disk',\n",
            "                'CHECKPOINT_FREQUENCY': 2,\n",
            "                'CHECKPOINT_ITER_FREQUENCY': -1,\n",
            "                'DIR': '/content/checkpoints',\n",
            "                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,\n",
            "                'OVERWRITE_EXISTING': True,\n",
            "                'USE_SYMLINK_CHECKPOINT_FOR_RESUME': False},\n",
            " 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',\n",
            "                'DATA_LIMIT': -1,\n",
            "                'DATA_LIMIT_SAMPLING': {'SEED': 0},\n",
            "                'FEATURES': {'DATASET_NAME': '',\n",
            "                             'DATA_PARTITION': 'TRAIN',\n",
            "                             'DIMENSIONALITY_REDUCTION': 0,\n",
            "                             'EXTRACT': False,\n",
            "                             'LAYER_NAME': '',\n",
            "                             'PATH': '.',\n",
            "                             'TEST_PARTITION': 'TEST'},\n",
            "                'NUM_CLUSTERS': 16000,\n",
            "                'NUM_ITER': 50,\n",
            "                'OUTPUT_DIR': '.'},\n",
            " 'DATA': {'DDP_BUCKET_CAP_MB': 25,\n",
            "          'ENABLE_ASYNC_GPU_COPY': True,\n",
            "          'NUM_DATALOADER_WORKERS': 2,\n",
            "          'PIN_MEMORY': True,\n",
            "          'TEST': {'BASE_DATASET': 'generic_ssl',\n",
            "                   'BATCHSIZE_PER_REPLICA': 2,\n",
            "                   'COLLATE_FUNCTION': 'default_collate',\n",
            "                   'COLLATE_FUNCTION_PARAMS': {},\n",
            "                   'COPY_DESTINATION_DIR': '',\n",
            "                   'COPY_TO_LOCAL_DISK': False,\n",
            "                   'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                   'DATA_LIMIT': -1,\n",
            "                   'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,\n",
            "                                           'SEED': 0,\n",
            "                                           'SKIP_NUM_SAMPLES': 0},\n",
            "                   'DATA_PATHS': [],\n",
            "                   'DATA_SOURCES': ['disk_folder'],\n",
            "                   'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                   'DROP_LAST': False,\n",
            "                   'ENABLE_QUEUE_DATASET': False,\n",
            "                   'INPUT_KEY_NAMES': ['data'],\n",
            "                   'LABEL_PATHS': [],\n",
            "                   'LABEL_SOURCES': ['disk_folder'],\n",
            "                   'LABEL_TYPE': 'standard',\n",
            "                   'MMAP_MODE': True,\n",
            "                   'NEW_IMG_PATH_PREFIX': '',\n",
            "                   'RANDOM_SYNTHETIC_IMAGES': False,\n",
            "                   'REMOVE_IMG_PATH_PREFIX': '',\n",
            "                   'TARGET_KEY_NAMES': ['label'],\n",
            "                   'TRANSFORMS': [{'name': 'Resize', 'size': 256},\n",
            "                                  {'name': 'CenterCrop', 'size': 224},\n",
            "                                  {'name': 'ToTensor'},\n",
            "                                  {'mean': [0.485, 0.456, 0.406],\n",
            "                                   'name': 'Normalize',\n",
            "                                   'std': [0.229, 0.224, 0.225]}],\n",
            "                   'USE_DEBUGGING_SAMPLER': False,\n",
            "                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},\n",
            "          'TRAIN': {'BASE_DATASET': 'generic_ssl',\n",
            "                    'BATCHSIZE_PER_REPLICA': 2,\n",
            "                    'COLLATE_FUNCTION': 'default_collate',\n",
            "                    'COLLATE_FUNCTION_PARAMS': {},\n",
            "                    'COPY_DESTINATION_DIR': '',\n",
            "                    'COPY_TO_LOCAL_DISK': False,\n",
            "                    'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                    'DATA_LIMIT': -1,\n",
            "                    'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,\n",
            "                                            'SEED': 0,\n",
            "                                            'SKIP_NUM_SAMPLES': 0},\n",
            "                    'DATA_PATHS': [],\n",
            "                    'DATA_SOURCES': ['disk_folder'],\n",
            "                    'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                    'DROP_LAST': False,\n",
            "                    'ENABLE_QUEUE_DATASET': False,\n",
            "                    'INPUT_KEY_NAMES': ['data'],\n",
            "                    'LABEL_PATHS': [],\n",
            "                    'LABEL_SOURCES': ['disk_folder'],\n",
            "                    'LABEL_TYPE': 'standard',\n",
            "                    'MMAP_MODE': True,\n",
            "                    'NEW_IMG_PATH_PREFIX': '',\n",
            "                    'RANDOM_SYNTHETIC_IMAGES': False,\n",
            "                    'REMOVE_IMG_PATH_PREFIX': '',\n",
            "                    'TARGET_KEY_NAMES': ['label'],\n",
            "                    'TRANSFORMS': [{'name': 'RandomResizedCrop', 'size': 224},\n",
            "                                   {'name': 'RandomHorizontalFlip'},\n",
            "                                   {'name': 'ToTensor'},\n",
            "                                   {'mean': [0.485, 0.456, 0.406],\n",
            "                                    'name': 'Normalize',\n",
            "                                    'std': [0.229, 0.224, 0.225]}],\n",
            "                    'USE_DEBUGGING_SAMPLER': False,\n",
            "                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},\n",
            " 'DISTRIBUTED': {'BACKEND': 'nccl',\n",
            "                 'BROADCAST_BUFFERS': True,\n",
            "                 'INIT_METHOD': 'tcp',\n",
            "                 'MANUAL_GRADIENT_REDUCTION': False,\n",
            "                 'NCCL_DEBUG': False,\n",
            "                 'NCCL_SOCKET_NTHREADS': '',\n",
            "                 'NUM_NODES': 1,\n",
            "                 'NUM_PROC_PER_NODE': 1,\n",
            "                 'RUN_ID': 'auto'},\n",
            " 'EXTRACT_FEATURES': {'CHUNK_THRESHOLD': 0, 'OUTPUT_DIR': ''},\n",
            " 'HOOKS': {'LOG_GPU_STATS': True,\n",
            "           'MEMORY_SUMMARY': {'DUMP_MEMORY_ON_EXCEPTION': False,\n",
            "                              'LOG_ITERATION_NUM': 0,\n",
            "                              'PRINT_MEMORY_SUMMARY': True},\n",
            "           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,\n",
            "                                'INPUT_SHAPE': [3, 224, 224]},\n",
            "           'PERF_STATS': {'MONITOR_PERF_STATS': True,\n",
            "                          'PERF_STAT_FREQUENCY': -1,\n",
            "                          'ROLLING_BTIME_FREQ': -1},\n",
            "           'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': 'tensorboard',\n",
            "                                 'FLUSH_EVERY_N_MIN': 5,\n",
            "                                 'LOG_DIR': '.',\n",
            "                                 'LOG_PARAMS': True,\n",
            "                                 'LOG_PARAMS_EVERY_N_ITERS': 310,\n",
            "                                 'LOG_PARAMS_GRADIENTS': True,\n",
            "                                 'USE_TENSORBOARD': False}},\n",
            " 'IMG_RETRIEVAL': {'CROP_QUERY_ROI': False,\n",
            "                   'DATASET_PATH': '',\n",
            "                   'DEBUG_MODE': False,\n",
            "                   'EVAL_BINARY_PATH': '',\n",
            "                   'EVAL_DATASET_NAME': 'Paris',\n",
            "                   'FEATS_PROCESSING_TYPE': '',\n",
            "                   'GEM_POOL_POWER': 4.0,\n",
            "                   'IMG_SCALINGS': [1],\n",
            "                   'NORMALIZE_FEATURES': True,\n",
            "                   'NUM_DATABASE_SAMPLES': -1,\n",
            "                   'NUM_QUERY_SAMPLES': -1,\n",
            "                   'NUM_TRAINING_SAMPLES': -1,\n",
            "                   'N_PCA': 512,\n",
            "                   'RESIZE_IMG': 1024,\n",
            "                   'SAVE_FEATURES': False,\n",
            "                   'SAVE_RETRIEVAL_RANKINGS_SCORES': True,\n",
            "                   'SIMILARITY_MEASURE': 'cosine_similarity',\n",
            "                   'SPATIAL_LEVELS': 3,\n",
            "                   'TRAIN_DATASET_NAME': 'Oxford',\n",
            "                   'TRAIN_PCA_WHITENING': True,\n",
            "                   'USE_DISTRACTORS': False,\n",
            "                   'WHITEN_IMG_LIST': ''},\n",
            " 'LOG_FREQUENCY': 10,\n",
            " 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},\n",
            "          'barlow_twins_loss': {'embedding_dim': 8192,\n",
            "                                'lambda_': 0.0051,\n",
            "                                'scale_loss': 0.024},\n",
            "          'bce_logits_multiple_output_single_target': {'normalize_output': False,\n",
            "                                                       'reduction': 'none',\n",
            "                                                       'world_size': 1},\n",
            "          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,\n",
            "                                                          'normalize_output': False,\n",
            "                                                          'reduction': 'mean',\n",
            "                                                          'temperature': 1.0,\n",
            "                                                          'weight': None},\n",
            "          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,\n",
            "                                 'DROP_LAST': True,\n",
            "                                 'kmeans_iters': 10,\n",
            "                                 'memory_params': {'crops_for_mb': [0],\n",
            "                                                   'embedding_dim': 128},\n",
            "                                 'num_clusters': [3000, 3000, 3000],\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_train_samples': -1,\n",
            "                                 'temperature': 0.1},\n",
            "          'dino_loss': {'crops_for_teacher': [0, 1],\n",
            "                        'ema_center': 0.9,\n",
            "                        'momentum': 0.996,\n",
            "                        'normalize_last_layer': True,\n",
            "                        'output_dim': 65536,\n",
            "                        'student_temp': 0.1,\n",
            "                        'teacher_temp_max': 0.07,\n",
            "                        'teacher_temp_min': 0.04,\n",
            "                        'teacher_temp_warmup_iters': 37500},\n",
            "          'moco_loss': {'embedding_dim': 128,\n",
            "                        'momentum': 0.999,\n",
            "                        'queue_size': 65536,\n",
            "                        'temperature': 0.2},\n",
            "          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                               'embedding_dim': 128,\n",
            "                                                               'world_size': 64},\n",
            "                                             'num_crops': 2,\n",
            "                                             'temperature': 0.1},\n",
            "          'name': 'cross_entropy_multiple_output_single_target',\n",
            "          'nce_loss_with_memory': {'loss_type': 'nce',\n",
            "                                   'loss_weights': [1.0],\n",
            "                                   'memory_params': {'embedding_dim': 128,\n",
            "                                                     'memory_size': -1,\n",
            "                                                     'momentum': 0.5,\n",
            "                                                     'norm_init': True,\n",
            "                                                     'update_mem_on_forward': True},\n",
            "                                   'negative_sampling_params': {'num_negatives': 16000,\n",
            "                                                                'type': 'random'},\n",
            "                                   'norm_constant': -1,\n",
            "                                   'norm_embedding': True,\n",
            "                                   'num_train_samples': -1,\n",
            "                                   'temperature': 0.07,\n",
            "                                   'update_mem_with_emb_index': -100},\n",
            "          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                     'embedding_dim': 128,\n",
            "                                                     'world_size': 64},\n",
            "                                   'temperature': 0.1},\n",
            "          'swav_loss': {'crops_for_assign': [0, 1],\n",
            "                        'embedding_dim': 128,\n",
            "                        'epsilon': 0.05,\n",
            "                        'normalize_last_layer': True,\n",
            "                        'num_crops': 2,\n",
            "                        'num_iters': 3,\n",
            "                        'num_prototypes': [3000],\n",
            "                        'output_dir': '.',\n",
            "                        'queue': {'local_queue_length': 0,\n",
            "                                  'queue_length': 0,\n",
            "                                  'start_iter': 0},\n",
            "                        'temp_hard_assignment_iters': 0,\n",
            "                        'temperature': 0.1,\n",
            "                        'use_double_precision': False},\n",
            "          'swav_momentum_loss': {'crops_for_assign': [0, 1],\n",
            "                                 'embedding_dim': 128,\n",
            "                                 'epsilon': 0.05,\n",
            "                                 'momentum': 0.99,\n",
            "                                 'momentum_eval_mode_iter_start': 0,\n",
            "                                 'normalize_last_layer': True,\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_iters': 3,\n",
            "                                 'num_prototypes': [3000],\n",
            "                                 'queue': {'local_queue_length': 0,\n",
            "                                           'queue_length': 0,\n",
            "                                           'start_iter': 0},\n",
            "                                 'temperature': 0.1,\n",
            "                                 'use_double_precision': False}},\n",
            " 'MACHINE': {'DEVICE': 'gpu'},\n",
            " 'METERS': {'accuracy_list_meter': {'meter_names': [],\n",
            "                                    'num_meters': 1,\n",
            "                                    'topk_values': [1, 5]},\n",
            "            'enable_training_meter': True,\n",
            "            'mean_ap_list_meter': {'max_cpu_capacity': -1,\n",
            "                                   'meter_names': [],\n",
            "                                   'num_classes': 9605,\n",
            "                                   'num_meters': 1},\n",
            "            'name': 'accuracy_list_meter'},\n",
            " 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,\n",
            "                                        'USE_ACTIVATION_CHECKPOINTING': False},\n",
            "           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'},\n",
            "                          'AMP_TYPE': 'apex',\n",
            "                          'USE_AMP': False},\n",
            "           'CUDA_CACHE': {'CLEAR_CUDA_CACHE': False, 'CLEAR_FREQ': 100},\n",
            "           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': True,\n",
            "                                     'EVAL_TRUNK_AND_HEAD': False,\n",
            "                                     'EXTRACT_TRUNK_FEATURES_ONLY': False,\n",
            "                                     'FREEZE_TRUNK_AND_HEAD': False,\n",
            "                                     'FREEZE_TRUNK_ONLY': True,\n",
            "                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [],\n",
            "                                     'SHOULD_FLATTEN_FEATS': False},\n",
            "           'FSDP_CONFIG': {'AUTO_WRAP_THRESHOLD': 0,\n",
            "                           'bucket_cap_mb': 0,\n",
            "                           'clear_autocast_cache': True,\n",
            "                           'compute_dtype': torch.float32,\n",
            "                           'flatten_parameters': True,\n",
            "                           'fp32_reduce_scatter': False,\n",
            "                           'mixed_precision': True,\n",
            "                           'verbose': True},\n",
            "           'GRAD_CLIP': {'MAX_NORM': 1, 'NORM_TYPE': 2, 'USE_GRAD_CLIP': False},\n",
            "           'HEAD': {'BATCHNORM_EPS': 1e-05,\n",
            "                    'BATCHNORM_MOMENTUM': 0.1,\n",
            "                    'PARAMS': [['eval_mlp',\n",
            "                                {'dims': [2048, 1000], 'in_channels': 2048}]],\n",
            "                    'PARAMS_MULTIPLIER': 1.0},\n",
            "           'INPUT_TYPE': 'rgb',\n",
            "           'MULTI_INPUT_HEAD_MAPPING': [],\n",
            "           'NON_TRAINABLE_PARAMS': [],\n",
            "           'SHARDED_DDP_SETUP': {'USE_SDP': False, 'reduce_buffer_size': -1},\n",
            "           'SINGLE_PASS_EVERY_CROP': False,\n",
            "           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': True,\n",
            "                              'GROUP_SIZE': 0,\n",
            "                              'SYNC_BN_TYPE': 'pytorch'},\n",
            "           'TEMP_FROZEN_PARAMS_ITER_MAP': [],\n",
            "           'TRUNK': {'CONVIT': {'CLASS_TOKEN_IN_LOCAL_LAYERS': False,\n",
            "                                'LOCALITY_DIM': 10,\n",
            "                                'LOCALITY_STRENGTH': 1.0,\n",
            "                                'N_GPSA_LAYERS': 10,\n",
            "                                'USE_LOCAL_INIT': True},\n",
            "                     'EFFICIENT_NETS': {},\n",
            "                     'NAME': 'resnet',\n",
            "                     'REGNET': {},\n",
            "                     'RESNETS': {'DEPTH': 50,\n",
            "                                 'GROUPNORM_GROUPS': 32,\n",
            "                                 'GROUPS': 1,\n",
            "                                 'LAYER4_STRIDE': 2,\n",
            "                                 'NORM': 'BatchNorm',\n",
            "                                 'STANDARDIZE_CONVOLUTIONS': False,\n",
            "                                 'WIDTH_MULTIPLIER': 1,\n",
            "                                 'WIDTH_PER_GROUP': 64,\n",
            "                                 'ZERO_INIT_RESIDUAL': False},\n",
            "                     'VISION_TRANSFORMERS': {'ATTENTION_DROPOUT_RATE': 0,\n",
            "                                             'CLASSIFIER': 'token',\n",
            "                                             'DROPOUT_RATE': 0,\n",
            "                                             'DROP_PATH_RATE': 0,\n",
            "                                             'HIDDEN_DIM': 768,\n",
            "                                             'IMAGE_SIZE': 224,\n",
            "                                             'MLP_DIM': 3072,\n",
            "                                             'NUM_HEADS': 12,\n",
            "                                             'NUM_LAYERS': 12,\n",
            "                                             'PATCH_SIZE': 16,\n",
            "                                             'QKV_BIAS': False,\n",
            "                                             'QK_SCALE': False,\n",
            "                                             'name': None},\n",
            "                     'XCIT': {'ATTENTION_DROPOUT_RATE': 0,\n",
            "                              'DROPOUT_RATE': 0,\n",
            "                              'DROP_PATH_RATE': 0.05,\n",
            "                              'ETA': 1,\n",
            "                              'HIDDEN_DIM': 384,\n",
            "                              'IMAGE_SIZE': 224,\n",
            "                              'NUM_HEADS': 8,\n",
            "                              'NUM_LAYERS': 12,\n",
            "                              'PATCH_SIZE': 16,\n",
            "                              'QKV_BIAS': True,\n",
            "                              'QK_SCALE': False,\n",
            "                              'TOKENS_NORM': True,\n",
            "                              'name': None}},\n",
            "           'WEIGHTS_INIT': {'APPEND_PREFIX': 'trunk._feature_blocks.',\n",
            "                            'PARAMS_FILE': '/content/resnet50-19c8e357.pth',\n",
            "                            'REMOVE_PREFIX': '',\n",
            "                            'SKIP_LAYERS': ['num_batches_tracked'],\n",
            "                            'STATE_DICT_KEY_NAME': ''},\n",
            "           '_MODEL_INIT_SEED': 1},\n",
            " 'MONITORING': {'MONITOR_ACTIVATION_STATISTICS': 0},\n",
            " 'MULTI_PROCESSING_METHOD': 'forkserver',\n",
            " 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},\n",
            " 'OPTIMIZER': {'betas': [0.9, 0.999],\n",
            "               'construct_single_param_group_only': False,\n",
            "               'head_optimizer_params': {'use_different_lr': False,\n",
            "                                         'use_different_wd': False,\n",
            "                                         'weight_decay': 0.0005},\n",
            "               'larc_config': {'clip': False,\n",
            "                               'eps': 1e-08,\n",
            "                               'trust_coefficient': 0.001},\n",
            "               'momentum': 0.9,\n",
            "               'name': 'sgd',\n",
            "               'nesterov': True,\n",
            "               'non_regularized_parameters': [],\n",
            "               'num_epochs': 2,\n",
            "               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': False,\n",
            "                                                               'base_lr_batch_size': 256,\n",
            "                                                               'base_value': 0.1,\n",
            "                                                               'scaling_type': 'linear'},\n",
            "                                           'end_value': 0.0,\n",
            "                                           'interval_scaling': [],\n",
            "                                           'lengths': [],\n",
            "                                           'milestones': [1],\n",
            "                                           'name': 'multistep',\n",
            "                                           'schedulers': [],\n",
            "                                           'start_value': 0.1,\n",
            "                                           'update_interval': 'epoch',\n",
            "                                           'value': 0.1,\n",
            "                                           'values': [0.01, 0.001]},\n",
            "                                    'lr_head': {'auto_lr_scaling': {'auto_scale': False,\n",
            "                                                                    'base_lr_batch_size': 256,\n",
            "                                                                    'base_value': 0.1,\n",
            "                                                                    'scaling_type': 'linear'},\n",
            "                                                'end_value': 0.0,\n",
            "                                                'interval_scaling': [],\n",
            "                                                'lengths': [],\n",
            "                                                'milestones': [1],\n",
            "                                                'name': 'multistep',\n",
            "                                                'schedulers': [],\n",
            "                                                'start_value': 0.1,\n",
            "                                                'update_interval': 'epoch',\n",
            "                                                'value': 0.1,\n",
            "                                                'values': [0.01, 0.001]}},\n",
            "               'regularize_bias': True,\n",
            "               'regularize_bn': False,\n",
            "               'use_larc': False,\n",
            "               'use_zero': False,\n",
            "               'weight_decay': 0.0005},\n",
            " 'PROFILING': {'MEMORY_PROFILING': {'TRACK_BY_LAYER_MEMORY': False},\n",
            "               'NUM_ITERATIONS': 10,\n",
            "               'OUTPUT_FOLDER': '.',\n",
            "               'PROFILED_RANKS': [0, 1],\n",
            "               'RUNTIME_PROFILING': {'LEGACY_PROFILER': False,\n",
            "                                     'PROFILE_CPU': True,\n",
            "                                     'PROFILE_GPU': True,\n",
            "                                     'USE_PROFILER': False},\n",
            "               'START_ITERATION': 0,\n",
            "               'STOP_TRAINING_AFTER_PROFILING': False,\n",
            "               'WARMUP_ITERATIONS': 0},\n",
            " 'REPRODUCIBILITY': {'CUDDN_DETERMINISTIC': False},\n",
            " 'SEED_VALUE': 1,\n",
            " 'SLURM': {'ADDITIONAL_PARAMETERS': {},\n",
            "           'COMMENT': 'vissl job',\n",
            "           'CONSTRAINT': '',\n",
            "           'LOG_FOLDER': '.',\n",
            "           'MEM_GB': 250,\n",
            "           'NAME': 'vissl',\n",
            "           'NUM_CPU_PER_PROC': 8,\n",
            "           'PARTITION': '',\n",
            "           'PORT_ID': 40050,\n",
            "           'TIME_HOURS': 72,\n",
            "           'TIME_MINUTES': 0,\n",
            "           'USE_SLURM': False},\n",
            " 'SVM': {'cls_list': [],\n",
            "         'costs': {'base': -1.0,\n",
            "                   'costs_list': [0.1, 0.01],\n",
            "                   'power_range': [4, 20]},\n",
            "         'cross_val_folds': 3,\n",
            "         'dual': True,\n",
            "         'force_retrain': False,\n",
            "         'loss': 'squared_hinge',\n",
            "         'low_shot': {'dataset_name': 'voc',\n",
            "                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],\n",
            "                      'sample_inds': [1, 2, 3, 4, 5]},\n",
            "         'max_iter': 2000,\n",
            "         'normalize': True,\n",
            "         'penalty': 'l2'},\n",
            " 'TEST_EVERY_NUM_EPOCH': 2,\n",
            " 'TEST_MODEL': True,\n",
            " 'TEST_ONLY': False,\n",
            " 'TRAINER': {'TASK_NAME': 'self_supervision_task',\n",
            "             'TRAIN_STEP_NAME': 'standard_train_step'},\n",
            " 'VERBOSE': True}\n",
            "INFO 2021-10-18 00:36:59,344 train.py: 117: System config:\n",
            "-------------------  ---------------------------------------------------------------\n",
            "sys.platform         linux\n",
            "Python               3.7.12 (default, Sep 10 2021, 00:21:48) [GCC 7.5.0]\n",
            "numpy                1.19.5\n",
            "Pillow               7.1.2\n",
            "vissl                0.1.6 @/content/vissl/vissl\n",
            "GPU available        True\n",
            "GPU 0                Tesla K80\n",
            "CUDA_HOME            /usr/local/cuda\n",
            "torchvision          0.9.0+cu101 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "hydra                1.0.7 @/usr/local/lib/python3.7/dist-packages/hydra\n",
            "classy_vision        0.7.0.dev @/usr/local/lib/python3.7/dist-packages/classy_vision\n",
            "tensorboard          2.6.0\n",
            "apex                 0.1 @/usr/local/lib/python3.7/dist-packages/apex\n",
            "cv2                  4.1.2\n",
            "PyTorch              1.8.0+cu101 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build  False\n",
            "-------------------  ---------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 10.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.1, CUDNN_VERSION=7.6.3, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
            "\n",
            "CPU info:\n",
            "-------------------  ------------------------------\n",
            "Architecture         x86_64\n",
            "CPU op-mode(s)       32-bit, 64-bit\n",
            "Byte Order           Little Endian\n",
            "CPU(s)               2\n",
            "On-line CPU(s) list  0,1\n",
            "Thread(s) per core   2\n",
            "Core(s) per socket   1\n",
            "Socket(s)            1\n",
            "NUMA node(s)         1\n",
            "Vendor ID            GenuineIntel\n",
            "CPU family           6\n",
            "Model                63\n",
            "Model name           Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "Stepping             0\n",
            "CPU MHz              2300.000\n",
            "BogoMIPS             4600.00\n",
            "Hypervisor vendor    KVM\n",
            "Virtualization type  full\n",
            "L1d cache            32K\n",
            "L1i cache            32K\n",
            "L2 cache             256K\n",
            "L3 cache             46080K\n",
            "NUMA node0 CPU(s)    0,1\n",
            "-------------------  ------------------------------\n",
            "INFO 2021-10-18 00:36:59,345 trainer_main.py: 113: Using Distributed init method: tcp://localhost:60789, world_size: 1, rank: 0\n",
            "INFO 2021-10-18 00:36:59,346 distributed_c10d.py: 187: Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "INFO 2021-10-18 00:36:59,347 trainer_main.py: 134: | initialized host 3df825104503 as rank 0 (0)\n",
            "INFO 2021-10-18 00:37:01,450 train_task.py: 181: Not using Automatic Mixed Precision\n",
            "INFO 2021-10-18 00:37:01,451 train_task.py: 449: Building model....\n",
            "INFO 2021-10-18 00:37:01,451 resnext.py:  68: ResNeXT trunk, supports activation checkpointing. Deactivated\n",
            "INFO 2021-10-18 00:37:01,451 resnext.py:  88: Building model: ResNeXt50-1x64d-w1-BatchNorm2d\n",
            "INFO 2021-10-18 00:37:02,216 model_helpers.py: 150: Using SyncBN group size: None\n",
            "INFO 2021-10-18 00:37:02,217 model_helpers.py: 165: Converting BN layers to PyTorch SyncBN\n",
            "INFO 2021-10-18 00:37:02,217 model_helpers.py: 168: Not creating process_group for PyTorch SyncBN...\n",
            "INFO 2021-10-18 00:37:02,227 train_task.py: 467: config.MODEL.FEATURE_EVAL_SETTINGS.FREEZE_TRUNK_ONLY=True, will freeze trunk...\n",
            "INFO 2021-10-18 00:37:02,227 base_ssl_model.py: 194: Freezing model trunk...\n",
            "INFO 2021-10-18 00:37:02,228 train_task.py: 423: Initializing model from: /content/resnet50-19c8e357.pth\n",
            "INFO 2021-10-18 00:37:02,228 util.py: 276: Attempting to load checkpoint from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-10-18 00:37:02,440 util.py: 281: Loaded checkpoint from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-10-18 00:37:02,440 util.py: 240: Broadcasting checkpoint loaded from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-10-18 00:37:06,165 train_task.py: 429: Checkpoint loaded: /content/resnet50-19c8e357.pth...\n",
            "INFO 2021-10-18 00:37:06,167 checkpoint.py: 886: Loaded: trunk._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,167 checkpoint.py: 886: Loaded: trunk._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,167 checkpoint.py: 886: Loaded: trunk._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,167 checkpoint.py: 886: Loaded: trunk._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,167 checkpoint.py: 886: Loaded: trunk._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,168 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,168 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,168 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,168 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,168 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,168 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,169 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,169 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,169 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,169 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,169 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,169 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,170 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,170 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,170 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,170 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,170 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,170 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,171 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,171 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,171 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,171 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,171 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,171 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,172 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,172 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,172 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,172 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,172 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,172 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,173 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,173 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,173 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,173 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,173 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,174 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,174 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,174 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,174 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,174 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,174 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,175 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,175 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,175 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,175 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,175 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,175 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,176 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,176 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,176 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,176 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,176 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,176 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,177 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,177 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,177 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,177 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,177 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,177 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,178 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,178 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,178 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,178 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,178 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,178 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,179 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,179 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,179 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,179 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,179 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,179 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,180 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,180 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,180 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,180 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,180 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,181 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,181 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,181 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,181 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,181 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,181 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,182 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,182 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,182 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,182 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,182 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,182 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,183 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,183 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,183 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,183 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,183 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,184 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,184 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,184 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,184 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,184 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,185 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,185 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,185 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,185 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,185 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,185 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,186 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,186 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,186 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,186 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,186 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,187 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,187 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,187 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,187 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,187 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,188 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,264 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,264 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,264 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,264 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,265 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,265 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,265 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,265 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,266 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,266 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,266 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,266 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.3.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,267 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,267 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,267 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,267 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,268 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,268 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.3.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,268 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,268 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,269 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,269 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,269 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,269 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.3.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,270 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,270 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,270 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,270 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,271 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,271 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,272 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,272 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,272 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,272 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,273 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,273 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,273 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,274 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,274 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,274 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,274 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,275 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,275 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,275 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,276 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,276 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,276 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,277 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,277 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,277 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,277 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,278 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,278 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,278 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,279 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,279 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,279 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,280 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,280 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,280 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,281 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,281 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,281 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,281 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,282 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,282 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,282 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,283 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,283 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,283 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,283 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,284 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,284 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,285 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,285 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,285 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,285 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,286 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,286 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,286 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,287 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,287 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,287 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,287 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,288 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,288 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,288 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,289 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,289 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,289 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.3.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,290 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,290 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,290 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,290 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,291 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,291 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.3.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,291 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,291 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,292 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,292 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,292 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,292 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.3.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,293 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,293 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,293 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,293 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,293 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,293 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.4.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,294 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,294 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,295 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,295 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,295 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,295 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.4.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,295 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,296 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,296 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,296 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,296 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,296 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.4.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,297 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,297 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,297 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,297 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,297 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,297 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.5.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,298 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,298 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,299 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,299 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,299 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,299 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.5.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,299 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,299 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,300 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,300 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,300 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,300 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.5.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,301 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,301 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,301 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,301 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,301 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,302 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,304 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,304 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,304 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,304 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,304 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,304 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,305 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,305 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,306 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,306 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,306 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,306 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,308 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,308 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,308 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,308 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,309 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,309 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,310 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,310 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,310 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,310 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,310 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,311 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,314 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,314 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,314 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,314 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,315 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,315 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,316 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,316 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,316 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,317 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,317 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,317 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,318 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,319 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,319 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,319 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,319 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,319 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,322 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,322 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,322 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,322 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,323 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,323 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,324 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,324 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,324 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,324 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,327 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:37:06,327 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,327 checkpoint.py: 894: Not found:\t\theads.0.channel_bn.weight, not initialized\n",
            "INFO 2021-10-18 00:37:06,327 checkpoint.py: 894: Not found:\t\theads.0.channel_bn.bias, not initialized\n",
            "INFO 2021-10-18 00:37:06,327 checkpoint.py: 894: Not found:\t\theads.0.channel_bn.running_mean, not initialized\n",
            "INFO 2021-10-18 00:37:06,327 checkpoint.py: 894: Not found:\t\theads.0.channel_bn.running_var, not initialized\n",
            "INFO 2021-10-18 00:37:06,327 checkpoint.py: 851: Ignored layer:\theads.0.channel_bn.num_batches_tracked\n",
            "INFO 2021-10-18 00:37:06,328 checkpoint.py: 894: Not found:\t\theads.0.clf.clf.0.weight, not initialized\n",
            "INFO 2021-10-18 00:37:06,328 checkpoint.py: 894: Not found:\t\theads.0.clf.clf.0.bias, not initialized\n",
            "INFO 2021-10-18 00:37:06,328 checkpoint.py: 901: Extra layers not loaded from checkpoint: ['trunk._feature_blocks.fc.weight', 'trunk._feature_blocks.fc.bias', 'trunk._feature_blocks.type']\n",
            "INFO 2021-10-18 00:37:06,341 train_task.py: 651: Broadcast model BN buffers from primary on every forward pass\n",
            "INFO 2021-10-18 00:37:06,342 classification_task.py: 387: Synchronized Batch Normalization is disabled\n",
            "INFO 2021-10-18 00:37:06,384 optimizer_helper.py: 294: \n",
            "Trainable params: 4, \n",
            "Non-Trainable params: 0, \n",
            "Trunk Regularized Parameters: 0, \n",
            "Trunk Unregularized Parameters 0, \n",
            "Head Regularized Parameters: 2, \n",
            "Head Unregularized Parameters: 2 \n",
            "Remaining Regularized Parameters: 0 \n",
            "Remaining Unregularized Parameters: 0\n",
            "INFO 2021-10-18 00:37:06,385 ssl_dataset.py: 157: Rank: 0 split: TEST Data files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-10-18 00:37:06,390 ssl_dataset.py: 160: Rank: 0 split: TEST Label files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-10-18 00:37:06,391 disk_dataset.py:  86: Loaded 10 samples from folder /content/dummy_data/val\n",
            "INFO 2021-10-18 00:37:06,391 ssl_dataset.py: 157: Rank: 0 split: TRAIN Data files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-10-18 00:37:06,392 ssl_dataset.py: 160: Rank: 0 split: TRAIN Label files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-10-18 00:37:06,392 disk_dataset.py:  86: Loaded 10 samples from folder /content/dummy_data/train\n",
            "INFO 2021-10-18 00:37:06,393 misc.py: 161: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-10-18 00:37:06,393 __init__.py: 126: Created the Distributed Sampler....\n",
            "INFO 2021-10-18 00:37:06,393 __init__.py: 101: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "INFO 2021-10-18 00:37:06,393 __init__.py: 215: Wrapping the dataloader to async device copies\n",
            "INFO 2021-10-18 00:37:06,394 misc.py: 161: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-10-18 00:37:06,394 __init__.py: 126: Created the Distributed Sampler....\n",
            "INFO 2021-10-18 00:37:06,394 __init__.py: 101: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "INFO 2021-10-18 00:37:06,394 __init__.py: 215: Wrapping the dataloader to async device copies\n",
            "INFO 2021-10-18 00:37:06,394 train_task.py: 384: Building loss...\n",
            "INFO 2021-10-18 00:37:06,395 trainer_main.py: 268: Training 2 epochs\n",
            "INFO 2021-10-18 00:37:06,395 trainer_main.py: 269: One epoch = 5 iterations.\n",
            "INFO 2021-10-18 00:37:06,395 trainer_main.py: 270: Total 10 samples in one epoch\n",
            "INFO 2021-10-18 00:37:06,395 trainer_main.py: 276: Total 10 iterations for training\n",
            "INFO 2021-10-18 00:37:06,497 logger.py:  84: Mon Oct 18 00:37:06 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    54W / 149W |    562MiB / 11441MiB |      9%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "INFO 2021-10-18 00:37:06,502 trainer_main.py: 173: Model is:\n",
            " Classy <class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'>:\n",
            "BaseSSLMultiInputOutputModel(\n",
            "  (_heads): ModuleDict()\n",
            "  (trunk): ResNeXt(\n",
            "    (_feature_blocks): ModuleDict(\n",
            "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1_relu): ReLU(inplace=True)\n",
            "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (layer1): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer2): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer3): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (4): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (5): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer4): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), bias=False)\n",
            "            (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "      (flatten): Flatten()\n",
            "    )\n",
            "  )\n",
            "  (heads): ModuleList(\n",
            "    (0): LinearEvalMLP(\n",
            "      (channel_bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (clf): MLP(\n",
            "        (clf): Sequential(\n",
            "          (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "INFO 2021-10-18 00:37:06,595 trainer_main.py: 174: Loss is: CrossEntropyMultipleOutputSingleTargetLoss(\n",
            "  (criterion): CrossEntropyMultipleOutputSingleTargetCriterion(\n",
            "    (_losses): ModuleList()\n",
            "  )\n",
            ")\n",
            "INFO 2021-10-18 00:37:06,596 trainer_main.py: 175: Starting training....\n",
            "INFO 2021-10-18 00:37:06,597 __init__.py: 101: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-10-18 00:37:09,128 trainer_main.py: 333: Phase advanced. Rank: 0\n",
            "INFO 2021-10-18 00:37:09,130 log_hooks.py:  77: ========= Memory Summary at on_phase_start =======\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |  101283 KB |  101283 KB |  101284 KB |     512 B  |\n",
            "|       from large pool |   83416 KB |   83416 KB |   83416 KB |       0 B  |\n",
            "|       from small pool |   17867 KB |   17867 KB |   17868 KB |     512 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |  101283 KB |  101283 KB |  101284 KB |     512 B  |\n",
            "|       from large pool |   83416 KB |   83416 KB |   83416 KB |       0 B  |\n",
            "|       from small pool |   17867 KB |   17867 KB |   17868 KB |     512 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |  143360 KB |  143360 KB |  143360 KB |       0 B  |\n",
            "|       from large pool |  122880 KB |  122880 KB |  122880 KB |       0 B  |\n",
            "|       from small pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |   42076 KB |   42077 KB |  109570 KB |   67493 KB |\n",
            "|       from large pool |   39464 KB |   39464 KB |   93800 KB |   54336 KB |\n",
            "|       from small pool |    2612 KB |    2613 KB |   15770 KB |   13157 KB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     329    |     329    |     330    |       1    |\n",
            "|       from large pool |      19    |      19    |      19    |       0    |\n",
            "|       from small pool |     310    |     310    |     311    |       1    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     329    |     329    |     330    |       1    |\n",
            "|       from large pool |      19    |      19    |      19    |       0    |\n",
            "|       from small pool |     310    |     310    |     311    |       1    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      16    |      16    |      16    |       0    |\n",
            "|       from large pool |       6    |       6    |       6    |       0    |\n",
            "|       from small pool |      10    |      10    |      10    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       9    |       9    |      17    |       8    |\n",
            "|       from large pool |       6    |       6    |       6    |       0    |\n",
            "|       from small pool |       3    |       5    |      11    |       8    |\n",
            "|===========================================================================|\n",
            "\n",
            "\n",
            "INFO 2021-10-18 00:37:09,130 state_update_hooks.py: 113: Starting phase 0 [train]\n",
            "INFO 2021-10-18 00:37:10,444 log_hooks.py:  77: ========= Memory Summary at on_forward =======\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |  102517 KB |    2420 MB |   14867 MB |   14767 MB |\n",
            "|       from large pool |   84592 KB |    2402 MB |   14817 MB |   14735 MB |\n",
            "|       from small pool |   17925 KB |      19 MB |      50 MB |      32 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |  102517 KB |    2420 MB |   14867 MB |   14767 MB |\n",
            "|       from large pool |   84592 KB |    2402 MB |   14817 MB |   14735 MB |\n",
            "|       from small pool |   17925 KB |      19 MB |      50 MB |      32 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |    2462 MB |    3614 MB |   11612 MB |    9150 MB |\n",
            "|       from large pool |    2438 MB |    3592 MB |   11580 MB |    9142 MB |\n",
            "|       from small pool |      24 MB |      24 MB |      32 MB |       8 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |   40843 KB |    1260 MB |    4003 MB |    3963 MB |\n",
            "|       from large pool |   38288 KB |    1257 MB |    3937 MB |    3900 MB |\n",
            "|       from small pool |    2555 KB |       5 MB |      66 MB |      63 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     338    |     339    |     667    |     329    |\n",
            "|       from large pool |      20    |      24    |     102    |      82    |\n",
            "|       from small pool |     318    |     318    |     565    |     247    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     338    |     339    |     667    |     329    |\n",
            "|       from large pool |      20    |      24    |     102    |      82    |\n",
            "|       from small pool |     318    |     318    |     565    |     247    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      19    |      19    |      35    |      16    |\n",
            "|       from large pool |       7    |       9    |      19    |      12    |\n",
            "|       from small pool |      12    |      12    |      16    |       4    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      10    |      14    |     203    |     193    |\n",
            "|       from large pool |       6    |       9    |      44    |      38    |\n",
            "|       from small pool |       4    |       7    |     159    |     155    |\n",
            "|===========================================================================|\n",
            "\n",
            "\n",
            "INFO 2021-10-18 00:37:10,450 log_hooks.py:  77: ========= Memory Summary at on_backward =======\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |  110874 KB |    2420 MB |   14876 MB |   14767 MB |\n",
            "|       from large pool |   92976 KB |    2402 MB |   14825 MB |   14735 MB |\n",
            "|       from small pool |   17898 KB |      19 MB |      50 MB |      32 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |  110874 KB |    2420 MB |   14876 MB |   14767 MB |\n",
            "|       from large pool |   92976 KB |    2402 MB |   14825 MB |   14735 MB |\n",
            "|       from small pool |   17898 KB |      19 MB |      50 MB |      32 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |    2462 MB |    3614 MB |   11612 MB |    9150 MB |\n",
            "|       from large pool |    2438 MB |    3592 MB |   11580 MB |    9142 MB |\n",
            "|       from small pool |      24 MB |      24 MB |      32 MB |       8 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |   32486 KB |    1260 MB |    4003 MB |    3972 MB |\n",
            "|       from large pool |   29904 KB |    1257 MB |    3937 MB |    3908 MB |\n",
            "|       from small pool |    2582 KB |       5 MB |      66 MB |      63 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     340    |     346    |     689    |     349    |\n",
            "|       from large pool |      21    |      24    |     103    |      82    |\n",
            "|       from small pool |     319    |     325    |     586    |     267    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     340    |     346    |     689    |     349    |\n",
            "|       from large pool |      21    |      24    |     103    |      82    |\n",
            "|       from small pool |     319    |     325    |     586    |     267    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      19    |      19    |      35    |      16    |\n",
            "|       from large pool |       7    |       9    |      19    |      12    |\n",
            "|       from small pool |      12    |      12    |      16    |       4    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      10    |      14    |     215    |     205    |\n",
            "|       from large pool |       5    |       9    |      44    |      39    |\n",
            "|       from small pool |       5    |       7    |     171    |     166    |\n",
            "|===========================================================================|\n",
            "\n",
            "\n",
            "INFO 2021-10-18 00:37:10,452 log_hooks.py:  77: ========= Memory Summary at on_update =======\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |  118894 KB |    2420 MB |   14899 MB |   14783 MB |\n",
            "|       from large pool |  100976 KB |    2402 MB |   14849 MB |   14750 MB |\n",
            "|       from small pool |   17918 KB |      19 MB |      50 MB |      32 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |  118894 KB |    2420 MB |   14899 MB |   14783 MB |\n",
            "|       from large pool |  100976 KB |    2402 MB |   14849 MB |   14750 MB |\n",
            "|       from small pool |   17918 KB |      19 MB |      50 MB |      32 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |    2462 MB |    3614 MB |   11612 MB |    9150 MB |\n",
            "|       from large pool |    2438 MB |    3592 MB |   11580 MB |    9142 MB |\n",
            "|       from small pool |      24 MB |      24 MB |      32 MB |       8 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    2341 MB |    2341 MB |    6329 MB |    3987 MB |\n",
            "|       from large pool |    2339 MB |    2339 MB |    6263 MB |    3924 MB |\n",
            "|       from small pool |       2 MB |       5 MB |      66 MB |      63 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     344    |     346    |     699    |     355    |\n",
            "|       from large pool |      22    |      24    |     106    |      84    |\n",
            "|       from small pool |     322    |     325    |     593    |     271    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     344    |     346    |     699    |     355    |\n",
            "|       from large pool |      22    |      24    |     106    |      84    |\n",
            "|       from small pool |     322    |     325    |     593    |     271    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      19    |      19    |      35    |      16    |\n",
            "|       from large pool |       7    |       9    |      19    |      12    |\n",
            "|       from small pool |      12    |      12    |      16    |       4    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      12    |      14    |     218    |     206    |\n",
            "|       from large pool |       7    |       9    |      46    |      39    |\n",
            "|       from small pool |       5    |       7    |     172    |     167    |\n",
            "|===========================================================================|\n",
            "\n",
            "\n",
            "INFO 2021-10-18 00:37:10,452 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 0; lr: 0.01; loss: 7.06991; btime(ms): 0; eta: 0:00:00; peak_mem(M): 2420;\n",
            "INFO 2021-10-18 00:37:10,481 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 1; lr: 0.01; loss: 7.05428; btime(ms): 4057; eta: 0:00:36; peak_mem(M): 2420; max_iterations: 10;\n",
            "INFO 2021-10-18 00:37:10,580 trainer_main.py: 214: Meters synced\n",
            "INFO 2021-10-18 00:37:10,580 log_hooks.py: 568: Average train batch time (ms) for 5 batches: 290\n",
            "INFO 2021-10-18 00:37:10,581 log_hooks.py: 577: Train step time breakdown (rank 0):\n",
            "               Timer     Host    CudaEvent\n",
            "         read_sample:    3.35 ms    3.33 ms\n",
            "             forward:  274.08 ms  281.72 ms\n",
            "        loss_compute:    0.70 ms    0.69 ms\n",
            "     loss_all_reduce:    0.10 ms    0.11 ms\n",
            "       meters_update:    0.48 ms    0.51 ms\n",
            "            backward:    1.00 ms    1.28 ms\n",
            "      optimizer_step:    0.53 ms    0.84 ms\n",
            "    train_step_total:  289.73 ms  289.82 ms\n",
            "INFO 2021-10-18 00:37:10,581 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {0: 0.0}, 'top_5': {0: 0.0}}\n",
            "INFO 2021-10-18 00:37:10,581 io.py:  63: Saving data to file: /content/checkpoints/metrics.json\n",
            "INFO 2021-10-18 00:37:10,581 io.py:  89: Saved data to file: /content/checkpoints/metrics.json\n",
            "INFO 2021-10-18 00:37:10,582 log_hooks.py: 426: [phase: 0] Saving checkpoint to /content/checkpoints\n",
            "INFO 2021-10-18 00:37:10,808 checkpoint.py: 131: Saved checkpoint: /content/checkpoints/model_phase0.torch\n",
            "INFO 2021-10-18 00:37:10,808 checkpoint.py: 140: Creating symlink...\n",
            "INFO 2021-10-18 00:37:10,809 checkpoint.py: 144: Created symlink: /content/checkpoints/checkpoint.torch\n",
            "INFO 2021-10-18 00:37:10,809 __init__.py: 101: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 1, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-10-18 00:37:13,146 trainer_main.py: 333: Phase advanced. Rank: 0\n",
            "INFO 2021-10-18 00:37:13,146 state_update_hooks.py: 113: Starting phase 1 [test]\n",
            "INFO 2021-10-18 00:37:13,342 trainer_main.py: 214: Meters synced\n",
            "INFO 2021-10-18 00:37:13,343 log_hooks.py: 568: Average test batch time (ms) for 5 batches: 39\n",
            "INFO 2021-10-18 00:37:13,343 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {0: 0.0}, 'top_5': {0: 0.0}}\n",
            "INFO 2021-10-18 00:37:13,343 io.py:  63: Saving data to file: /content/checkpoints/metrics.json\n",
            "INFO 2021-10-18 00:37:13,344 io.py:  89: Saved data to file: /content/checkpoints/metrics.json\n",
            "INFO 2021-10-18 00:37:13,344 __init__.py: 101: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 2, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-10-18 00:37:15,637 trainer_main.py: 333: Phase advanced. Rank: 0\n",
            "INFO 2021-10-18 00:37:15,637 state_update_hooks.py: 113: Starting phase 2 [train]\n",
            "INFO 2021-10-18 00:37:15,724 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 5; lr: 0.001; loss: 6.95932; btime(ms): 694; eta: 0:00:03; peak_mem(M): 2420;\n",
            "INFO 2021-10-18 00:37:15,866 trainer_main.py: 214: Meters synced\n",
            "INFO 2021-10-18 00:37:15,866 log_hooks.py: 568: Average train batch time (ms) for 5 batches: 45\n",
            "INFO 2021-10-18 00:37:15,867 log_hooks.py: 577: Train step time breakdown (rank 0):\n",
            "               Timer     Host    CudaEvent\n",
            "         read_sample:   10.75 ms   10.73 ms\n",
            "             forward:   22.11 ms   29.49 ms\n",
            "        loss_compute:    0.48 ms    0.49 ms\n",
            "     loss_all_reduce:    0.10 ms    0.11 ms\n",
            "       meters_update:    0.45 ms    0.46 ms\n",
            "            backward:    1.45 ms    1.79 ms\n",
            "      optimizer_step:    1.23 ms    1.51 ms\n",
            "    train_step_total:   45.46 ms   45.58 ms\n",
            "INFO 2021-10-18 00:37:15,867 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {0: 20.0}, 'top_5': {0: 30.0}}\n",
            "INFO 2021-10-18 00:37:15,867 io.py:  63: Saving data to file: /content/checkpoints/metrics.json\n",
            "INFO 2021-10-18 00:37:15,867 io.py:  89: Saved data to file: /content/checkpoints/metrics.json\n",
            "INFO 2021-10-18 00:37:15,868 log_hooks.py: 426: [phase: 1] Saving checkpoint to /content/checkpoints\n",
            "INFO 2021-10-18 00:37:16,122 checkpoint.py: 131: Saved checkpoint: /content/checkpoints/model_final_checkpoint_phase1.torch\n",
            "INFO 2021-10-18 00:37:16,122 checkpoint.py: 140: Creating symlink...\n",
            "INFO 2021-10-18 00:37:16,122 checkpoint.py: 144: Created symlink: /content/checkpoints/checkpoint.torch\n",
            "INFO 2021-10-18 00:37:16,123 __init__.py: 101: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 3, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-10-18 00:37:18,586 trainer_main.py: 333: Phase advanced. Rank: 0\n",
            "INFO 2021-10-18 00:37:18,586 state_update_hooks.py: 113: Starting phase 3 [test]\n",
            "INFO 2021-10-18 00:37:18,783 trainer_main.py: 214: Meters synced\n",
            "INFO 2021-10-18 00:37:18,784 log_hooks.py: 568: Average test batch time (ms) for 5 batches: 39\n",
            "INFO 2021-10-18 00:37:18,784 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {0: 50.0}, 'top_5': {0: 50.0}}\n",
            "INFO 2021-10-18 00:37:18,784 io.py:  63: Saving data to file: /content/checkpoints/metrics.json\n",
            "INFO 2021-10-18 00:37:18,784 io.py:  89: Saved data to file: /content/checkpoints/metrics.json\n",
            "INFO 2021-10-18 00:37:18,880 train.py: 131: All Done!\n",
            "INFO 2021-10-18 00:37:18,880 logger.py:  73: Shutting down loggers...\n",
            "INFO 2021-10-18 00:37:18,881 distributed_launcher.py: 168: All Done!\n",
            "INFO 2021-10-18 00:37:18,881 logger.py:  73: Shutting down loggers...\n"
          ]
        }
      ],
      "source": [
        "!python3 tools/run_distributed_engines.py \\\n",
        "    hydra.verbose=true \\\n",
        "    config=test/integration_test/quick_eval_in1k_linear_imagefolder_head.yaml \\\n",
        "    config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DATA.TRAIN.DATA_LIMIT=-1 \\\n",
        "    config.DATA.TEST.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TEST.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DATA.TEST.DATA_LIMIT=-1 \\\n",
        "    config.DISTRIBUTED.NUM_NODES=1 \\\n",
        "    config.DISTRIBUTED.NUM_PROC_PER_NODE=1 \\\n",
        "    config.CHECKPOINT.DIR=\"/content/checkpoints\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.PARAMS_FILE=\"/content/resnet50-19c8e357.pth\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=\"trunk._feature_blocks.\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8fILq7VzyOu"
      },
      "source": [
        "And we are done!! We have the linear classifier trained on the trunk output and the `metrics.json` containing `top-1` and `top-5` accuracy on validation set is available in `checkpoints/metrics.json`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otUmgl4ms96M",
        "outputId": "bf4229ed-bb9b-4ea0-f948-23a3497663d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;36mcheckpoint.torch\u001b[0m@  model_final_checkpoint_phase1.torch  train_config.yaml\n",
            "log.txt            model_phase0.torch\n",
            "metrics.json       stdout.json\n"
          ]
        }
      ],
      "source": [
        "ls /content/checkpoints/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDMLjudpya2I",
        "outputId": "195ed6da-af0e-4396-c27d-e84a550a6bed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"iteration\": 5, \"phase_idx\": 0, \"train_accuracy_list_meter\": {\"top_1\": {\"0\": 0.0}, \"top_5\": {\"0\": 0.0}}, \"train_phase_idx\": 0}\n",
            "{\"iteration\": 5, \"phase_idx\": 1, \"test_accuracy_list_meter\": {\"top_1\": {\"0\": 0.0}, \"top_5\": {\"0\": 0.0}}, \"train_phase_idx\": 0}\n",
            "{\"iteration\": 10, \"phase_idx\": 2, \"train_accuracy_list_meter\": {\"top_1\": {\"0\": 20.0}, \"top_5\": {\"0\": 30.0}}, \"train_phase_idx\": 1}\n",
            "{\"iteration\": 10, \"phase_idx\": 3, \"test_accuracy_list_meter\": {\"top_1\": {\"0\": 50.0}, \"top_5\": {\"0\": 50.0}}, \"train_phase_idx\": 1}\n"
          ]
        }
      ],
      "source": [
        "cat /content/checkpoints/metrics.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJKSyC0txO4x"
      },
      "source": [
        "## Training linear classifiers on several trunk features\n",
        "\n",
        "VISSL also supports training linear classifiers on several features of the trunk. For the purpose of tutorial, we will use [this](https://github.com/facebookresearch/vissl/blob/master/configs/config/test/integration_test/quick_eval_in1k_linear_imagefolder.yaml) config file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8hMOAgBxptv"
      },
      "source": [
        "Now, let's re-run the previous command with the new config."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwEg7GLoxvr5",
        "outputId": "a8f0905a-44b0-4c26-cbc1-2c9ce4c9f39f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "####### overrides: ['hydra.verbose=true', 'config=test/integration_test/quick_eval_in1k_linear_imagefolder.yaml', 'config.DATA.TRAIN.DATA_SOURCES=[disk_folder]', 'config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]', 'config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2', 'config.DATA.TRAIN.DATA_LIMIT=-1', 'config.DATA.TEST.DATA_SOURCES=[disk_folder]', 'config.DATA.TEST.LABEL_SOURCES=[disk_folder]', 'config.DATA.TEST.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TEST.BATCHSIZE_PER_REPLICA=2', 'config.DATA.TEST.DATA_LIMIT=-1', 'config.DISTRIBUTED.NUM_NODES=1', 'config.DISTRIBUTED.NUM_PROC_PER_NODE=1', 'config.CHECKPOINT.DIR=/content/checkpoints_trunk_eval', 'config.MODEL.WEIGHTS_INIT.PARAMS_FILE=/content/resnet50-19c8e357.pth', 'config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=trunk.base_model._feature_blocks.', 'config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=', 'hydra.verbose=true']\n",
            "INFO 2021-10-18 00:39:53,506 distributed_launcher.py: 184: Spawning process for node_id: 0, local_rank: 0, dist_rank: 0, dist_run_id: localhost:34881\n",
            "INFO 2021-10-18 00:39:53,506 train.py:  94: Env set for rank: 0, dist_rank: 0\n",
            "INFO 2021-10-18 00:39:53,507 env.py:  50: CLICOLOR:\t1\n",
            "INFO 2021-10-18 00:39:53,507 env.py:  50: CLOUDSDK_CONFIG:\t/content/.config\n",
            "INFO 2021-10-18 00:39:53,507 env.py:  50: CLOUDSDK_PYTHON:\tpython3\n",
            "INFO 2021-10-18 00:39:53,507 env.py:  50: COLAB_GPU:\t1\n",
            "INFO 2021-10-18 00:39:53,507 env.py:  50: CUDA_VERSION:\t11.1.1\n",
            "INFO 2021-10-18 00:39:53,507 env.py:  50: CUDNN_VERSION:\t8.0.5.39\n",
            "INFO 2021-10-18 00:39:53,507 env.py:  50: DATALAB_SETTINGS_OVERRIDES:\t{\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=\\\"172.28.0.2\\\"\"],\"debugAdapterMultiplexerPath\":\"/usr/local/bin/dap_multiplexer\",\"enableLsp\":true}\n",
            "INFO 2021-10-18 00:39:53,507 env.py:  50: DEBIAN_FRONTEND:\tnoninteractive\n",
            "INFO 2021-10-18 00:39:53,508 env.py:  50: ENV:\t/root/.bashrc\n",
            "INFO 2021-10-18 00:39:53,508 env.py:  50: GCE_METADATA_TIMEOUT:\t0\n",
            "INFO 2021-10-18 00:39:53,508 env.py:  50: GCS_READ_CACHE_BLOCK_SIZE_MB:\t16\n",
            "INFO 2021-10-18 00:39:53,508 env.py:  50: GIT_PAGER:\tcat\n",
            "INFO 2021-10-18 00:39:53,508 env.py:  50: GLIBCPP_FORCE_NEW:\t1\n",
            "INFO 2021-10-18 00:39:53,508 env.py:  50: GLIBCXX_FORCE_NEW:\t1\n",
            "INFO 2021-10-18 00:39:53,508 env.py:  50: HOME:\t/root\n",
            "INFO 2021-10-18 00:39:53,509 env.py:  50: HOSTNAME:\t3df825104503\n",
            "INFO 2021-10-18 00:39:53,509 env.py:  50: JPY_PARENT_PID:\t67\n",
            "INFO 2021-10-18 00:39:53,509 env.py:  50: LANG:\ten_US.UTF-8\n",
            "INFO 2021-10-18 00:39:53,509 env.py:  50: LAST_FORCED_REBUILD:\t20211007\n",
            "INFO 2021-10-18 00:39:53,509 env.py:  50: LD_LIBRARY_PATH:\t/usr/lib64-nvidia\n",
            "INFO 2021-10-18 00:39:53,509 env.py:  50: LD_PRELOAD:\t/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4\n",
            "INFO 2021-10-18 00:39:53,509 env.py:  50: LIBRARY_PATH:\t/usr/local/cuda/lib64/stubs\n",
            "INFO 2021-10-18 00:39:53,509 env.py:  50: LOCAL_RANK:\t0\n",
            "INFO 2021-10-18 00:39:53,510 env.py:  50: MPLBACKEND:\tmodule://ipykernel.pylab.backend_inline\n",
            "INFO 2021-10-18 00:39:53,510 env.py:  50: NCCL_VERSION:\t2.7.8\n",
            "INFO 2021-10-18 00:39:53,510 env.py:  50: NO_GCE_CHECK:\tTrue\n",
            "INFO 2021-10-18 00:39:53,510 env.py:  50: NVIDIA_DRIVER_CAPABILITIES:\tcompute,utility\n",
            "INFO 2021-10-18 00:39:53,510 env.py:  50: NVIDIA_REQUIRE_CUDA:\tcuda>=11.1 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 brand=tesla,driver>=450,driver<451\n",
            "INFO 2021-10-18 00:39:53,510 env.py:  50: NVIDIA_VISIBLE_DEVICES:\tall\n",
            "INFO 2021-10-18 00:39:53,510 env.py:  50: OLDPWD:\t/\n",
            "INFO 2021-10-18 00:39:53,510 env.py:  50: PAGER:\tcat\n",
            "INFO 2021-10-18 00:39:53,511 env.py:  50: PATH:\t/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n",
            "INFO 2021-10-18 00:39:53,511 env.py:  50: PWD:\t/content/vissl\n",
            "INFO 2021-10-18 00:39:53,511 env.py:  50: PYDEVD_USE_FRAME_EVAL:\tNO\n",
            "INFO 2021-10-18 00:39:53,511 env.py:  50: PYTHONPATH:\t/env/python\n",
            "INFO 2021-10-18 00:39:53,511 env.py:  50: PYTHONWARNINGS:\tignore:::pip._internal.cli.base_command\n",
            "INFO 2021-10-18 00:39:53,511 env.py:  50: RANK:\t0\n",
            "INFO 2021-10-18 00:39:53,511 env.py:  50: SHELL:\t/bin/bash\n",
            "INFO 2021-10-18 00:39:53,511 env.py:  50: SHLVL:\t1\n",
            "INFO 2021-10-18 00:39:53,512 env.py:  50: TBE_CREDS_ADDR:\t172.28.0.1:8008\n",
            "INFO 2021-10-18 00:39:53,512 env.py:  50: TERM:\txterm-color\n",
            "INFO 2021-10-18 00:39:53,512 env.py:  50: TF_FORCE_GPU_ALLOW_GROWTH:\ttrue\n",
            "INFO 2021-10-18 00:39:53,512 env.py:  50: WORLD_SIZE:\t1\n",
            "INFO 2021-10-18 00:39:53,512 env.py:  50: _:\t/usr/bin/python3\n",
            "INFO 2021-10-18 00:39:53,512 env.py:  50: __EGL_VENDOR_LIBRARY_DIRS:\t/usr/lib64-nvidia:/usr/share/glvnd/egl_vendor.d/\n",
            "INFO 2021-10-18 00:39:53,512 misc.py: 161: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-10-18 00:39:53,513 train.py: 105: Setting seed....\n",
            "INFO 2021-10-18 00:39:53,513 misc.py: 173: MACHINE SEED: 2\n",
            "INFO 2021-10-18 00:39:53,514 hydra_config.py: 131: Training with config:\n",
            "INFO 2021-10-18 00:39:53,523 hydra_config.py: 140: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,\n",
            "                'AUTO_RESUME': True,\n",
            "                'BACKEND': 'disk',\n",
            "                'CHECKPOINT_FREQUENCY': 2,\n",
            "                'CHECKPOINT_ITER_FREQUENCY': -1,\n",
            "                'DIR': '/content/checkpoints_trunk_eval',\n",
            "                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,\n",
            "                'OVERWRITE_EXISTING': True,\n",
            "                'USE_SYMLINK_CHECKPOINT_FOR_RESUME': False},\n",
            " 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',\n",
            "                'DATA_LIMIT': -1,\n",
            "                'DATA_LIMIT_SAMPLING': {'SEED': 0},\n",
            "                'FEATURES': {'DATASET_NAME': '',\n",
            "                             'DATA_PARTITION': 'TRAIN',\n",
            "                             'DIMENSIONALITY_REDUCTION': 0,\n",
            "                             'EXTRACT': False,\n",
            "                             'LAYER_NAME': '',\n",
            "                             'PATH': '.',\n",
            "                             'TEST_PARTITION': 'TEST'},\n",
            "                'NUM_CLUSTERS': 16000,\n",
            "                'NUM_ITER': 50,\n",
            "                'OUTPUT_DIR': '.'},\n",
            " 'DATA': {'DDP_BUCKET_CAP_MB': 25,\n",
            "          'ENABLE_ASYNC_GPU_COPY': True,\n",
            "          'NUM_DATALOADER_WORKERS': 2,\n",
            "          'PIN_MEMORY': True,\n",
            "          'TEST': {'BASE_DATASET': 'generic_ssl',\n",
            "                   'BATCHSIZE_PER_REPLICA': 2,\n",
            "                   'COLLATE_FUNCTION': 'default_collate',\n",
            "                   'COLLATE_FUNCTION_PARAMS': {},\n",
            "                   'COPY_DESTINATION_DIR': '',\n",
            "                   'COPY_TO_LOCAL_DISK': False,\n",
            "                   'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                   'DATA_LIMIT': -1,\n",
            "                   'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,\n",
            "                                           'SEED': 0,\n",
            "                                           'SKIP_NUM_SAMPLES': 0},\n",
            "                   'DATA_PATHS': [],\n",
            "                   'DATA_SOURCES': ['disk_folder'],\n",
            "                   'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                   'DROP_LAST': False,\n",
            "                   'ENABLE_QUEUE_DATASET': False,\n",
            "                   'INPUT_KEY_NAMES': ['data'],\n",
            "                   'LABEL_PATHS': [],\n",
            "                   'LABEL_SOURCES': ['disk_folder'],\n",
            "                   'LABEL_TYPE': 'standard',\n",
            "                   'MMAP_MODE': True,\n",
            "                   'NEW_IMG_PATH_PREFIX': '',\n",
            "                   'RANDOM_SYNTHETIC_IMAGES': False,\n",
            "                   'REMOVE_IMG_PATH_PREFIX': '',\n",
            "                   'TARGET_KEY_NAMES': ['label'],\n",
            "                   'TRANSFORMS': [{'name': 'Resize', 'size': 256},\n",
            "                                  {'name': 'CenterCrop', 'size': 224},\n",
            "                                  {'name': 'ToTensor'},\n",
            "                                  {'mean': [0.485, 0.456, 0.406],\n",
            "                                   'name': 'Normalize',\n",
            "                                   'std': [0.229, 0.224, 0.225]}],\n",
            "                   'USE_DEBUGGING_SAMPLER': False,\n",
            "                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},\n",
            "          'TRAIN': {'BASE_DATASET': 'generic_ssl',\n",
            "                    'BATCHSIZE_PER_REPLICA': 2,\n",
            "                    'COLLATE_FUNCTION': 'default_collate',\n",
            "                    'COLLATE_FUNCTION_PARAMS': {},\n",
            "                    'COPY_DESTINATION_DIR': '',\n",
            "                    'COPY_TO_LOCAL_DISK': False,\n",
            "                    'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                    'DATA_LIMIT': -1,\n",
            "                    'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,\n",
            "                                            'SEED': 0,\n",
            "                                            'SKIP_NUM_SAMPLES': 0},\n",
            "                    'DATA_PATHS': [],\n",
            "                    'DATA_SOURCES': ['disk_folder'],\n",
            "                    'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                    'DROP_LAST': False,\n",
            "                    'ENABLE_QUEUE_DATASET': False,\n",
            "                    'INPUT_KEY_NAMES': ['data'],\n",
            "                    'LABEL_PATHS': [],\n",
            "                    'LABEL_SOURCES': ['disk_folder'],\n",
            "                    'LABEL_TYPE': 'standard',\n",
            "                    'MMAP_MODE': True,\n",
            "                    'NEW_IMG_PATH_PREFIX': '',\n",
            "                    'RANDOM_SYNTHETIC_IMAGES': False,\n",
            "                    'REMOVE_IMG_PATH_PREFIX': '',\n",
            "                    'TARGET_KEY_NAMES': ['label'],\n",
            "                    'TRANSFORMS': [{'name': 'RandomResizedCrop', 'size': 224},\n",
            "                                   {'name': 'RandomHorizontalFlip'},\n",
            "                                   {'name': 'ToTensor'},\n",
            "                                   {'mean': [0.485, 0.456, 0.406],\n",
            "                                    'name': 'Normalize',\n",
            "                                    'std': [0.229, 0.224, 0.225]}],\n",
            "                    'USE_DEBUGGING_SAMPLER': False,\n",
            "                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},\n",
            " 'DISTRIBUTED': {'BACKEND': 'nccl',\n",
            "                 'BROADCAST_BUFFERS': True,\n",
            "                 'INIT_METHOD': 'tcp',\n",
            "                 'MANUAL_GRADIENT_REDUCTION': False,\n",
            "                 'NCCL_DEBUG': False,\n",
            "                 'NCCL_SOCKET_NTHREADS': '',\n",
            "                 'NUM_NODES': 1,\n",
            "                 'NUM_PROC_PER_NODE': 1,\n",
            "                 'RUN_ID': 'auto'},\n",
            " 'EXTRACT_FEATURES': {'CHUNK_THRESHOLD': 0, 'OUTPUT_DIR': ''},\n",
            " 'HOOKS': {'LOG_GPU_STATS': True,\n",
            "           'MEMORY_SUMMARY': {'DUMP_MEMORY_ON_EXCEPTION': False,\n",
            "                              'LOG_ITERATION_NUM': 0,\n",
            "                              'PRINT_MEMORY_SUMMARY': True},\n",
            "           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,\n",
            "                                'INPUT_SHAPE': [3, 224, 224]},\n",
            "           'PERF_STATS': {'MONITOR_PERF_STATS': True,\n",
            "                          'PERF_STAT_FREQUENCY': -1,\n",
            "                          'ROLLING_BTIME_FREQ': -1},\n",
            "           'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': 'tensorboard',\n",
            "                                 'FLUSH_EVERY_N_MIN': 5,\n",
            "                                 'LOG_DIR': '.',\n",
            "                                 'LOG_PARAMS': True,\n",
            "                                 'LOG_PARAMS_EVERY_N_ITERS': 310,\n",
            "                                 'LOG_PARAMS_GRADIENTS': True,\n",
            "                                 'USE_TENSORBOARD': False}},\n",
            " 'IMG_RETRIEVAL': {'CROP_QUERY_ROI': False,\n",
            "                   'DATASET_PATH': '',\n",
            "                   'DEBUG_MODE': False,\n",
            "                   'EVAL_BINARY_PATH': '',\n",
            "                   'EVAL_DATASET_NAME': 'Paris',\n",
            "                   'FEATS_PROCESSING_TYPE': '',\n",
            "                   'GEM_POOL_POWER': 4.0,\n",
            "                   'IMG_SCALINGS': [1],\n",
            "                   'NORMALIZE_FEATURES': True,\n",
            "                   'NUM_DATABASE_SAMPLES': -1,\n",
            "                   'NUM_QUERY_SAMPLES': -1,\n",
            "                   'NUM_TRAINING_SAMPLES': -1,\n",
            "                   'N_PCA': 512,\n",
            "                   'RESIZE_IMG': 1024,\n",
            "                   'SAVE_FEATURES': False,\n",
            "                   'SAVE_RETRIEVAL_RANKINGS_SCORES': True,\n",
            "                   'SIMILARITY_MEASURE': 'cosine_similarity',\n",
            "                   'SPATIAL_LEVELS': 3,\n",
            "                   'TRAIN_DATASET_NAME': 'Oxford',\n",
            "                   'TRAIN_PCA_WHITENING': True,\n",
            "                   'USE_DISTRACTORS': False,\n",
            "                   'WHITEN_IMG_LIST': ''},\n",
            " 'LOG_FREQUENCY': 10,\n",
            " 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},\n",
            "          'barlow_twins_loss': {'embedding_dim': 8192,\n",
            "                                'lambda_': 0.0051,\n",
            "                                'scale_loss': 0.024},\n",
            "          'bce_logits_multiple_output_single_target': {'normalize_output': False,\n",
            "                                                       'reduction': 'none',\n",
            "                                                       'world_size': 1},\n",
            "          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,\n",
            "                                                          'normalize_output': False,\n",
            "                                                          'reduction': 'mean',\n",
            "                                                          'temperature': 1.0,\n",
            "                                                          'weight': None},\n",
            "          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,\n",
            "                                 'DROP_LAST': True,\n",
            "                                 'kmeans_iters': 10,\n",
            "                                 'memory_params': {'crops_for_mb': [0],\n",
            "                                                   'embedding_dim': 128},\n",
            "                                 'num_clusters': [3000, 3000, 3000],\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_train_samples': -1,\n",
            "                                 'temperature': 0.1},\n",
            "          'dino_loss': {'crops_for_teacher': [0, 1],\n",
            "                        'ema_center': 0.9,\n",
            "                        'momentum': 0.996,\n",
            "                        'normalize_last_layer': True,\n",
            "                        'output_dim': 65536,\n",
            "                        'student_temp': 0.1,\n",
            "                        'teacher_temp_max': 0.07,\n",
            "                        'teacher_temp_min': 0.04,\n",
            "                        'teacher_temp_warmup_iters': 37500},\n",
            "          'moco_loss': {'embedding_dim': 128,\n",
            "                        'momentum': 0.999,\n",
            "                        'queue_size': 65536,\n",
            "                        'temperature': 0.2},\n",
            "          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                               'embedding_dim': 128,\n",
            "                                                               'world_size': 64},\n",
            "                                             'num_crops': 2,\n",
            "                                             'temperature': 0.1},\n",
            "          'name': 'cross_entropy_multiple_output_single_target',\n",
            "          'nce_loss_with_memory': {'loss_type': 'nce',\n",
            "                                   'loss_weights': [1.0],\n",
            "                                   'memory_params': {'embedding_dim': 128,\n",
            "                                                     'memory_size': -1,\n",
            "                                                     'momentum': 0.5,\n",
            "                                                     'norm_init': True,\n",
            "                                                     'update_mem_on_forward': True},\n",
            "                                   'negative_sampling_params': {'num_negatives': 16000,\n",
            "                                                                'type': 'random'},\n",
            "                                   'norm_constant': -1,\n",
            "                                   'norm_embedding': True,\n",
            "                                   'num_train_samples': -1,\n",
            "                                   'temperature': 0.07,\n",
            "                                   'update_mem_with_emb_index': -100},\n",
            "          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                     'embedding_dim': 128,\n",
            "                                                     'world_size': 64},\n",
            "                                   'temperature': 0.1},\n",
            "          'swav_loss': {'crops_for_assign': [0, 1],\n",
            "                        'embedding_dim': 128,\n",
            "                        'epsilon': 0.05,\n",
            "                        'normalize_last_layer': True,\n",
            "                        'num_crops': 2,\n",
            "                        'num_iters': 3,\n",
            "                        'num_prototypes': [3000],\n",
            "                        'output_dir': '.',\n",
            "                        'queue': {'local_queue_length': 0,\n",
            "                                  'queue_length': 0,\n",
            "                                  'start_iter': 0},\n",
            "                        'temp_hard_assignment_iters': 0,\n",
            "                        'temperature': 0.1,\n",
            "                        'use_double_precision': False},\n",
            "          'swav_momentum_loss': {'crops_for_assign': [0, 1],\n",
            "                                 'embedding_dim': 128,\n",
            "                                 'epsilon': 0.05,\n",
            "                                 'momentum': 0.99,\n",
            "                                 'momentum_eval_mode_iter_start': 0,\n",
            "                                 'normalize_last_layer': True,\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_iters': 3,\n",
            "                                 'num_prototypes': [3000],\n",
            "                                 'queue': {'local_queue_length': 0,\n",
            "                                           'queue_length': 0,\n",
            "                                           'start_iter': 0},\n",
            "                                 'temperature': 0.1,\n",
            "                                 'use_double_precision': False}},\n",
            " 'MACHINE': {'DEVICE': 'gpu'},\n",
            " 'METERS': {'accuracy_list_meter': {'meter_names': ['res5', 'res5avg'],\n",
            "                                    'num_meters': 2,\n",
            "                                    'topk_values': [1, 5]},\n",
            "            'enable_training_meter': True,\n",
            "            'mean_ap_list_meter': {'max_cpu_capacity': -1,\n",
            "                                   'meter_names': [],\n",
            "                                   'num_classes': 9605,\n",
            "                                   'num_meters': 1},\n",
            "            'name': 'accuracy_list_meter'},\n",
            " 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,\n",
            "                                        'USE_ACTIVATION_CHECKPOINTING': False},\n",
            "           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'},\n",
            "                          'AMP_TYPE': 'apex',\n",
            "                          'USE_AMP': False},\n",
            "           'CUDA_CACHE': {'CLEAR_CUDA_CACHE': False, 'CLEAR_FREQ': 100},\n",
            "           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': True,\n",
            "                                     'EVAL_TRUNK_AND_HEAD': False,\n",
            "                                     'EXTRACT_TRUNK_FEATURES_ONLY': False,\n",
            "                                     'FREEZE_TRUNK_AND_HEAD': False,\n",
            "                                     'FREEZE_TRUNK_ONLY': True,\n",
            "                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [['res5',\n",
            "                                                                        ['AvgPool2d',\n",
            "                                                                         [[6,\n",
            "                                                                           6],\n",
            "                                                                          1,\n",
            "                                                                          0]]],\n",
            "                                                                       ['res5avg',\n",
            "                                                                        ['Identity',\n",
            "                                                                         []]]],\n",
            "                                     'SHOULD_FLATTEN_FEATS': False},\n",
            "           'FSDP_CONFIG': {'AUTO_WRAP_THRESHOLD': 0,\n",
            "                           'bucket_cap_mb': 0,\n",
            "                           'clear_autocast_cache': True,\n",
            "                           'compute_dtype': torch.float32,\n",
            "                           'flatten_parameters': True,\n",
            "                           'fp32_reduce_scatter': False,\n",
            "                           'mixed_precision': True,\n",
            "                           'verbose': True},\n",
            "           'GRAD_CLIP': {'MAX_NORM': 1, 'NORM_TYPE': 2, 'USE_GRAD_CLIP': False},\n",
            "           'HEAD': {'BATCHNORM_EPS': 1e-05,\n",
            "                    'BATCHNORM_MOMENTUM': 0.1,\n",
            "                    'PARAMS': [['eval_mlp',\n",
            "                                {'dims': [8192, 1000], 'in_channels': 2048}],\n",
            "                               ['eval_mlp',\n",
            "                                {'dims': [2048, 1000], 'in_channels': 2048}]],\n",
            "                    'PARAMS_MULTIPLIER': 100.0},\n",
            "           'INPUT_TYPE': 'rgb',\n",
            "           'MULTI_INPUT_HEAD_MAPPING': [],\n",
            "           'NON_TRAINABLE_PARAMS': [],\n",
            "           'SHARDED_DDP_SETUP': {'USE_SDP': False, 'reduce_buffer_size': -1},\n",
            "           'SINGLE_PASS_EVERY_CROP': False,\n",
            "           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': True,\n",
            "                              'GROUP_SIZE': 0,\n",
            "                              'SYNC_BN_TYPE': 'pytorch'},\n",
            "           'TEMP_FROZEN_PARAMS_ITER_MAP': [],\n",
            "           'TRUNK': {'CONVIT': {'CLASS_TOKEN_IN_LOCAL_LAYERS': False,\n",
            "                                'LOCALITY_DIM': 10,\n",
            "                                'LOCALITY_STRENGTH': 1.0,\n",
            "                                'N_GPSA_LAYERS': 10,\n",
            "                                'USE_LOCAL_INIT': True},\n",
            "                     'EFFICIENT_NETS': {},\n",
            "                     'NAME': 'resnet',\n",
            "                     'REGNET': {},\n",
            "                     'RESNETS': {'DEPTH': 50,\n",
            "                                 'GROUPNORM_GROUPS': 32,\n",
            "                                 'GROUPS': 1,\n",
            "                                 'LAYER4_STRIDE': 2,\n",
            "                                 'NORM': 'BatchNorm',\n",
            "                                 'STANDARDIZE_CONVOLUTIONS': False,\n",
            "                                 'WIDTH_MULTIPLIER': 1,\n",
            "                                 'WIDTH_PER_GROUP': 64,\n",
            "                                 'ZERO_INIT_RESIDUAL': False},\n",
            "                     'VISION_TRANSFORMERS': {'ATTENTION_DROPOUT_RATE': 0,\n",
            "                                             'CLASSIFIER': 'token',\n",
            "                                             'DROPOUT_RATE': 0,\n",
            "                                             'DROP_PATH_RATE': 0,\n",
            "                                             'HIDDEN_DIM': 768,\n",
            "                                             'IMAGE_SIZE': 224,\n",
            "                                             'MLP_DIM': 3072,\n",
            "                                             'NUM_HEADS': 12,\n",
            "                                             'NUM_LAYERS': 12,\n",
            "                                             'PATCH_SIZE': 16,\n",
            "                                             'QKV_BIAS': False,\n",
            "                                             'QK_SCALE': False,\n",
            "                                             'name': None},\n",
            "                     'XCIT': {'ATTENTION_DROPOUT_RATE': 0,\n",
            "                              'DROPOUT_RATE': 0,\n",
            "                              'DROP_PATH_RATE': 0.05,\n",
            "                              'ETA': 1,\n",
            "                              'HIDDEN_DIM': 384,\n",
            "                              'IMAGE_SIZE': 224,\n",
            "                              'NUM_HEADS': 8,\n",
            "                              'NUM_LAYERS': 12,\n",
            "                              'PATCH_SIZE': 16,\n",
            "                              'QKV_BIAS': True,\n",
            "                              'QK_SCALE': False,\n",
            "                              'TOKENS_NORM': True,\n",
            "                              'name': None}},\n",
            "           'WEIGHTS_INIT': {'APPEND_PREFIX': 'trunk.base_model._feature_blocks.',\n",
            "                            'PARAMS_FILE': '/content/resnet50-19c8e357.pth',\n",
            "                            'REMOVE_PREFIX': '',\n",
            "                            'SKIP_LAYERS': ['num_batches_tracked'],\n",
            "                            'STATE_DICT_KEY_NAME': ''},\n",
            "           '_MODEL_INIT_SEED': 1},\n",
            " 'MONITORING': {'MONITOR_ACTIVATION_STATISTICS': 0},\n",
            " 'MULTI_PROCESSING_METHOD': 'forkserver',\n",
            " 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},\n",
            " 'OPTIMIZER': {'betas': [0.9, 0.999],\n",
            "               'construct_single_param_group_only': False,\n",
            "               'head_optimizer_params': {'use_different_lr': True,\n",
            "                                         'use_different_wd': True,\n",
            "                                         'weight_decay': 0.0001},\n",
            "               'larc_config': {'clip': False,\n",
            "                               'eps': 1e-08,\n",
            "                               'trust_coefficient': 0.001},\n",
            "               'momentum': 0.9,\n",
            "               'name': 'sgd',\n",
            "               'nesterov': True,\n",
            "               'non_regularized_parameters': [],\n",
            "               'num_epochs': 2,\n",
            "               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': False,\n",
            "                                                               'base_lr_batch_size': 256,\n",
            "                                                               'base_value': 0.1,\n",
            "                                                               'scaling_type': 'linear'},\n",
            "                                           'end_value': 0.0,\n",
            "                                           'interval_scaling': [],\n",
            "                                           'lengths': [],\n",
            "                                           'milestones': [1],\n",
            "                                           'name': 'multistep',\n",
            "                                           'schedulers': [],\n",
            "                                           'start_value': 0.1,\n",
            "                                           'update_interval': 'epoch',\n",
            "                                           'value': 0.1,\n",
            "                                           'values': [0.01, 0.001]},\n",
            "                                    'lr_head': {'auto_lr_scaling': {'auto_scale': False,\n",
            "                                                                    'base_lr_batch_size': 256,\n",
            "                                                                    'base_value': 0.1,\n",
            "                                                                    'scaling_type': 'linear'},\n",
            "                                                'end_value': 0.0,\n",
            "                                                'interval_scaling': [],\n",
            "                                                'lengths': [],\n",
            "                                                'milestones': [1],\n",
            "                                                'name': 'multistep',\n",
            "                                                'schedulers': [],\n",
            "                                                'start_value': 0.1,\n",
            "                                                'update_interval': 'epoch',\n",
            "                                                'value': 0.1,\n",
            "                                                'values': [0.2, 0.02]}},\n",
            "               'regularize_bias': True,\n",
            "               'regularize_bn': False,\n",
            "               'use_larc': False,\n",
            "               'use_zero': False,\n",
            "               'weight_decay': 0.0005},\n",
            " 'PROFILING': {'MEMORY_PROFILING': {'TRACK_BY_LAYER_MEMORY': False},\n",
            "               'NUM_ITERATIONS': 10,\n",
            "               'OUTPUT_FOLDER': '.',\n",
            "               'PROFILED_RANKS': [0, 1],\n",
            "               'RUNTIME_PROFILING': {'LEGACY_PROFILER': False,\n",
            "                                     'PROFILE_CPU': True,\n",
            "                                     'PROFILE_GPU': True,\n",
            "                                     'USE_PROFILER': False},\n",
            "               'START_ITERATION': 0,\n",
            "               'STOP_TRAINING_AFTER_PROFILING': False,\n",
            "               'WARMUP_ITERATIONS': 0},\n",
            " 'REPRODUCIBILITY': {'CUDDN_DETERMINISTIC': False},\n",
            " 'SEED_VALUE': 1,\n",
            " 'SLURM': {'ADDITIONAL_PARAMETERS': {},\n",
            "           'COMMENT': 'vissl job',\n",
            "           'CONSTRAINT': '',\n",
            "           'LOG_FOLDER': '.',\n",
            "           'MEM_GB': 250,\n",
            "           'NAME': 'vissl',\n",
            "           'NUM_CPU_PER_PROC': 8,\n",
            "           'PARTITION': '',\n",
            "           'PORT_ID': 40050,\n",
            "           'TIME_HOURS': 72,\n",
            "           'TIME_MINUTES': 0,\n",
            "           'USE_SLURM': False},\n",
            " 'SVM': {'cls_list': [],\n",
            "         'costs': {'base': -1.0,\n",
            "                   'costs_list': [0.1, 0.01],\n",
            "                   'power_range': [4, 20]},\n",
            "         'cross_val_folds': 3,\n",
            "         'dual': True,\n",
            "         'force_retrain': False,\n",
            "         'loss': 'squared_hinge',\n",
            "         'low_shot': {'dataset_name': 'voc',\n",
            "                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],\n",
            "                      'sample_inds': [1, 2, 3, 4, 5]},\n",
            "         'max_iter': 2000,\n",
            "         'normalize': True,\n",
            "         'penalty': 'l2'},\n",
            " 'TEST_EVERY_NUM_EPOCH': 2,\n",
            " 'TEST_MODEL': True,\n",
            " 'TEST_ONLY': False,\n",
            " 'TRAINER': {'TASK_NAME': 'self_supervision_task',\n",
            "             'TRAIN_STEP_NAME': 'standard_train_step'},\n",
            " 'VERBOSE': True}\n",
            "INFO 2021-10-18 00:39:54,281 train.py: 117: System config:\n",
            "-------------------  ---------------------------------------------------------------\n",
            "sys.platform         linux\n",
            "Python               3.7.12 (default, Sep 10 2021, 00:21:48) [GCC 7.5.0]\n",
            "numpy                1.19.5\n",
            "Pillow               7.1.2\n",
            "vissl                0.1.6 @/content/vissl/vissl\n",
            "GPU available        True\n",
            "GPU 0                Tesla K80\n",
            "CUDA_HOME            /usr/local/cuda\n",
            "torchvision          0.9.0+cu101 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "hydra                1.0.7 @/usr/local/lib/python3.7/dist-packages/hydra\n",
            "classy_vision        0.7.0.dev @/usr/local/lib/python3.7/dist-packages/classy_vision\n",
            "tensorboard          2.6.0\n",
            "apex                 0.1 @/usr/local/lib/python3.7/dist-packages/apex\n",
            "cv2                  4.1.2\n",
            "PyTorch              1.8.0+cu101 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build  False\n",
            "-------------------  ---------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 10.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.1, CUDNN_VERSION=7.6.3, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
            "\n",
            "CPU info:\n",
            "-------------------  ------------------------------\n",
            "Architecture         x86_64\n",
            "CPU op-mode(s)       32-bit, 64-bit\n",
            "Byte Order           Little Endian\n",
            "CPU(s)               2\n",
            "On-line CPU(s) list  0,1\n",
            "Thread(s) per core   2\n",
            "Core(s) per socket   1\n",
            "Socket(s)            1\n",
            "NUMA node(s)         1\n",
            "Vendor ID            GenuineIntel\n",
            "CPU family           6\n",
            "Model                63\n",
            "Model name           Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "Stepping             0\n",
            "CPU MHz              2300.000\n",
            "BogoMIPS             4600.00\n",
            "Hypervisor vendor    KVM\n",
            "Virtualization type  full\n",
            "L1d cache            32K\n",
            "L1i cache            32K\n",
            "L2 cache             256K\n",
            "L3 cache             46080K\n",
            "NUMA node0 CPU(s)    0,1\n",
            "-------------------  ------------------------------\n",
            "INFO 2021-10-18 00:39:54,282 trainer_main.py: 113: Using Distributed init method: tcp://localhost:34881, world_size: 1, rank: 0\n",
            "INFO 2021-10-18 00:39:54,283 distributed_c10d.py: 187: Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "INFO 2021-10-18 00:39:54,284 trainer_main.py: 134: | initialized host 3df825104503 as rank 0 (0)\n",
            "INFO 2021-10-18 00:39:56,453 train_task.py: 181: Not using Automatic Mixed Precision\n",
            "INFO 2021-10-18 00:39:56,453 train_task.py: 449: Building model....\n",
            "INFO 2021-10-18 00:39:56,454 feature_extractor.py:  27: Creating Feature extractor trunk...\n",
            "INFO 2021-10-18 00:39:56,454 resnext.py:  68: ResNeXT trunk, supports activation checkpointing. Deactivated\n",
            "INFO 2021-10-18 00:39:56,454 resnext.py:  88: Building model: ResNeXt50-1x64d-w1-BatchNorm2d\n",
            "INFO 2021-10-18 00:39:57,215 feature_extractor.py:  50: Freezing model trunk...\n",
            "INFO 2021-10-18 00:39:57,300 model_helpers.py: 150: Using SyncBN group size: None\n",
            "INFO 2021-10-18 00:39:57,300 model_helpers.py: 165: Converting BN layers to PyTorch SyncBN\n",
            "INFO 2021-10-18 00:39:57,300 model_helpers.py: 168: Not creating process_group for PyTorch SyncBN...\n",
            "INFO 2021-10-18 00:39:57,310 train_task.py: 467: config.MODEL.FEATURE_EVAL_SETTINGS.FREEZE_TRUNK_ONLY=True, will freeze trunk...\n",
            "INFO 2021-10-18 00:39:57,310 base_ssl_model.py: 194: Freezing model trunk...\n",
            "INFO 2021-10-18 00:39:57,311 train_task.py: 423: Initializing model from: /content/resnet50-19c8e357.pth\n",
            "INFO 2021-10-18 00:39:57,311 util.py: 276: Attempting to load checkpoint from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-10-18 00:39:57,521 util.py: 281: Loaded checkpoint from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-10-18 00:39:57,522 util.py: 240: Broadcasting checkpoint loaded from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-10-18 00:40:01,237 train_task.py: 429: Checkpoint loaded: /content/resnet50-19c8e357.pth...\n",
            "INFO 2021-10-18 00:40:01,239 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,240 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,240 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,240 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,240 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,240 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,240 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,241 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,241 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,241 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,241 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,241 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,241 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,242 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,242 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,242 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,242 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,242 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,242 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,242 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,243 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,243 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,243 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,243 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,243 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,243 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,244 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,244 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,244 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,244 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,244 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,244 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,245 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,245 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,245 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,245 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,245 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,245 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,245 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,246 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,246 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,246 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,246 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,246 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,246 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,247 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,247 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,247 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,247 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,247 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,247 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,247 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,248 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,248 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,248 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,248 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,248 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,248 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,249 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,249 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,249 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,249 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,249 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,249 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,250 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,250 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,250 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,250 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,250 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,250 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,251 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,251 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,251 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,251 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,251 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,251 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,252 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,252 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,252 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,252 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,252 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,252 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,253 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,253 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,253 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,253 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,253 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,253 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,254 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,254 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,254 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,254 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,254 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,254 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,255 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,255 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,255 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,255 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,261 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,261 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,262 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,262 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,263 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,263 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,263 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,263 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,263 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,263 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,264 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,264 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,264 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,264 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,264 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,264 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,265 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,265 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,265 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,265 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,265 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,265 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,266 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,266 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,266 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,266 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,266 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,267 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,267 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,267 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,267 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,267 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,267 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,268 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.3.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,268 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,268 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,268 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,268 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,268 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,269 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.3.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,269 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,269 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,269 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,269 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,269 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,270 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.3.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,270 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,270 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,270 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,270 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,270 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,270 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,271 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,271 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,271 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,271 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,272 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,272 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,272 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,272 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,272 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,273 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,273 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,273 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,274 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,274 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,274 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,274 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,274 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,274 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,275 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,275 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,275 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,275 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,275 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,275 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,276 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,276 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,276 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,276 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,277 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,277 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,277 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,277 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,277 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,278 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,278 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,278 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,278 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,278 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,279 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,279 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,279 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,279 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,279 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,280 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,280 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,280 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,280 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,280 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,281 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,281 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,281 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,363 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,364 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,364 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,366 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,366 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,366 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,366 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,366 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,367 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.3.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,367 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,367 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,368 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,368 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,368 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,368 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.3.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,368 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,369 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,369 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,369 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,369 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,369 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.3.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,370 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,370 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,370 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,370 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,370 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,370 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.4.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,371 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,371 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,371 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,372 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,372 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,372 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.4.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,372 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,372 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,373 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,373 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,373 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,373 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.4.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,373 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,374 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,374 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,374 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,374 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,374 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.5.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,375 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,375 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,375 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,375 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,375 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,375 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.5.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,376 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,376 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,376 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,376 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,377 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,377 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.5.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,377 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,377 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,378 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,378 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,378 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,378 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,380 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,380 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,380 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,381 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,381 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,381 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,382 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,382 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,382 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,382 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,383 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,383 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,385 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,385 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,385 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,385 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,385 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,385 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,386 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,386 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,387 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,387 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,387 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,387 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,389 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,389 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,389 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,389 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,390 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,390 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,391 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,391 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,391 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,391 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,391 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,391 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,393 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,393 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,393 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,393 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,468 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,468 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,471 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,471 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,472 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,472 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,472 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,472 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,473 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,474 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,474 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,474 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,474 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-18 00:40:01,474 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,475 checkpoint.py: 894: Not found:\t\theads.0.channel_bn.weight, not initialized\n",
            "INFO 2021-10-18 00:40:01,475 checkpoint.py: 894: Not found:\t\theads.0.channel_bn.bias, not initialized\n",
            "INFO 2021-10-18 00:40:01,475 checkpoint.py: 894: Not found:\t\theads.0.channel_bn.running_mean, not initialized\n",
            "INFO 2021-10-18 00:40:01,475 checkpoint.py: 894: Not found:\t\theads.0.channel_bn.running_var, not initialized\n",
            "INFO 2021-10-18 00:40:01,475 checkpoint.py: 851: Ignored layer:\theads.0.channel_bn.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,475 checkpoint.py: 894: Not found:\t\theads.0.clf.clf.0.weight, not initialized\n",
            "INFO 2021-10-18 00:40:01,476 checkpoint.py: 894: Not found:\t\theads.0.clf.clf.0.bias, not initialized\n",
            "INFO 2021-10-18 00:40:01,476 checkpoint.py: 894: Not found:\t\theads.1.channel_bn.weight, not initialized\n",
            "INFO 2021-10-18 00:40:01,476 checkpoint.py: 894: Not found:\t\theads.1.channel_bn.bias, not initialized\n",
            "INFO 2021-10-18 00:40:01,476 checkpoint.py: 894: Not found:\t\theads.1.channel_bn.running_mean, not initialized\n",
            "INFO 2021-10-18 00:40:01,477 checkpoint.py: 894: Not found:\t\theads.1.channel_bn.running_var, not initialized\n",
            "INFO 2021-10-18 00:40:01,477 checkpoint.py: 851: Ignored layer:\theads.1.channel_bn.num_batches_tracked\n",
            "INFO 2021-10-18 00:40:01,477 checkpoint.py: 894: Not found:\t\theads.1.clf.clf.0.weight, not initialized\n",
            "INFO 2021-10-18 00:40:01,477 checkpoint.py: 894: Not found:\t\theads.1.clf.clf.0.bias, not initialized\n",
            "INFO 2021-10-18 00:40:01,477 checkpoint.py: 901: Extra layers not loaded from checkpoint: ['trunk.base_model._feature_blocks.fc.weight', 'trunk.base_model._feature_blocks.fc.bias', 'trunk.base_model._feature_blocks.type']\n",
            "INFO 2021-10-18 00:40:01,493 train_task.py: 651: Broadcast model BN buffers from primary on every forward pass\n",
            "INFO 2021-10-18 00:40:01,494 classification_task.py: 387: Synchronized Batch Normalization is disabled\n",
            "INFO 2021-10-18 00:40:01,542 optimizer_helper.py: 294: \n",
            "Trainable params: 8, \n",
            "Non-Trainable params: 0, \n",
            "Trunk Regularized Parameters: 0, \n",
            "Trunk Unregularized Parameters 0, \n",
            "Head Regularized Parameters: 4, \n",
            "Head Unregularized Parameters: 4 \n",
            "Remaining Regularized Parameters: 0 \n",
            "Remaining Unregularized Parameters: 0\n",
            "INFO 2021-10-18 00:40:01,543 ssl_dataset.py: 157: Rank: 0 split: TEST Data files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-10-18 00:40:01,543 ssl_dataset.py: 160: Rank: 0 split: TEST Label files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-10-18 00:40:01,543 disk_dataset.py:  86: Loaded 10 samples from folder /content/dummy_data/val\n",
            "INFO 2021-10-18 00:40:01,544 ssl_dataset.py: 157: Rank: 0 split: TRAIN Data files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-10-18 00:40:01,544 ssl_dataset.py: 160: Rank: 0 split: TRAIN Label files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-10-18 00:40:01,544 disk_dataset.py:  86: Loaded 10 samples from folder /content/dummy_data/train\n",
            "INFO 2021-10-18 00:40:01,545 misc.py: 161: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-10-18 00:40:01,545 __init__.py: 126: Created the Distributed Sampler....\n",
            "INFO 2021-10-18 00:40:01,545 __init__.py: 101: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "INFO 2021-10-18 00:40:01,545 __init__.py: 215: Wrapping the dataloader to async device copies\n",
            "INFO 2021-10-18 00:40:01,545 misc.py: 161: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-10-18 00:40:01,546 __init__.py: 126: Created the Distributed Sampler....\n",
            "INFO 2021-10-18 00:40:01,546 __init__.py: 101: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "INFO 2021-10-18 00:40:01,546 __init__.py: 215: Wrapping the dataloader to async device copies\n",
            "INFO 2021-10-18 00:40:01,546 train_task.py: 384: Building loss...\n",
            "INFO 2021-10-18 00:40:01,547 trainer_main.py: 268: Training 2 epochs\n",
            "INFO 2021-10-18 00:40:01,547 trainer_main.py: 269: One epoch = 5 iterations.\n",
            "INFO 2021-10-18 00:40:01,547 trainer_main.py: 270: Total 10 samples in one epoch\n",
            "INFO 2021-10-18 00:40:01,547 trainer_main.py: 276: Total 10 iterations for training\n",
            "INFO 2021-10-18 00:40:01,646 logger.py:  84: Mon Oct 18 00:40:01 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    55W / 149W |    594MiB / 11441MiB |      6%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "INFO 2021-10-18 00:40:01,648 trainer_main.py: 173: Model is:\n",
            " Classy <class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'>:\n",
            "BaseSSLMultiInputOutputModel(\n",
            "  (_heads): ModuleDict()\n",
            "  (trunk): FeatureExtractorModel(\n",
            "    (base_model): ResNeXt(\n",
            "      (_feature_blocks): ModuleDict(\n",
            "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv1_relu): ReLU(inplace=True)\n",
            "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "        (layer1): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (layer2): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (layer3): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (4): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (5): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (layer4): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), bias=False)\n",
            "              (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "        (flatten): Flatten()\n",
            "      )\n",
            "    )\n",
            "    (feature_pool_ops): ModuleList(\n",
            "      (0): AvgPool2d(kernel_size=[6, 6], stride=1, padding=0)\n",
            "      (1): Identity()\n",
            "    )\n",
            "  )\n",
            "  (heads): ModuleList(\n",
            "    (0): LinearEvalMLP(\n",
            "      (channel_bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (clf): MLP(\n",
            "        (clf): Sequential(\n",
            "          (0): Linear(in_features=8192, out_features=1000, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): LinearEvalMLP(\n",
            "      (channel_bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (clf): MLP(\n",
            "        (clf): Sequential(\n",
            "          (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "INFO 2021-10-18 00:40:01,668 trainer_main.py: 174: Loss is: CrossEntropyMultipleOutputSingleTargetLoss(\n",
            "  (criterion): CrossEntropyMultipleOutputSingleTargetCriterion(\n",
            "    (_losses): ModuleList()\n",
            "  )\n",
            ")\n",
            "INFO 2021-10-18 00:40:01,669 trainer_main.py: 175: Starting training....\n",
            "INFO 2021-10-18 00:40:01,669 __init__.py: 101: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-10-18 00:40:04,170 trainer_main.py: 333: Phase advanced. Rank: 0\n",
            "INFO 2021-10-18 00:40:04,172 log_hooks.py:  77: ========= Memory Summary at on_phase_start =======\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |  134088 KB |  134088 KB |  134088 KB |     512 B  |\n",
            "|       from large pool |  116184 KB |  116184 KB |  116184 KB |       0 B  |\n",
            "|       from small pool |   17904 KB |   17904 KB |   17904 KB |     512 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |  134088 KB |  134088 KB |  134088 KB |     512 B  |\n",
            "|       from large pool |  116184 KB |  116184 KB |  116184 KB |       0 B  |\n",
            "|       from small pool |   17904 KB |   17904 KB |   17904 KB |     512 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |  176128 KB |  176128 KB |  176128 KB |       0 B  |\n",
            "|       from large pool |  155648 KB |  155648 KB |  155648 KB |       0 B  |\n",
            "|       from small pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |   42040 KB |   42041 KB |  109570 KB |   67530 KB |\n",
            "|       from large pool |   39464 KB |   39464 KB |   93800 KB |   54336 KB |\n",
            "|       from small pool |    2576 KB |    2577 KB |   15770 KB |   13194 KB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     336    |     336    |     337    |       1    |\n",
            "|       from large pool |      20    |      20    |      20    |       0    |\n",
            "|       from small pool |     316    |     316    |     317    |       1    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     336    |     336    |     337    |       1    |\n",
            "|       from large pool |      20    |      20    |      20    |       0    |\n",
            "|       from small pool |     316    |     316    |     317    |       1    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      17    |      17    |      17    |       0    |\n",
            "|       from large pool |       7    |       7    |       7    |       0    |\n",
            "|       from small pool |      10    |      10    |      10    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       9    |       9    |      17    |       8    |\n",
            "|       from large pool |       6    |       6    |       6    |       0    |\n",
            "|       from small pool |       3    |       5    |      11    |       8    |\n",
            "|===========================================================================|\n",
            "\n",
            "\n",
            "INFO 2021-10-18 00:40:04,172 state_update_hooks.py: 113: Starting phase 0 [train]\n",
            "INFO 2021-10-18 00:40:05,491 log_hooks.py:  77: ========= Memory Summary at on_forward =======\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |  135473 KB |    2452 MB |   14906 MB |   14773 MB |\n",
            "|       from large pool |  117360 KB |    2434 MB |   14855 MB |   14741 MB |\n",
            "|       from small pool |   18113 KB |      19 MB |      50 MB |      32 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |  135473 KB |    2452 MB |   14906 MB |   14773 MB |\n",
            "|       from large pool |  117360 KB |    2434 MB |   14855 MB |   14741 MB |\n",
            "|       from small pool |   18113 KB |      19 MB |      50 MB |      32 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |    2494 MB |    3646 MB |   11644 MB |    9150 MB |\n",
            "|       from large pool |    2470 MB |    3624 MB |   11612 MB |    9142 MB |\n",
            "|       from small pool |      24 MB |      24 MB |      32 MB |       8 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |   40654 KB |    1260 MB |    4009 MB |    3970 MB |\n",
            "|       from large pool |   38288 KB |    1257 MB |    3943 MB |    3906 MB |\n",
            "|       from small pool |    2366 KB |       4 MB |      65 MB |      63 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     350    |     350    |     522    |     172    |\n",
            "|       from large pool |      21    |      25    |     106    |      85    |\n",
            "|       from small pool |     329    |     329    |     416    |      87    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     350    |     350    |     522    |     172    |\n",
            "|       from large pool |      21    |      25    |     106    |      85    |\n",
            "|       from small pool |     329    |     329    |     416    |      87    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      20    |      20    |      36    |      16    |\n",
            "|       from large pool |       8    |      10    |      20    |      12    |\n",
            "|       from small pool |      12    |      12    |      16    |       4    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      10    |      13    |      96    |      86    |\n",
            "|       from large pool |       6    |       9    |      47    |      41    |\n",
            "|       from small pool |       4    |       6    |      49    |      45    |\n",
            "|===========================================================================|\n",
            "\n",
            "\n",
            "INFO 2021-10-18 00:40:05,498 log_hooks.py:  77: ========= Memory Summary at on_backward =======\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |  175706 KB |    2452 MB |   14945 MB |   14774 MB |\n",
            "|       from large pool |  157744 KB |    2434 MB |   14895 MB |   14741 MB |\n",
            "|       from small pool |   17962 KB |      19 MB |      50 MB |      33 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |  175706 KB |    2452 MB |   14945 MB |   14774 MB |\n",
            "|       from large pool |  157744 KB |    2434 MB |   14895 MB |   14741 MB |\n",
            "|       from small pool |   17962 KB |      19 MB |      50 MB |      33 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |    2494 MB |    3646 MB |   11644 MB |    9150 MB |\n",
            "|       from large pool |    2470 MB |    3624 MB |   11612 MB |    9142 MB |\n",
            "|       from small pool |      24 MB |      24 MB |      32 MB |       8 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    2318 MB |    2318 MB |    6296 MB |    3978 MB |\n",
            "|       from large pool |    2315 MB |    2315 MB |    6230 MB |    3914 MB |\n",
            "|       from small pool |       2 MB |       4 MB |      66 MB |      63 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     352    |     360    |     563    |     211    |\n",
            "|       from large pool |      23    |      25    |     108    |      85    |\n",
            "|       from small pool |     329    |     339    |     455    |     126    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     352    |     360    |     563    |     211    |\n",
            "|       from large pool |      23    |      25    |     108    |      85    |\n",
            "|       from small pool |     329    |     339    |     455    |     126    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      20    |      20    |      36    |      16    |\n",
            "|       from large pool |       8    |      10    |      20    |      12    |\n",
            "|       from small pool |      12    |      12    |      16    |       4    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      13    |      14    |     116    |     103    |\n",
            "|       from large pool |       6    |       9    |      48    |      42    |\n",
            "|       from small pool |       7    |       8    |      68    |      61    |\n",
            "|===========================================================================|\n",
            "\n",
            "\n",
            "INFO 2021-10-18 00:40:05,499 log_hooks.py:  77: ========= Memory Summary at on_update =======\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |  215746 KB |    2452 MB |   15063 MB |   14852 MB |\n",
            "|       from large pool |  197744 KB |    2434 MB |   15012 MB |   14819 MB |\n",
            "|       from small pool |   18002 KB |      19 MB |      50 MB |      33 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |  215746 KB |    2452 MB |   15063 MB |   14852 MB |\n",
            "|       from large pool |  197744 KB |    2434 MB |   15012 MB |   14819 MB |\n",
            "|       from small pool |   18002 KB |      19 MB |      50 MB |      33 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |    2494 MB |    3646 MB |   11644 MB |    9150 MB |\n",
            "|       from large pool |    2470 MB |    3624 MB |   11612 MB |    9142 MB |\n",
            "|       from small pool |      24 MB |      24 MB |      32 MB |       8 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |    2279 MB |    2318 MB |    6375 MB |    4095 MB |\n",
            "|       from large pool |    2276 MB |    2315 MB |    6308 MB |    4031 MB |\n",
            "|       from small pool |       2 MB |       4 MB |      66 MB |      63 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     360    |     361    |     583    |     223    |\n",
            "|       from large pool |      25    |      27    |     114    |      89    |\n",
            "|       from small pool |     335    |     339    |     469    |     134    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     360    |     361    |     583    |     223    |\n",
            "|       from large pool |      25    |      27    |     114    |      89    |\n",
            "|       from small pool |     335    |     339    |     469    |     134    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      20    |      20    |      36    |      16    |\n",
            "|       from large pool |       8    |      10    |      20    |      12    |\n",
            "|       from small pool |      12    |      12    |      16    |       4    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      16    |      16    |     121    |     105    |\n",
            "|       from large pool |       8    |       9    |      50    |      42    |\n",
            "|       from small pool |       8    |       8    |      71    |      63    |\n",
            "|===========================================================================|\n",
            "\n",
            "\n",
            "INFO 2021-10-18 00:40:05,502 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 0; lr: [0.01, 0.2]; loss: 383.99719; btime(ms): 0; eta: 0:00:00; peak_mem(M): 2452;\n",
            "INFO 2021-10-18 00:40:05,533 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 1; lr: [0.01, 0.2]; loss: 3232.49121; btime(ms): 3955; eta: 0:00:35; peak_mem(M): 2452; max_iterations: 10;\n",
            "INFO 2021-10-18 00:40:05,632 trainer_main.py: 214: Meters synced\n",
            "INFO 2021-10-18 00:40:05,637 log_hooks.py: 568: Average train batch time (ms) for 5 batches: 293\n",
            "INFO 2021-10-18 00:40:05,637 log_hooks.py: 577: Train step time breakdown (rank 0):\n",
            "               Timer     Host    CudaEvent\n",
            "         read_sample:    3.36 ms    2.38 ms\n",
            "             forward:  271.70 ms  280.79 ms\n",
            "        loss_compute:    0.90 ms    0.90 ms\n",
            "     loss_all_reduce:    0.09 ms    0.10 ms\n",
            "       meters_update:    0.66 ms    0.67 ms\n",
            "            backward:    1.24 ms    3.28 ms\n",
            "      optimizer_step:    0.75 ms    3.58 ms\n",
            "    train_step_total:  291.84 ms  292.87 ms\n",
            "INFO 2021-10-18 00:40:05,638 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 30.0, 'res5avg': 30.0}, 'top_5': {'res5': 60.0, 'res5avg': 60.0}}\n",
            "INFO 2021-10-18 00:40:05,638 io.py:  63: Saving data to file: /content/checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-10-18 00:40:05,638 io.py:  89: Saved data to file: /content/checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-10-18 00:40:05,638 log_hooks.py: 426: [phase: 0] Saving checkpoint to /content/checkpoints_trunk_eval\n",
            "INFO 2021-10-18 00:40:06,119 checkpoint.py: 131: Saved checkpoint: /content/checkpoints_trunk_eval/model_phase0.torch\n",
            "INFO 2021-10-18 00:40:06,119 checkpoint.py: 140: Creating symlink...\n",
            "INFO 2021-10-18 00:40:06,120 checkpoint.py: 144: Created symlink: /content/checkpoints_trunk_eval/checkpoint.torch\n",
            "INFO 2021-10-18 00:40:06,120 __init__.py: 101: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 1, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-10-18 00:40:08,460 trainer_main.py: 333: Phase advanced. Rank: 0\n",
            "INFO 2021-10-18 00:40:08,460 state_update_hooks.py: 113: Starting phase 1 [test]\n",
            "INFO 2021-10-18 00:40:08,721 trainer_main.py: 214: Meters synced\n",
            "INFO 2021-10-18 00:40:08,722 log_hooks.py: 568: Average test batch time (ms) for 5 batches: 52\n",
            "INFO 2021-10-18 00:40:08,722 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 50.0, 'res5avg': 50.0}, 'top_5': {'res5': 100.0, 'res5avg': 100.0}}\n",
            "INFO 2021-10-18 00:40:08,722 io.py:  63: Saving data to file: /content/checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-10-18 00:40:08,722 io.py:  89: Saved data to file: /content/checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-10-18 00:40:08,723 __init__.py: 101: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 2, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-10-18 00:40:11,072 trainer_main.py: 333: Phase advanced. Rank: 0\n",
            "INFO 2021-10-18 00:40:11,072 state_update_hooks.py: 113: Starting phase 2 [train]\n",
            "INFO 2021-10-18 00:40:11,120 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 5; lr: [0.001, 0.02]; loss: 3307.89722; btime(ms): 717; eta: 0:00:03; peak_mem(M): 2452;\n",
            "INFO 2021-10-18 00:40:11,272 trainer_main.py: 214: Meters synced\n",
            "INFO 2021-10-18 00:40:11,277 log_hooks.py: 568: Average train batch time (ms) for 5 batches: 40\n",
            "INFO 2021-10-18 00:40:11,277 log_hooks.py: 577: Train step time breakdown (rank 0):\n",
            "               Timer     Host    CudaEvent\n",
            "         read_sample:    5.14 ms    3.47 ms\n",
            "             forward:   18.51 ms   26.19 ms\n",
            "        loss_compute:    0.85 ms    0.85 ms\n",
            "     loss_all_reduce:    0.11 ms    0.12 ms\n",
            "       meters_update:    0.84 ms    0.86 ms\n",
            "            backward:    2.67 ms    4.32 ms\n",
            "      optimizer_step:    1.53 ms    3.96 ms\n",
            "    train_step_total:   39.76 ms   40.85 ms\n",
            "INFO 2021-10-18 00:40:11,278 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 30.0, 'res5avg': 40.0}, 'top_5': {'res5': 50.0, 'res5avg': 100.0}}\n",
            "INFO 2021-10-18 00:40:11,278 io.py:  63: Saving data to file: /content/checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-10-18 00:40:11,278 io.py:  89: Saved data to file: /content/checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-10-18 00:40:11,278 log_hooks.py: 426: [phase: 1] Saving checkpoint to /content/checkpoints_trunk_eval\n",
            "INFO 2021-10-18 00:40:11,762 checkpoint.py: 131: Saved checkpoint: /content/checkpoints_trunk_eval/model_final_checkpoint_phase1.torch\n",
            "INFO 2021-10-18 00:40:11,762 checkpoint.py: 140: Creating symlink...\n",
            "INFO 2021-10-18 00:40:11,763 checkpoint.py: 144: Created symlink: /content/checkpoints_trunk_eval/checkpoint.torch\n",
            "INFO 2021-10-18 00:40:11,763 __init__.py: 101: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 3, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-10-18 00:40:14,160 trainer_main.py: 333: Phase advanced. Rank: 0\n",
            "INFO 2021-10-18 00:40:14,161 state_update_hooks.py: 113: Starting phase 3 [test]\n",
            "INFO 2021-10-18 00:40:14,377 trainer_main.py: 214: Meters synced\n",
            "INFO 2021-10-18 00:40:14,377 log_hooks.py: 568: Average test batch time (ms) for 5 batches: 43\n",
            "INFO 2021-10-18 00:40:14,377 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 50.0, 'res5avg': 50.0}, 'top_5': {'res5': 100.0, 'res5avg': 100.0}}\n",
            "INFO 2021-10-18 00:40:14,378 io.py:  63: Saving data to file: /content/checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-10-18 00:40:14,378 io.py:  89: Saved data to file: /content/checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-10-18 00:40:14,467 train.py: 131: All Done!\n",
            "INFO 2021-10-18 00:40:14,468 logger.py:  73: Shutting down loggers...\n",
            "INFO 2021-10-18 00:40:14,469 distributed_launcher.py: 168: All Done!\n",
            "INFO 2021-10-18 00:40:14,469 logger.py:  73: Shutting down loggers...\n"
          ]
        }
      ],
      "source": [
        "!python3 tools/run_distributed_engines.py \\\n",
        "    hydra.verbose=true \\\n",
        "    config=test/integration_test/quick_eval_in1k_linear_imagefolder.yaml \\\n",
        "    config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DATA.TRAIN.DATA_LIMIT=-1 \\\n",
        "    config.DATA.TEST.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TEST.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DATA.TEST.DATA_LIMIT=-1 \\\n",
        "    config.DISTRIBUTED.NUM_NODES=1 \\\n",
        "    config.DISTRIBUTED.NUM_PROC_PER_NODE=1 \\\n",
        "    config.CHECKPOINT.DIR=\"/content/checkpoints_trunk_eval\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.PARAMS_FILE=\"/content/resnet50-19c8e357.pth\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=\"trunk.base_model._feature_blocks.\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvUJcklKyI5F"
      },
      "source": [
        "And we are done!! We have the linear classifier trained on the trunk features `res5` and `res5avg` and the `metrics.json` containing the `top-1` and `top-5` accuracy for each feature in `checkpoints_trunk_eval/metrics.json`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpQ1__UqyQgj",
        "outputId": "caac81fc-2ca3-48b3-95d5-4436a11a8b7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;36mcheckpoint.torch\u001b[0m@  model_final_checkpoint_phase1.torch  train_config.yaml\n",
            "log.txt            model_phase0.torch\n",
            "metrics.json       stdout.json\n"
          ]
        }
      ],
      "source": [
        "ls /content/checkpoints_trunk_eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsvStuaWySlY",
        "outputId": "b200dffb-7110-4aaa-9850-c1577a06eecb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"iteration\": 5, \"phase_idx\": 0, \"train_accuracy_list_meter\": {\"top_1\": {\"res5\": 30.0, \"res5avg\": 30.0}, \"top_5\": {\"res5\": 60.0, \"res5avg\": 60.0}}, \"train_phase_idx\": 0}\n",
            "{\"iteration\": 5, \"phase_idx\": 1, \"test_accuracy_list_meter\": {\"top_1\": {\"res5\": 50.0, \"res5avg\": 50.0}, \"top_5\": {\"res5\": 100.0, \"res5avg\": 100.0}}, \"train_phase_idx\": 0}\n",
            "{\"iteration\": 10, \"phase_idx\": 2, \"train_accuracy_list_meter\": {\"top_1\": {\"res5\": 30.0, \"res5avg\": 40.0}, \"top_5\": {\"res5\": 50.0, \"res5avg\": 100.0}}, \"train_phase_idx\": 1}\n",
            "{\"iteration\": 10, \"phase_idx\": 3, \"test_accuracy_list_meter\": {\"top_1\": {\"res5\": 50.0, \"res5avg\": 50.0}, \"top_5\": {\"res5\": 100.0, \"res5avg\": 100.0}}, \"train_phase_idx\": 1}\n"
          ]
        }
      ],
      "source": [
        "cat /content/checkpoints_trunk_eval/metrics.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xFUcTj00B_a"
      },
      "source": [
        "# Loading Pre-trained models in VISSL\n",
        "\n",
        "VISSL supports Torchvision models out of the box. Generally, for loading any non-VISSL model, one needs to correctly set the following configuration options:\n",
        "\n",
        "```yaml\n",
        "WEIGHTS_INIT:\n",
        "  # path to the .torch weights files\n",
        "  PARAMS_FILE: \"\"\n",
        "  # name of the state dict. checkpoint = {\"classy_state_dict\": {layername:value}}. Options:\n",
        "  #   1. classy_state_dict - if model is trained and checkpointed with VISSL.\n",
        "  #      checkpoint = {\"classy_state_dict\": {layername:value}}\n",
        "  #   2. \"\" - if the model_file is not a nested dictionary for model weights i.e.\n",
        "  #      checkpoint = {layername:value}\n",
        "  #   3. key name that your model checkpoint uses for state_dict key name.\n",
        "  #      checkpoint = {\"your_key_name\": {layername:value}}\n",
        "  STATE_DICT_KEY_NAME: \"classy_state_dict\"\n",
        "  # specify what layer should not be loaded. Layer names with this key are not copied\n",
        "  # By default, set to BatchNorm stats \"num_batches_tracked\" to be skipped.\n",
        "  SKIP_LAYERS: [\"num_batches_tracked\"]\n",
        "  ####### If loading a non-VISSL trained model, set the following two args carefully #########\n",
        "  # to make the checkpoint compatible with VISSL, if you need to remove some names\n",
        "  # from the checkpoint keys, specify the name\n",
        "  REMOVE_PREFIX: \"\"\n",
        "  # In order to load the model (if not trained with VISSL) with VISSL, there are 2 scenarios:\n",
        "  #    1. If you are interested in evaluating the model features and freeze the trunk.\n",
        "  #       Set APPEND_PREFIX=\"trunk.base_model.\" This assumes that your model is compatible\n",
        "  #       with the VISSL trunks. The VISSL trunks start with \"_feature_blocks.\" prefix. If\n",
        "  #       your model doesn't have these prefix you can append them. For example:\n",
        "  #       For TorchVision ResNet trunk, set APPEND_PREFIX=\"trunk.base_model._feature_blocks.\"\n",
        "  #    2. where you want to load the model simply and finetune the full model.\n",
        "  #       Set APPEND_PREFIX=\"trunk.\"\n",
        "  #       This assumes that your model is compatible with the VISSL trunks. The VISSL\n",
        "  #       trunks start with \"_feature_blocks.\" prefix. If your model doesn't have these\n",
        "  #       prefix you can append them.\n",
        "  #       For TorchVision ResNet trunk, set APPEND_PREFIX=\"trunk._feature_blocks.\"\n",
        "  # NOTE: the prefix is appended to all the layers in the model\n",
        "  APPEND_PREFIX: \"trunk._feature_blocks.\"\n",
        "  ```\n",
        "\n",
        "  **NOTE:** The above configuration will only load the TRUNK of a torchvision model. If you wish to load the HEAD and TRUNK of a torchvision model, you will have to convert the torchvision model to a VISSL supported checkpoint."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Benchmark Linear Image Classification on ImageNet-1K V0.1.6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
