{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/facebookresearch/vissl/blob/v0.1.6/tutorials/Feature_Extraction_V0_1_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ndZ6XwI7MYA"
      },
      "outputs": [],
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates. All rights reserved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XzxTZfKwFNo"
      },
      "source": [
        "# Feature Extraction\n",
        "\n",
        "In this tutorial, we look at a simple example of how to use VISSL to extract features for [ResNet-50 Torchvision pre-trained model](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L16).\n",
        "\n",
        "You can make a copy of this tutorial by `File -> Open in playground mode` and make changes there. Please do *NOT* request access to this tutorial.\n",
        "\n",
        "**NOTE:** Please ensure your Collab Notebook has a GPU available. To ensure this, simply follow: `Edit -> Notebook Settings -> select GPU.`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VohdWhBSw69e"
      },
      "source": [
        "# Install VISSL\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhM3-jpeJ0GN"
      },
      "source": [
        "Installing VISSL is straightfoward. We will install VISSL from source using pip, following the instructions from [here](https://github.com/facebookresearch/vissl/blob/master/INSTALL.md#install-vissl-pip-package). Note, you can also install VISSL in a conda environment or from our conda/pip binaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5ISg59KTOqU"
      },
      "outputs": [],
      "source": [
        "# Install pytorch version 1.8\n",
        "!pip install torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install Apex by checking system settings: cuda version, pytorch version, and python version\n",
        "import sys\n",
        "import torch\n",
        "version_str=\"\".join([\n",
        "    f\"py3{sys.version_info.minor}_cu\",\n",
        "    torch.version.cuda.replace(\".\",\"\"),\n",
        "    f\"_pyt{torch.__version__[0:5:2]}\"\n",
        "])\n",
        "print(version_str)\n",
        "\n",
        "# install apex (pre-compiled with optimizer C++ extensions and CUDA kernels)\n",
        "!pip install apex -f https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/{version_str}/download.html\n",
        "\n",
        "# # clone vissl repository and checkout latest version.\n",
        "!git clone --recursive https://github.com/facebookresearch/vissl.git\n",
        "\n",
        "%cd vissl/\n",
        "\n",
        "!git checkout v0.1.6\n",
        "!git checkout -b v0.1.6\n",
        "\n",
        "# install vissl dependencies\n",
        "!pip install --progress-bar off -r requirements.txt\n",
        "!pip install opencv-python\n",
        "\n",
        "# update classy vision install to commit compatible with v0.1.6\n",
        "!pip uninstall -y classy_vision\n",
        "!pip install classy-vision@https://github.com/facebookresearch/ClassyVision/tarball/4785d5ee19d3bcedd5b28c1eb51ea1f59188b54d\n",
        "\n",
        "# Update fairscale to commit compatible with v0.1.6\n",
        "!pip uninstall -y fairscale\n",
        "!pip install fairscale@https://github.com/facebookresearch/fairscale/tarball/df7db85cef7f9c30a5b821007754b96eb1f977b6\n",
        "\n",
        "# install vissl dev mode (e stands for editable)\n",
        "!pip install -e .[dev]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Fxe3MWxqsI"
      },
      "source": [
        "VISSL should be successfuly installed by now and all the dependencies should be available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np6atgoOTPrA"
      },
      "outputs": [],
      "source": [
        "import vissl\n",
        "import tensorboard\n",
        "import apex\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxMXLYLpsJXj"
      },
      "source": [
        "## Download the ResNet-50 weights from Torchvision\n",
        "\n",
        "We download the weights from the [torchvision ResNet50 model](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L16):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mv0quZwFsWxs"
      },
      "outputs": [],
      "source": [
        "!wget https://download.pytorch.org/models/resnet50-19c8e357.pth -P /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0hng2EPY7pr"
      },
      "source": [
        "## Creating a dummy dataset\n",
        "\n",
        "For the purpose of this tutorial, since we don't have ImageNet on the disk, we will create a dummy dataset by copying an image from COCO dataset in ImageNet dataset folder style as below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-sy6nD-RfwB"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/dummy_data/train/class1\n",
        "!mkdir -p /content/dummy_data/train/class2\n",
        "!mkdir -p /content/dummy_data/val/class1\n",
        "!mkdir -p /content/dummy_data/val/class2\n",
        "\n",
        "# create 2 classes in train and add 5 images per class\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img5.jpg\n",
        "\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img5.jpg\n",
        "\n",
        "# create 2 classes in val and add 5 images per class\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img5.jpg\n",
        "\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img5.jpg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPGCiTsXZeW3"
      },
      "source": [
        "## Using the custom data in VISSL\n",
        "\n",
        "Next step for us is to register the dummy data we created above with VISSL. Registering the dataset involves telling VISSL about the dataset name and the paths for the dataset. For this, we create a simple json file with the metadata and save it to `configs/config/dataset_catalog.py` file.\n",
        "\n",
        "**NOTE**: VISSL uses the specific `dataset_catalog.json` under the path `configs/config/dataset_catalog.json`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Q6LCqaWjl1"
      },
      "outputs": [],
      "source": [
        "json_data = {\n",
        "    \"dummy_data_folder\": {\n",
        "      \"train\": [\n",
        "        \"/content/dummy_data/train\", \"/content/dummy_data/train\"\n",
        "      ],\n",
        "      \"val\": [\n",
        "        \"/content/dummy_data/val\", \"/content/dummy_data/val\"\n",
        "      ]\n",
        "    }\n",
        "}\n",
        "\n",
        "# use VISSL's api to save or you can use your custom code.\n",
        "from vissl.utils.io import save_file\n",
        "save_file(json_data, \"/content/vissl/configs/config/dataset_catalog.json\", append_to_json=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otN1pB32cBHK"
      },
      "source": [
        "Next, we verify that the dataset is registered with VISSL. For that we query VISSL's dataset catalog as below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZBhH-s5bcHd",
        "outputId": "bb251efd-fa65-4ac2-e78d-50af2767bc55"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:fvcore.common.file_io:** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['dummy_data_folder']\n",
            "{'train': ['/content/dummy_data/train', '/content/dummy_data/train'], 'val': ['/content/dummy_data/val', '/content/dummy_data/val']}\n"
          ]
        }
      ],
      "source": [
        "from vissl.data.dataset_catalog import VisslDatasetCatalog\n",
        "\n",
        "# list all the datasets that exist in catalog\n",
        "print(VisslDatasetCatalog.list())\n",
        "\n",
        "# get the metadata of dummy_data_folder dataset\n",
        "print(VisslDatasetCatalog.get(\"dummy_data_folder\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCvq5y8MQlOa"
      },
      "source": [
        "# Loading Pre-trained models in VISSL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jvEsSFJJPb1"
      },
      "source": [
        "VISSL supports Torchvision models out of the box. Generally, for loading any non-VISSL model, one needs to correctly set the following configuration options:\n",
        "\n",
        "```yaml\n",
        "WEIGHTS_INIT:\n",
        "  # path to the .torch weights files\n",
        "  PARAMS_FILE: \"\"\n",
        "  # name of the state dict. checkpoint = {\"classy_state_dict\": {layername:value}}. Options:\n",
        "  #   1. classy_state_dict - if model is trained and checkpointed with VISSL.\n",
        "  #      checkpoint = {\"classy_state_dict\": {layername:value}}\n",
        "  #   2. \"\" - if the model_file is not a nested dictionary for model weights i.e.\n",
        "  #      checkpoint = {layername:value}\n",
        "  #   3. key name that your model checkpoint uses for state_dict key name.\n",
        "  #      checkpoint = {\"your_key_name\": {layername:value}}\n",
        "  STATE_DICT_KEY_NAME: \"classy_state_dict\"\n",
        "  # specify what layer should not be loaded. Layer names with this key are not copied\n",
        "  # By default, set to BatchNorm stats \"num_batches_tracked\" to be skipped.\n",
        "  SKIP_LAYERS: [\"num_batches_tracked\"]\n",
        "  ####### If loading a non-VISSL trained model, set the following two args carefully #########\n",
        "  # to make the checkpoint compatible with VISSL, if you need to remove some names\n",
        "  # from the checkpoint keys, specify the name\n",
        "  REMOVE_PREFIX: \"\"\n",
        "  # In order to load the model (if not trained with VISSL) with VISSL, there are 2 scenarios:\n",
        "  #    1. If you are interested in evaluating the model features and freeze the trunk.\n",
        "  #       Set APPEND_PREFIX=\"trunk.base_model.\" This assumes that your model is compatible\n",
        "  #       with the VISSL trunks. The VISSL trunks start with \"_feature_blocks.\" prefix. If\n",
        "  #       your model doesn't have these prefix you can append them. For example:\n",
        "  #       For TorchVision ResNet trunk, set APPEND_PREFIX=\"trunk.base_model._feature_blocks.\"\n",
        "  #    2. where you want to load the model simply and finetune the full model.\n",
        "  #       Set APPEND_PREFIX=\"trunk.\"\n",
        "  #       This assumes that your model is compatible with the VISSL trunks. The VISSL\n",
        "  #       trunks start with \"_feature_blocks.\" prefix. If your model doesn't have these\n",
        "  #       prefix you can append them.\n",
        "  #       For TorchVision ResNet trunk, set APPEND_PREFIX=\"trunk._feature_blocks.\"\n",
        "  # NOTE: the prefix is appended to all the layers in the model\n",
        "  APPEND_PREFIX: \"\"\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaUMDwMdzYHN"
      },
      "source": [
        "## Extract the TRUNK features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM7IigSpONW0"
      },
      "source": [
        "We are ready to extract the TRUNK features now. For the purpose of this tutorial, we will use synthetic dataset and train on dummy images. VISSL supports training on wide range of datasets and allows adding custom datasets. Please see VISSL documentation on how to use the datasets. To train on ImageNet instead: assuming your ImageNet dataset folder path is `/path/to/my/imagenet/folder/`, you can add the following command line \n",
        "input to your training command: \n",
        "```\n",
        "config.DATA.TRAIN.DATASET_NAMES=[imagenet1k_folder] \\\n",
        "config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "config.DATA.TRAIN.DATA_PATHS=[\"/path/to/my/imagenet/folder/train\"] \\\n",
        "config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]\n",
        "```\n",
        "\n",
        "VISSL provides a [helper python tool](https://github.com/facebookresearch/vissl/blob/main/tools/run_distributed_engines.py) that allows to use VISSL for training purposes. This tool allows:\n",
        "- training and feature extraction.\n",
        "- training on 1-gpu, multi-gpu, or even multi-machine using Pytorch DDP or Fairscale FSDP.\n",
        "\n",
        "VISSL provides yaml configuration files for extracting features [here](https://github.com/facebookresearch/vissl/tree/main/configs/config/feature_extraction). \n",
        "\n",
        "For the purpose of this tutorial, we will use the config file for extracting features from several layers of the trunk of ResNet-50 supervised model on 1-gpu.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v0HvauIj9S2",
        "outputId": "e6107dd3-7ed5-44d4-c0d5-949cb4a7cdf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/vissl\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "####### overrides: ['hydra.verbose=true', 'config=feature_extraction/extract_resnet_in1k_8gpu', '+config/feature_extraction/trunk_only=rn50_layers.yaml', 'config.DATA.TRAIN.DATA_SOURCES=[disk_folder]', 'config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]', 'config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2', 'config.DATA.TEST.DATA_SOURCES=[disk_folder]', 'config.DATA.TEST.LABEL_SOURCES=[disk_folder]', 'config.DATA.TEST.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TEST.BATCHSIZE_PER_REPLICA=2', 'config.DISTRIBUTED.NUM_NODES=1', 'config.DISTRIBUTED.NUM_PROC_PER_NODE=1', 'config.CHECKPOINT.DIR=/content/checkpoints', 'config.MODEL.WEIGHTS_INIT.PARAMS_FILE=/content/resnet50-19c8e357.pth', 'config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=trunk.base_model._feature_blocks.', 'config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=', 'config.EXTRACT_FEATURES.CHUNK_THRESHOLD=-1', 'hydra.verbose=true']\n",
            "INFO 2021-10-14 19:02:16,814 distributed_launcher.py: 184: Spawning process for node_id: 0, local_rank: 0, dist_rank: 0, dist_run_id: localhost:51497\n",
            "INFO 2021-10-14 19:02:16,814 extract_features.py:  80: Env set for rank: 0, dist_rank: 0\n",
            "INFO 2021-10-14 19:02:16,815 env.py:  50: CLICOLOR:\t1\n",
            "INFO 2021-10-14 19:02:16,815 env.py:  50: CLOUDSDK_CONFIG:\t/content/.config\n",
            "INFO 2021-10-14 19:02:16,815 env.py:  50: CLOUDSDK_PYTHON:\tpython3\n",
            "INFO 2021-10-14 19:02:16,815 env.py:  50: COLAB_GPU:\t1\n",
            "INFO 2021-10-14 19:02:16,815 env.py:  50: CUDA_VERSION:\t11.1.1\n",
            "INFO 2021-10-14 19:02:16,815 env.py:  50: CUDNN_VERSION:\t8.0.5.39\n",
            "INFO 2021-10-14 19:02:16,815 env.py:  50: DATALAB_SETTINGS_OVERRIDES:\t{\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=\\\"172.28.0.2\\\"\"],\"debugAdapterMultiplexerPath\":\"/usr/local/bin/dap_multiplexer\",\"enableLsp\":true}\n",
            "INFO 2021-10-14 19:02:16,815 env.py:  50: DEBIAN_FRONTEND:\tnoninteractive\n",
            "INFO 2021-10-14 19:02:16,815 env.py:  50: ENV:\t/root/.bashrc\n",
            "INFO 2021-10-14 19:02:16,816 env.py:  50: GCE_METADATA_TIMEOUT:\t0\n",
            "INFO 2021-10-14 19:02:16,816 env.py:  50: GCS_READ_CACHE_BLOCK_SIZE_MB:\t16\n",
            "INFO 2021-10-14 19:02:16,816 env.py:  50: GIT_PAGER:\tcat\n",
            "INFO 2021-10-14 19:02:16,816 env.py:  50: GLIBCPP_FORCE_NEW:\t1\n",
            "INFO 2021-10-14 19:02:16,816 env.py:  50: GLIBCXX_FORCE_NEW:\t1\n",
            "INFO 2021-10-14 19:02:16,816 env.py:  50: HOME:\t/root\n",
            "INFO 2021-10-14 19:02:16,816 env.py:  50: HOSTNAME:\t3af1980960bc\n",
            "INFO 2021-10-14 19:02:16,816 env.py:  50: JPY_PARENT_PID:\t65\n",
            "INFO 2021-10-14 19:02:16,816 env.py:  50: LANG:\ten_US.UTF-8\n",
            "INFO 2021-10-14 19:02:16,817 env.py:  50: LAST_FORCED_REBUILD:\t20211007\n",
            "INFO 2021-10-14 19:02:16,817 env.py:  50: LD_LIBRARY_PATH:\t/usr/lib64-nvidia\n",
            "INFO 2021-10-14 19:02:16,817 env.py:  50: LD_PRELOAD:\t/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4\n",
            "INFO 2021-10-14 19:02:16,817 env.py:  50: LIBRARY_PATH:\t/usr/local/cuda/lib64/stubs\n",
            "INFO 2021-10-14 19:02:16,817 env.py:  50: LOCAL_RANK:\t0\n",
            "INFO 2021-10-14 19:02:16,817 env.py:  50: MPLBACKEND:\tmodule://ipykernel.pylab.backend_inline\n",
            "INFO 2021-10-14 19:02:16,817 env.py:  50: NCCL_VERSION:\t2.7.8\n",
            "INFO 2021-10-14 19:02:16,817 env.py:  50: NO_GCE_CHECK:\tTrue\n",
            "INFO 2021-10-14 19:02:16,817 env.py:  50: NVIDIA_DRIVER_CAPABILITIES:\tcompute,utility\n",
            "INFO 2021-10-14 19:02:16,818 env.py:  50: NVIDIA_REQUIRE_CUDA:\tcuda>=11.1 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 brand=tesla,driver>=450,driver<451\n",
            "INFO 2021-10-14 19:02:16,818 env.py:  50: NVIDIA_VISIBLE_DEVICES:\tall\n",
            "INFO 2021-10-14 19:02:16,818 env.py:  50: OLDPWD:\t/\n",
            "INFO 2021-10-14 19:02:16,818 env.py:  50: PAGER:\tcat\n",
            "INFO 2021-10-14 19:02:16,818 env.py:  50: PATH:\t/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n",
            "INFO 2021-10-14 19:02:16,818 env.py:  50: PWD:\t/content/vissl\n",
            "INFO 2021-10-14 19:02:16,818 env.py:  50: PYDEVD_USE_FRAME_EVAL:\tNO\n",
            "INFO 2021-10-14 19:02:16,818 env.py:  50: PYTHONPATH:\t/env/python\n",
            "INFO 2021-10-14 19:02:16,818 env.py:  50: PYTHONWARNINGS:\tignore:::pip._internal.cli.base_command\n",
            "INFO 2021-10-14 19:02:16,818 env.py:  50: RANK:\t0\n",
            "INFO 2021-10-14 19:02:16,819 env.py:  50: SHELL:\t/bin/bash\n",
            "INFO 2021-10-14 19:02:16,819 env.py:  50: SHLVL:\t1\n",
            "INFO 2021-10-14 19:02:16,819 env.py:  50: TBE_CREDS_ADDR:\t172.28.0.1:8008\n",
            "INFO 2021-10-14 19:02:16,819 env.py:  50: TERM:\txterm-color\n",
            "INFO 2021-10-14 19:02:16,819 env.py:  50: TF_FORCE_GPU_ALLOW_GROWTH:\ttrue\n",
            "INFO 2021-10-14 19:02:16,819 env.py:  50: WORLD_SIZE:\t1\n",
            "INFO 2021-10-14 19:02:16,819 env.py:  50: _:\t/usr/bin/python3\n",
            "INFO 2021-10-14 19:02:16,819 env.py:  50: __EGL_VENDOR_LIBRARY_DIRS:\t/usr/lib64-nvidia:/usr/share/glvnd/egl_vendor.d/\n",
            "INFO 2021-10-14 19:02:16,819 misc.py: 161: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-10-14 19:02:16,820 extract_features.py:  91: Setting seed....\n",
            "INFO 2021-10-14 19:02:16,820 misc.py: 173: MACHINE SEED: 0\n",
            "INFO 2021-10-14 19:02:16,822 hydra_config.py: 131: Training with config:\n",
            "INFO 2021-10-14 19:02:16,831 hydra_config.py: 140: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,\n",
            "                'AUTO_RESUME': True,\n",
            "                'BACKEND': 'disk',\n",
            "                'CHECKPOINT_FREQUENCY': 1,\n",
            "                'CHECKPOINT_ITER_FREQUENCY': -1,\n",
            "                'DIR': '/content/checkpoints',\n",
            "                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,\n",
            "                'OVERWRITE_EXISTING': False,\n",
            "                'USE_SYMLINK_CHECKPOINT_FOR_RESUME': False},\n",
            " 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',\n",
            "                'DATA_LIMIT': -1,\n",
            "                'DATA_LIMIT_SAMPLING': {'SEED': 0},\n",
            "                'FEATURES': {'DATASET_NAME': '',\n",
            "                             'DATA_PARTITION': 'TRAIN',\n",
            "                             'DIMENSIONALITY_REDUCTION': 0,\n",
            "                             'EXTRACT': False,\n",
            "                             'LAYER_NAME': '',\n",
            "                             'PATH': '.',\n",
            "                             'TEST_PARTITION': 'TEST'},\n",
            "                'NUM_CLUSTERS': 16000,\n",
            "                'NUM_ITER': 50,\n",
            "                'OUTPUT_DIR': '.'},\n",
            " 'DATA': {'DDP_BUCKET_CAP_MB': 25,\n",
            "          'ENABLE_ASYNC_GPU_COPY': True,\n",
            "          'NUM_DATALOADER_WORKERS': 5,\n",
            "          'PIN_MEMORY': True,\n",
            "          'TEST': {'BASE_DATASET': 'generic_ssl',\n",
            "                   'BATCHSIZE_PER_REPLICA': 2,\n",
            "                   'COLLATE_FUNCTION': 'default_collate',\n",
            "                   'COLLATE_FUNCTION_PARAMS': {},\n",
            "                   'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',\n",
            "                   'COPY_TO_LOCAL_DISK': False,\n",
            "                   'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                   'DATA_LIMIT': -1,\n",
            "                   'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,\n",
            "                                           'SEED': 0,\n",
            "                                           'SKIP_NUM_SAMPLES': 0},\n",
            "                   'DATA_PATHS': [],\n",
            "                   'DATA_SOURCES': ['disk_folder'],\n",
            "                   'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                   'DROP_LAST': False,\n",
            "                   'ENABLE_QUEUE_DATASET': False,\n",
            "                   'INPUT_KEY_NAMES': ['data'],\n",
            "                   'LABEL_PATHS': [],\n",
            "                   'LABEL_SOURCES': ['disk_folder'],\n",
            "                   'LABEL_TYPE': 'standard',\n",
            "                   'MMAP_MODE': False,\n",
            "                   'NEW_IMG_PATH_PREFIX': '',\n",
            "                   'RANDOM_SYNTHETIC_IMAGES': False,\n",
            "                   'REMOVE_IMG_PATH_PREFIX': '',\n",
            "                   'TARGET_KEY_NAMES': ['label'],\n",
            "                   'TRANSFORMS': [{'name': 'Resize', 'size': 256},\n",
            "                                  {'name': 'CenterCrop', 'size': 224},\n",
            "                                  {'name': 'ToTensor'},\n",
            "                                  {'mean': [0.485, 0.456, 0.406],\n",
            "                                   'name': 'Normalize',\n",
            "                                   'std': [0.229, 0.224, 0.225]}],\n",
            "                   'USE_DEBUGGING_SAMPLER': False,\n",
            "                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},\n",
            "          'TRAIN': {'BASE_DATASET': 'generic_ssl',\n",
            "                    'BATCHSIZE_PER_REPLICA': 2,\n",
            "                    'COLLATE_FUNCTION': 'default_collate',\n",
            "                    'COLLATE_FUNCTION_PARAMS': {},\n",
            "                    'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',\n",
            "                    'COPY_TO_LOCAL_DISK': False,\n",
            "                    'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                    'DATA_LIMIT': -1,\n",
            "                    'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,\n",
            "                                            'SEED': 0,\n",
            "                                            'SKIP_NUM_SAMPLES': 0},\n",
            "                    'DATA_PATHS': [],\n",
            "                    'DATA_SOURCES': ['disk_folder'],\n",
            "                    'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                    'DROP_LAST': False,\n",
            "                    'ENABLE_QUEUE_DATASET': False,\n",
            "                    'INPUT_KEY_NAMES': ['data'],\n",
            "                    'LABEL_PATHS': [],\n",
            "                    'LABEL_SOURCES': ['disk_folder'],\n",
            "                    'LABEL_TYPE': 'sample_index',\n",
            "                    'MMAP_MODE': False,\n",
            "                    'NEW_IMG_PATH_PREFIX': '',\n",
            "                    'RANDOM_SYNTHETIC_IMAGES': False,\n",
            "                    'REMOVE_IMG_PATH_PREFIX': '',\n",
            "                    'TARGET_KEY_NAMES': ['label'],\n",
            "                    'TRANSFORMS': [{'name': 'Resize', 'size': 256},\n",
            "                                   {'name': 'CenterCrop', 'size': 224},\n",
            "                                   {'name': 'ToTensor'},\n",
            "                                   {'mean': [0.485, 0.456, 0.406],\n",
            "                                    'name': 'Normalize',\n",
            "                                    'std': [0.229, 0.224, 0.225]}],\n",
            "                    'USE_DEBUGGING_SAMPLER': False,\n",
            "                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},\n",
            " 'DISTRIBUTED': {'BACKEND': 'nccl',\n",
            "                 'BROADCAST_BUFFERS': True,\n",
            "                 'INIT_METHOD': 'tcp',\n",
            "                 'MANUAL_GRADIENT_REDUCTION': False,\n",
            "                 'NCCL_DEBUG': False,\n",
            "                 'NCCL_SOCKET_NTHREADS': '',\n",
            "                 'NUM_NODES': 1,\n",
            "                 'NUM_PROC_PER_NODE': 1,\n",
            "                 'RUN_ID': 'auto'},\n",
            " 'EXTRACT_FEATURES': {'CHUNK_THRESHOLD': -1, 'OUTPUT_DIR': ''},\n",
            " 'HOOKS': {'LOG_GPU_STATS': True,\n",
            "           'MEMORY_SUMMARY': {'DUMP_MEMORY_ON_EXCEPTION': False,\n",
            "                              'LOG_ITERATION_NUM': 0,\n",
            "                              'PRINT_MEMORY_SUMMARY': True},\n",
            "           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,\n",
            "                                'INPUT_SHAPE': [3, 224, 224]},\n",
            "           'PERF_STATS': {'MONITOR_PERF_STATS': False,\n",
            "                          'PERF_STAT_FREQUENCY': -1,\n",
            "                          'ROLLING_BTIME_FREQ': -1},\n",
            "           'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': 'tensorboard',\n",
            "                                 'FLUSH_EVERY_N_MIN': 5,\n",
            "                                 'LOG_DIR': '.',\n",
            "                                 'LOG_PARAMS': True,\n",
            "                                 'LOG_PARAMS_EVERY_N_ITERS': 310,\n",
            "                                 'LOG_PARAMS_GRADIENTS': True,\n",
            "                                 'USE_TENSORBOARD': False}},\n",
            " 'IMG_RETRIEVAL': {'CROP_QUERY_ROI': False,\n",
            "                   'DATASET_PATH': '',\n",
            "                   'DEBUG_MODE': False,\n",
            "                   'EVAL_BINARY_PATH': '',\n",
            "                   'EVAL_DATASET_NAME': 'Paris',\n",
            "                   'FEATS_PROCESSING_TYPE': '',\n",
            "                   'GEM_POOL_POWER': 4.0,\n",
            "                   'IMG_SCALINGS': [1],\n",
            "                   'NORMALIZE_FEATURES': True,\n",
            "                   'NUM_DATABASE_SAMPLES': -1,\n",
            "                   'NUM_QUERY_SAMPLES': -1,\n",
            "                   'NUM_TRAINING_SAMPLES': -1,\n",
            "                   'N_PCA': 512,\n",
            "                   'RESIZE_IMG': 1024,\n",
            "                   'SAVE_FEATURES': False,\n",
            "                   'SAVE_RETRIEVAL_RANKINGS_SCORES': True,\n",
            "                   'SIMILARITY_MEASURE': 'cosine_similarity',\n",
            "                   'SPATIAL_LEVELS': 3,\n",
            "                   'TRAIN_DATASET_NAME': 'Oxford',\n",
            "                   'TRAIN_PCA_WHITENING': True,\n",
            "                   'USE_DISTRACTORS': False,\n",
            "                   'WHITEN_IMG_LIST': ''},\n",
            " 'LOG_FREQUENCY': 10,\n",
            " 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},\n",
            "          'barlow_twins_loss': {'embedding_dim': 8192,\n",
            "                                'lambda_': 0.0051,\n",
            "                                'scale_loss': 0.024},\n",
            "          'bce_logits_multiple_output_single_target': {'normalize_output': False,\n",
            "                                                       'reduction': 'none',\n",
            "                                                       'world_size': 1},\n",
            "          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,\n",
            "                                                          'normalize_output': False,\n",
            "                                                          'reduction': 'mean',\n",
            "                                                          'temperature': 1.0,\n",
            "                                                          'weight': None},\n",
            "          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,\n",
            "                                 'DROP_LAST': True,\n",
            "                                 'kmeans_iters': 10,\n",
            "                                 'memory_params': {'crops_for_mb': [0],\n",
            "                                                   'embedding_dim': 128},\n",
            "                                 'num_clusters': [3000, 3000, 3000],\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_train_samples': -1,\n",
            "                                 'temperature': 0.1},\n",
            "          'dino_loss': {'crops_for_teacher': [0, 1],\n",
            "                        'ema_center': 0.9,\n",
            "                        'momentum': 0.996,\n",
            "                        'normalize_last_layer': True,\n",
            "                        'output_dim': 65536,\n",
            "                        'student_temp': 0.1,\n",
            "                        'teacher_temp_max': 0.07,\n",
            "                        'teacher_temp_min': 0.04,\n",
            "                        'teacher_temp_warmup_iters': 37500},\n",
            "          'moco_loss': {'embedding_dim': 128,\n",
            "                        'momentum': 0.999,\n",
            "                        'queue_size': 65536,\n",
            "                        'temperature': 0.2},\n",
            "          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                               'embedding_dim': 128,\n",
            "                                                               'world_size': 64},\n",
            "                                             'num_crops': 2,\n",
            "                                             'temperature': 0.1},\n",
            "          'name': 'CrossEntropyLoss',\n",
            "          'nce_loss_with_memory': {'loss_type': 'nce',\n",
            "                                   'loss_weights': [1.0],\n",
            "                                   'memory_params': {'embedding_dim': 128,\n",
            "                                                     'memory_size': -1,\n",
            "                                                     'momentum': 0.5,\n",
            "                                                     'norm_init': True,\n",
            "                                                     'update_mem_on_forward': True},\n",
            "                                   'negative_sampling_params': {'num_negatives': 16000,\n",
            "                                                                'type': 'random'},\n",
            "                                   'norm_constant': -1,\n",
            "                                   'norm_embedding': True,\n",
            "                                   'num_train_samples': -1,\n",
            "                                   'temperature': 0.07,\n",
            "                                   'update_mem_with_emb_index': -100},\n",
            "          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                     'embedding_dim': 128,\n",
            "                                                     'world_size': 64},\n",
            "                                   'temperature': 0.1},\n",
            "          'swav_loss': {'crops_for_assign': [0, 1],\n",
            "                        'embedding_dim': 128,\n",
            "                        'epsilon': 0.05,\n",
            "                        'normalize_last_layer': True,\n",
            "                        'num_crops': 2,\n",
            "                        'num_iters': 3,\n",
            "                        'num_prototypes': [3000],\n",
            "                        'output_dir': '.',\n",
            "                        'queue': {'local_queue_length': 0,\n",
            "                                  'queue_length': 0,\n",
            "                                  'start_iter': 0},\n",
            "                        'temp_hard_assignment_iters': 0,\n",
            "                        'temperature': 0.1,\n",
            "                        'use_double_precision': False},\n",
            "          'swav_momentum_loss': {'crops_for_assign': [0, 1],\n",
            "                                 'embedding_dim': 128,\n",
            "                                 'epsilon': 0.05,\n",
            "                                 'momentum': 0.99,\n",
            "                                 'momentum_eval_mode_iter_start': 0,\n",
            "                                 'normalize_last_layer': True,\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_iters': 3,\n",
            "                                 'num_prototypes': [3000],\n",
            "                                 'queue': {'local_queue_length': 0,\n",
            "                                           'queue_length': 0,\n",
            "                                           'start_iter': 0},\n",
            "                                 'temperature': 0.1,\n",
            "                                 'use_double_precision': False}},\n",
            " 'MACHINE': {'DEVICE': 'gpu'},\n",
            " 'METERS': {'accuracy_list_meter': {'meter_names': [],\n",
            "                                    'num_meters': 1,\n",
            "                                    'topk_values': [1]},\n",
            "            'enable_training_meter': True,\n",
            "            'mean_ap_list_meter': {'max_cpu_capacity': -1,\n",
            "                                   'meter_names': [],\n",
            "                                   'num_classes': 9605,\n",
            "                                   'num_meters': 1},\n",
            "            'name': ''},\n",
            " 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,\n",
            "                                        'USE_ACTIVATION_CHECKPOINTING': False},\n",
            "           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'},\n",
            "                          'AMP_TYPE': 'apex',\n",
            "                          'USE_AMP': False},\n",
            "           'CUDA_CACHE': {'CLEAR_CUDA_CACHE': False, 'CLEAR_FREQ': 100},\n",
            "           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': True,\n",
            "                                     'EVAL_TRUNK_AND_HEAD': False,\n",
            "                                     'EXTRACT_TRUNK_FEATURES_ONLY': True,\n",
            "                                     'FREEZE_TRUNK_AND_HEAD': False,\n",
            "                                     'FREEZE_TRUNK_ONLY': True,\n",
            "                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [['conv1',\n",
            "                                                                        ['AvgPool2d',\n",
            "                                                                         [[10,\n",
            "                                                                           10],\n",
            "                                                                          10,\n",
            "                                                                          4]]],\n",
            "                                                                       ['res2',\n",
            "                                                                        ['AvgPool2d',\n",
            "                                                                         [[16,\n",
            "                                                                           16],\n",
            "                                                                          8,\n",
            "                                                                          0]]],\n",
            "                                                                       ['res3',\n",
            "                                                                        ['AvgPool2d',\n",
            "                                                                         [[13,\n",
            "                                                                           13],\n",
            "                                                                          5,\n",
            "                                                                          0]]],\n",
            "                                                                       ['res4',\n",
            "                                                                        ['AvgPool2d',\n",
            "                                                                         [[8,\n",
            "                                                                           8],\n",
            "                                                                          3,\n",
            "                                                                          0]]],\n",
            "                                                                       ['res5',\n",
            "                                                                        ['AvgPool2d',\n",
            "                                                                         [[6,\n",
            "                                                                           6],\n",
            "                                                                          1,\n",
            "                                                                          0]]],\n",
            "                                                                       ['res5avg',\n",
            "                                                                        ['Identity',\n",
            "                                                                         []]]],\n",
            "                                     'SHOULD_FLATTEN_FEATS': False},\n",
            "           'FSDP_CONFIG': {'AUTO_WRAP_THRESHOLD': 0,\n",
            "                           'bucket_cap_mb': 0,\n",
            "                           'clear_autocast_cache': True,\n",
            "                           'compute_dtype': torch.float32,\n",
            "                           'flatten_parameters': True,\n",
            "                           'fp32_reduce_scatter': False,\n",
            "                           'mixed_precision': True,\n",
            "                           'verbose': True},\n",
            "           'GRAD_CLIP': {'MAX_NORM': 1, 'NORM_TYPE': 2, 'USE_GRAD_CLIP': False},\n",
            "           'HEAD': {'BATCHNORM_EPS': 1e-05,\n",
            "                    'BATCHNORM_MOMENTUM': 0.1,\n",
            "                    'PARAMS': [],\n",
            "                    'PARAMS_MULTIPLIER': 1.0},\n",
            "           'INPUT_TYPE': 'rgb',\n",
            "           'MULTI_INPUT_HEAD_MAPPING': [],\n",
            "           'NON_TRAINABLE_PARAMS': [],\n",
            "           'SHARDED_DDP_SETUP': {'USE_SDP': False, 'reduce_buffer_size': -1},\n",
            "           'SINGLE_PASS_EVERY_CROP': False,\n",
            "           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': False,\n",
            "                              'GROUP_SIZE': -1,\n",
            "                              'SYNC_BN_TYPE': 'pytorch'},\n",
            "           'TEMP_FROZEN_PARAMS_ITER_MAP': [],\n",
            "           'TRUNK': {'CONVIT': {'CLASS_TOKEN_IN_LOCAL_LAYERS': False,\n",
            "                                'LOCALITY_DIM': 10,\n",
            "                                'LOCALITY_STRENGTH': 1.0,\n",
            "                                'N_GPSA_LAYERS': 10,\n",
            "                                'USE_LOCAL_INIT': True},\n",
            "                     'EFFICIENT_NETS': {},\n",
            "                     'NAME': 'resnet',\n",
            "                     'REGNET': {},\n",
            "                     'RESNETS': {'DEPTH': 50,\n",
            "                                 'GROUPNORM_GROUPS': 32,\n",
            "                                 'GROUPS': 1,\n",
            "                                 'LAYER4_STRIDE': 2,\n",
            "                                 'NORM': 'BatchNorm',\n",
            "                                 'STANDARDIZE_CONVOLUTIONS': False,\n",
            "                                 'WIDTH_MULTIPLIER': 1,\n",
            "                                 'WIDTH_PER_GROUP': 64,\n",
            "                                 'ZERO_INIT_RESIDUAL': False},\n",
            "                     'VISION_TRANSFORMERS': {'ATTENTION_DROPOUT_RATE': 0,\n",
            "                                             'CLASSIFIER': 'token',\n",
            "                                             'DROPOUT_RATE': 0,\n",
            "                                             'DROP_PATH_RATE': 0,\n",
            "                                             'HIDDEN_DIM': 768,\n",
            "                                             'IMAGE_SIZE': 224,\n",
            "                                             'MLP_DIM': 3072,\n",
            "                                             'NUM_HEADS': 12,\n",
            "                                             'NUM_LAYERS': 12,\n",
            "                                             'PATCH_SIZE': 16,\n",
            "                                             'QKV_BIAS': False,\n",
            "                                             'QK_SCALE': False,\n",
            "                                             'name': None},\n",
            "                     'XCIT': {'ATTENTION_DROPOUT_RATE': 0,\n",
            "                              'DROPOUT_RATE': 0,\n",
            "                              'DROP_PATH_RATE': 0.05,\n",
            "                              'ETA': 1,\n",
            "                              'HIDDEN_DIM': 384,\n",
            "                              'IMAGE_SIZE': 224,\n",
            "                              'NUM_HEADS': 8,\n",
            "                              'NUM_LAYERS': 12,\n",
            "                              'PATCH_SIZE': 16,\n",
            "                              'QKV_BIAS': True,\n",
            "                              'QK_SCALE': False,\n",
            "                              'TOKENS_NORM': True,\n",
            "                              'name': None}},\n",
            "           'WEIGHTS_INIT': {'APPEND_PREFIX': 'trunk.base_model._feature_blocks.',\n",
            "                            'PARAMS_FILE': '/content/resnet50-19c8e357.pth',\n",
            "                            'REMOVE_PREFIX': '',\n",
            "                            'SKIP_LAYERS': ['num_batches_tracked'],\n",
            "                            'STATE_DICT_KEY_NAME': ''},\n",
            "           '_MODEL_INIT_SEED': 0},\n",
            " 'MONITORING': {'MONITOR_ACTIVATION_STATISTICS': 0},\n",
            " 'MULTI_PROCESSING_METHOD': 'forkserver',\n",
            " 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},\n",
            " 'OPTIMIZER': {'betas': [0.9, 0.999],\n",
            "               'construct_single_param_group_only': False,\n",
            "               'head_optimizer_params': {'use_different_lr': False,\n",
            "                                         'use_different_wd': False,\n",
            "                                         'weight_decay': 0.0001},\n",
            "               'larc_config': {'clip': False,\n",
            "                               'eps': 1e-08,\n",
            "                               'trust_coefficient': 0.001},\n",
            "               'momentum': 0.9,\n",
            "               'name': 'sgd',\n",
            "               'nesterov': False,\n",
            "               'non_regularized_parameters': [],\n",
            "               'num_epochs': 90,\n",
            "               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': False,\n",
            "                                                               'base_lr_batch_size': 256,\n",
            "                                                               'base_value': 0.1,\n",
            "                                                               'scaling_type': 'linear'},\n",
            "                                           'end_value': 0.0,\n",
            "                                           'interval_scaling': [],\n",
            "                                           'lengths': [],\n",
            "                                           'milestones': [30, 60],\n",
            "                                           'name': 'multistep',\n",
            "                                           'schedulers': [],\n",
            "                                           'start_value': 0.1,\n",
            "                                           'update_interval': 'epoch',\n",
            "                                           'value': 0.1,\n",
            "                                           'values': [0.1, 0.01, 0.001]},\n",
            "                                    'lr_head': {'auto_lr_scaling': {'auto_scale': False,\n",
            "                                                                    'base_lr_batch_size': 256,\n",
            "                                                                    'base_value': 0.1,\n",
            "                                                                    'scaling_type': 'linear'},\n",
            "                                                'end_value': 0.0,\n",
            "                                                'interval_scaling': [],\n",
            "                                                'lengths': [],\n",
            "                                                'milestones': [30, 60],\n",
            "                                                'name': 'multistep',\n",
            "                                                'schedulers': [],\n",
            "                                                'start_value': 0.1,\n",
            "                                                'update_interval': 'epoch',\n",
            "                                                'value': 0.1,\n",
            "                                                'values': [0.1, 0.01, 0.001]}},\n",
            "               'regularize_bias': True,\n",
            "               'regularize_bn': False,\n",
            "               'use_larc': False,\n",
            "               'use_zero': False,\n",
            "               'weight_decay': 0.0001},\n",
            " 'PROFILING': {'MEMORY_PROFILING': {'TRACK_BY_LAYER_MEMORY': False},\n",
            "               'NUM_ITERATIONS': 10,\n",
            "               'OUTPUT_FOLDER': '.',\n",
            "               'PROFILED_RANKS': [0, 1],\n",
            "               'RUNTIME_PROFILING': {'LEGACY_PROFILER': False,\n",
            "                                     'PROFILE_CPU': True,\n",
            "                                     'PROFILE_GPU': True,\n",
            "                                     'USE_PROFILER': False},\n",
            "               'START_ITERATION': 0,\n",
            "               'STOP_TRAINING_AFTER_PROFILING': False,\n",
            "               'WARMUP_ITERATIONS': 0},\n",
            " 'REPRODUCIBILITY': {'CUDDN_DETERMINISTIC': False},\n",
            " 'SEED_VALUE': 0,\n",
            " 'SLURM': {'ADDITIONAL_PARAMETERS': {},\n",
            "           'COMMENT': 'vissl job',\n",
            "           'CONSTRAINT': '',\n",
            "           'LOG_FOLDER': '.',\n",
            "           'MEM_GB': 250,\n",
            "           'NAME': 'vissl',\n",
            "           'NUM_CPU_PER_PROC': 8,\n",
            "           'PARTITION': '',\n",
            "           'PORT_ID': 40050,\n",
            "           'TIME_HOURS': 72,\n",
            "           'TIME_MINUTES': 0,\n",
            "           'USE_SLURM': False},\n",
            " 'SVM': {'cls_list': [],\n",
            "         'costs': {'base': -1.0,\n",
            "                   'costs_list': [0.1, 0.01],\n",
            "                   'power_range': [4, 20]},\n",
            "         'cross_val_folds': 3,\n",
            "         'dual': True,\n",
            "         'force_retrain': False,\n",
            "         'loss': 'squared_hinge',\n",
            "         'low_shot': {'dataset_name': 'voc',\n",
            "                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],\n",
            "                      'sample_inds': [1, 2, 3, 4, 5]},\n",
            "         'max_iter': 2000,\n",
            "         'normalize': True,\n",
            "         'penalty': 'l2'},\n",
            " 'TEST_EVERY_NUM_EPOCH': 1,\n",
            " 'TEST_MODEL': True,\n",
            " 'TEST_ONLY': False,\n",
            " 'TRAINER': {'TASK_NAME': 'self_supervision_task',\n",
            "             'TRAIN_STEP_NAME': 'standard_train_step'},\n",
            " 'VERBOSE': False}\n",
            "INFO 2021-10-14 19:02:18,067 extract_features.py: 103: System config:\n",
            "-------------------  ---------------------------------------------------------------\n",
            "sys.platform         linux\n",
            "Python               3.7.12 (default, Sep 10 2021, 00:21:48) [GCC 7.5.0]\n",
            "numpy                1.19.5\n",
            "Pillow               7.1.2\n",
            "vissl                0.1.6 @/content/vissl/vissl\n",
            "GPU available        True\n",
            "GPU 0                Tesla K80\n",
            "CUDA_HOME            /usr/local/cuda\n",
            "torchvision          0.9.0+cu101 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "hydra                1.0.7 @/usr/local/lib/python3.7/dist-packages/hydra\n",
            "classy_vision        0.7.0.dev @/usr/local/lib/python3.7/dist-packages/classy_vision\n",
            "tensorboard          2.6.0\n",
            "apex                 0.1 @/usr/local/lib/python3.7/dist-packages/apex\n",
            "cv2                  4.1.2\n",
            "PyTorch              1.8.0+cu101 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build  False\n",
            "-------------------  ---------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 10.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.1, CUDNN_VERSION=7.6.3, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
            "\n",
            "CPU info:\n",
            "-------------------  ------------------------------\n",
            "Architecture         x86_64\n",
            "CPU op-mode(s)       32-bit, 64-bit\n",
            "Byte Order           Little Endian\n",
            "CPU(s)               2\n",
            "On-line CPU(s) list  0,1\n",
            "Thread(s) per core   2\n",
            "Core(s) per socket   1\n",
            "Socket(s)            1\n",
            "NUMA node(s)         1\n",
            "Vendor ID            GenuineIntel\n",
            "CPU family           6\n",
            "Model                63\n",
            "Model name           Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "Stepping             0\n",
            "CPU MHz              2299.998\n",
            "BogoMIPS             4599.99\n",
            "Hypervisor vendor    KVM\n",
            "Virtualization type  full\n",
            "L1d cache            32K\n",
            "L1i cache            32K\n",
            "L2 cache             256K\n",
            "L3 cache             46080K\n",
            "NUMA node0 CPU(s)    0,1\n",
            "-------------------  ------------------------------\n",
            "INFO 2021-10-14 19:02:18,068 trainer_main.py: 113: Using Distributed init method: tcp://localhost:51497, world_size: 1, rank: 0\n",
            "INFO 2021-10-14 19:02:18,069 distributed_c10d.py: 187: Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "INFO 2021-10-14 19:02:18,069 trainer_main.py: 134: | initialized host 3af1980960bc as rank 0 (0)\n",
            "INFO 2021-10-14 19:02:20,245 train_task.py: 181: Not using Automatic Mixed Precision\n",
            "INFO 2021-10-14 19:02:20,247 ssl_dataset.py: 157: Rank: 0 split: TEST Data files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-10-14 19:02:20,247 ssl_dataset.py: 160: Rank: 0 split: TEST Label files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-10-14 19:02:20,247 disk_dataset.py:  86: Loaded 10 samples from folder /content/dummy_data/val\n",
            "INFO 2021-10-14 19:02:20,248 ssl_dataset.py: 157: Rank: 0 split: TRAIN Data files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-10-14 19:02:20,248 ssl_dataset.py: 160: Rank: 0 split: TRAIN Label files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-10-14 19:02:20,248 disk_dataset.py:  86: Loaded 10 samples from folder /content/dummy_data/train\n",
            "INFO 2021-10-14 19:02:20,248 misc.py: 161: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-10-14 19:02:20,249 __init__.py: 126: Created the Distributed Sampler....\n",
            "INFO 2021-10-14 19:02:20,249 __init__.py: 101: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "INFO 2021-10-14 19:02:20,250 __init__.py: 215: Wrapping the dataloader to async device copies\n",
            "INFO 2021-10-14 19:02:20,250 misc.py: 161: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-10-14 19:02:20,250 __init__.py: 126: Created the Distributed Sampler....\n",
            "INFO 2021-10-14 19:02:20,250 __init__.py: 101: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "INFO 2021-10-14 19:02:20,251 __init__.py: 215: Wrapping the dataloader to async device copies\n",
            "INFO 2021-10-14 19:02:20,251 train_task.py: 449: Building model....\n",
            "INFO 2021-10-14 19:02:20,251 feature_extractor.py:  27: Creating Feature extractor trunk...\n",
            "INFO 2021-10-14 19:02:20,251 resnext.py:  68: ResNeXT trunk, supports activation checkpointing. Deactivated\n",
            "INFO 2021-10-14 19:02:20,252 resnext.py:  88: Building model: ResNeXt50-1x64d-w1-BatchNorm2d\n",
            "INFO 2021-10-14 19:02:21,027 feature_extractor.py:  50: Freezing model trunk...\n",
            "INFO 2021-10-14 19:02:21,028 train_task.py: 467: config.MODEL.FEATURE_EVAL_SETTINGS.FREEZE_TRUNK_ONLY=True, will freeze trunk...\n",
            "INFO 2021-10-14 19:02:21,029 base_ssl_model.py: 194: Freezing model trunk...\n",
            "INFO 2021-10-14 19:02:21,029 train_task.py: 423: Initializing model from: /content/resnet50-19c8e357.pth\n",
            "INFO 2021-10-14 19:02:21,030 util.py: 276: Attempting to load checkpoint from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-10-14 19:02:21,398 util.py: 281: Loaded checkpoint from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-10-14 19:02:21,399 util.py: 240: Broadcasting checkpoint loaded from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-10-14 19:02:25,186 train_task.py: 429: Checkpoint loaded: /content/resnet50-19c8e357.pth...\n",
            "INFO 2021-10-14 19:02:25,188 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,189 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,189 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,189 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,189 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,189 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,189 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,189 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,190 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,190 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,190 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,190 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,190 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,190 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,190 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,191 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,191 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,191 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,191 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,191 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,191 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,191 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,192 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,192 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,192 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,192 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,192 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,192 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,192 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,193 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,193 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,193 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,193 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,193 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,193 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,193 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,194 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,194 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,194 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,194 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,194 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,194 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,194 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,195 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,195 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,195 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,195 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,195 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,195 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,195 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,196 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,196 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,196 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,196 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,196 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,196 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,196 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,197 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,197 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,197 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,197 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,197 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,197 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,197 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,198 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,198 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,198 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,198 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,198 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,198 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,198 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,199 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,199 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,199 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,199 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,199 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,199 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,200 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,200 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,200 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,200 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,200 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,200 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,200 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,201 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,201 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,201 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,201 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,201 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,201 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,202 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,202 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,202 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,202 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,202 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,202 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,203 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,203 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,203 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,262 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,262 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,263 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,263 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,263 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,263 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,264 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,264 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,265 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,265 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,265 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,265 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,266 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,266 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,266 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,267 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,267 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,267 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,268 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,268 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,268 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,269 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,269 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,269 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,269 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,270 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,270 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,270 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,270 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,270 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,271 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,271 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,271 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.3.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,271 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,272 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,272 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,272 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,272 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,272 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.3.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,273 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,273 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,273 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,273 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,274 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,274 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.3.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,274 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,274 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,274 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,275 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,275 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,275 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,276 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,276 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,276 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,277 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,277 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,277 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,277 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,278 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,278 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,278 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,278 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,279 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,279 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,279 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,280 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,280 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,280 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,280 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,280 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,281 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,281 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,281 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,281 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,281 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,282 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,282 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,282 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,283 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,283 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,283 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,283 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,283 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,283 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,284 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,284 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,284 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,284 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,284 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,285 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,285 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,285 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,285 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,286 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,286 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,286 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,286 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,286 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,286 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,287 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,287 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,287 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,287 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,287 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,287 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,288 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,288 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,288 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,288 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,288 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,288 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.3.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,289 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,289 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,289 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,290 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,290 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,290 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.3.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,290 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,290 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,290 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,291 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,291 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,291 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.3.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,291 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,291 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,291 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,291 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,292 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,292 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.4.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,293 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,293 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,293 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,293 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,293 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,293 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.4.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,294 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,294 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,294 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,294 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,294 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,294 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.4.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,295 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,295 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,295 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,295 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,295 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,295 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.5.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,296 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,296 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,296 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,297 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,297 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,297 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.5.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,297 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,297 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,298 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,298 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,298 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,298 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.5.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,299 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,299 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,380 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,380 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,380 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,381 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,384 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,384 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,384 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,384 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,384 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,385 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,386 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,386 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,386 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,386 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,386 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,386 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,389 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,389 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,389 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,389 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,389 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,389 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,391 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,391 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,391 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,391 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,391 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,391 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,394 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,394 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,394 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,394 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,394 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,394 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,396 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,396 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,396 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,396 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,396 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,396 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,397 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,398 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,398 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,398 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,398 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,398 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,401 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,401 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,401 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,401 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,401 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,401 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,403 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,403 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,403 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,403 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,403 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:02:25,403 checkpoint.py: 851: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:02:25,403 checkpoint.py: 901: Extra layers not loaded from checkpoint: ['trunk.base_model._feature_blocks.fc.weight', 'trunk.base_model._feature_blocks.fc.bias', 'trunk.base_model._feature_blocks.type']\n",
            "INFO 2021-10-14 19:02:25,465 trainer_main.py: 352: Model is:\n",
            " Classy <class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'>:\n",
            "BaseSSLMultiInputOutputModel(\n",
            "  (_heads): ModuleDict()\n",
            "  (trunk): FeatureExtractorModel(\n",
            "    (base_model): ResNeXt(\n",
            "      (_feature_blocks): ModuleDict(\n",
            "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv1_relu): ReLU(inplace=True)\n",
            "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "        (layer1): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (layer2): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (layer3): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (4): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (5): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (layer4): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), bias=False)\n",
            "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "        (flatten): Flatten()\n",
            "      )\n",
            "    )\n",
            "    (feature_pool_ops): ModuleList(\n",
            "      (0): AvgPool2d(kernel_size=[10, 10], stride=10, padding=4)\n",
            "      (1): AvgPool2d(kernel_size=[16, 16], stride=8, padding=0)\n",
            "      (2): AvgPool2d(kernel_size=[13, 13], stride=5, padding=0)\n",
            "      (3): AvgPool2d(kernel_size=[8, 8], stride=3, padding=0)\n",
            "      (4): AvgPool2d(kernel_size=[6, 6], stride=1, padding=0)\n",
            "      (5): Identity()\n",
            "    )\n",
            "  )\n",
            "  (heads): ModuleList()\n",
            "  (dummy_layer): Linear(in_features=4, out_features=4, bias=True)\n",
            ")\n",
            "INFO 2021-10-14 19:02:25,486 trainer_main.py: 362: ============== Split: TEST =======================\n",
            "INFO 2021-10-14 19:02:25,486 trainer_main.py: 363: Extracting features for partition: test\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-10-14 19:02:31,038 trainer_main.py: 423: Model set to eval mode during feature extraction...\n",
            "INFO 2021-10-14 19:02:32,473 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_conv1_features.npy\n",
            "INFO 2021-10-14 19:02:32,474 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_conv1_features.npy\n",
            "INFO 2021-10-14 19:02:32,475 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_conv1_targets.npy\n",
            "INFO 2021-10-14 19:02:32,475 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_conv1_targets.npy\n",
            "INFO 2021-10-14 19:02:32,475 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_conv1_inds.npy\n",
            "INFO 2021-10-14 19:02:32,476 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_conv1_inds.npy\n",
            "INFO 2021-10-14 19:02:32,476 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res2_features.npy\n",
            "INFO 2021-10-14 19:02:32,477 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res2_features.npy\n",
            "INFO 2021-10-14 19:02:32,477 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res2_targets.npy\n",
            "INFO 2021-10-14 19:02:32,477 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res2_targets.npy\n",
            "INFO 2021-10-14 19:02:32,477 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res2_inds.npy\n",
            "INFO 2021-10-14 19:02:32,478 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res2_inds.npy\n",
            "INFO 2021-10-14 19:02:32,478 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res3_features.npy\n",
            "INFO 2021-10-14 19:02:32,479 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res3_features.npy\n",
            "INFO 2021-10-14 19:02:32,479 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res3_targets.npy\n",
            "INFO 2021-10-14 19:02:32,479 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res3_targets.npy\n",
            "INFO 2021-10-14 19:02:32,479 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res3_inds.npy\n",
            "INFO 2021-10-14 19:02:32,480 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res3_inds.npy\n",
            "INFO 2021-10-14 19:02:32,480 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res4_features.npy\n",
            "INFO 2021-10-14 19:02:32,481 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res4_features.npy\n",
            "INFO 2021-10-14 19:02:32,481 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res4_targets.npy\n",
            "INFO 2021-10-14 19:02:32,481 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res4_targets.npy\n",
            "INFO 2021-10-14 19:02:32,481 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res4_inds.npy\n",
            "INFO 2021-10-14 19:02:32,482 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res4_inds.npy\n",
            "INFO 2021-10-14 19:02:32,482 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res5_features.npy\n",
            "INFO 2021-10-14 19:02:32,482 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res5_features.npy\n",
            "INFO 2021-10-14 19:02:32,483 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res5_targets.npy\n",
            "INFO 2021-10-14 19:02:32,483 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res5_targets.npy\n",
            "INFO 2021-10-14 19:02:32,483 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res5_inds.npy\n",
            "INFO 2021-10-14 19:02:32,483 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res5_inds.npy\n",
            "INFO 2021-10-14 19:02:32,484 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res5avg_features.npy\n",
            "INFO 2021-10-14 19:02:32,484 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res5avg_features.npy\n",
            "INFO 2021-10-14 19:02:32,484 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res5avg_targets.npy\n",
            "INFO 2021-10-14 19:02:32,485 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res5avg_targets.npy\n",
            "INFO 2021-10-14 19:02:32,485 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res5avg_inds.npy\n",
            "INFO 2021-10-14 19:02:32,485 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res5avg_inds.npy\n",
            "INFO 2021-10-14 19:02:32,486 trainer_main.py: 366: Done getting features for partition: test\n",
            "INFO 2021-10-14 19:02:32,486 trainer_main.py: 362: ============== Split: TRAIN =======================\n",
            "INFO 2021-10-14 19:02:32,486 trainer_main.py: 363: Extracting features for partition: train\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-10-14 19:02:37,747 trainer_main.py: 423: Model set to eval mode during feature extraction...\n",
            "INFO 2021-10-14 19:02:37,999 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_conv1_features.npy\n",
            "INFO 2021-10-14 19:02:38,001 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_conv1_features.npy\n",
            "INFO 2021-10-14 19:02:38,001 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_conv1_targets.npy\n",
            "INFO 2021-10-14 19:02:38,001 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_conv1_targets.npy\n",
            "INFO 2021-10-14 19:02:38,001 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_conv1_inds.npy\n",
            "INFO 2021-10-14 19:02:38,002 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_conv1_inds.npy\n",
            "INFO 2021-10-14 19:02:38,002 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res2_features.npy\n",
            "INFO 2021-10-14 19:02:38,003 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res2_features.npy\n",
            "INFO 2021-10-14 19:02:38,003 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res2_targets.npy\n",
            "INFO 2021-10-14 19:02:38,004 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res2_targets.npy\n",
            "INFO 2021-10-14 19:02:38,004 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res2_inds.npy\n",
            "INFO 2021-10-14 19:02:38,004 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res2_inds.npy\n",
            "INFO 2021-10-14 19:02:38,004 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res3_features.npy\n",
            "INFO 2021-10-14 19:02:38,005 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res3_features.npy\n",
            "INFO 2021-10-14 19:02:38,005 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res3_targets.npy\n",
            "INFO 2021-10-14 19:02:38,006 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res3_targets.npy\n",
            "INFO 2021-10-14 19:02:38,006 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res3_inds.npy\n",
            "INFO 2021-10-14 19:02:38,006 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res3_inds.npy\n",
            "INFO 2021-10-14 19:02:38,006 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res4_features.npy\n",
            "INFO 2021-10-14 19:02:38,007 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res4_features.npy\n",
            "INFO 2021-10-14 19:02:38,007 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res4_targets.npy\n",
            "INFO 2021-10-14 19:02:38,007 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res4_targets.npy\n",
            "INFO 2021-10-14 19:02:38,008 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res4_inds.npy\n",
            "INFO 2021-10-14 19:02:38,008 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res4_inds.npy\n",
            "INFO 2021-10-14 19:02:38,008 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res5_features.npy\n",
            "INFO 2021-10-14 19:02:38,009 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res5_features.npy\n",
            "INFO 2021-10-14 19:02:38,009 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res5_targets.npy\n",
            "INFO 2021-10-14 19:02:38,009 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res5_targets.npy\n",
            "INFO 2021-10-14 19:02:38,009 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res5_inds.npy\n",
            "INFO 2021-10-14 19:02:38,010 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res5_inds.npy\n",
            "INFO 2021-10-14 19:02:38,010 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res5avg_features.npy\n",
            "INFO 2021-10-14 19:02:38,011 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res5avg_features.npy\n",
            "INFO 2021-10-14 19:02:38,011 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res5avg_targets.npy\n",
            "INFO 2021-10-14 19:02:38,011 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res5avg_targets.npy\n",
            "INFO 2021-10-14 19:02:38,011 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res5avg_inds.npy\n",
            "INFO 2021-10-14 19:02:38,012 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res5avg_inds.npy\n",
            "INFO 2021-10-14 19:02:38,012 trainer_main.py: 366: Done getting features for partition: train\n",
            "INFO 2021-10-14 19:02:38,094 extract_features.py: 108: All Done!\n",
            "INFO 2021-10-14 19:02:38,094 logger.py:  73: Shutting down loggers...\n",
            "INFO 2021-10-14 19:02:38,095 distributed_launcher.py: 168: All Done!\n",
            "INFO 2021-10-14 19:02:38,095 logger.py:  73: Shutting down loggers...\n"
          ]
        }
      ],
      "source": [
        "%cd /content/vissl/\n",
        "!python3 tools/run_distributed_engines.py \\\n",
        "    hydra.verbose=true \\\n",
        "    config=feature_extraction/extract_resnet_in1k_8gpu \\\n",
        "    +config/feature_extraction/trunk_only=rn50_layers.yaml \\\n",
        "    config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DATA.TEST.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TEST.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DISTRIBUTED.NUM_NODES=1 \\\n",
        "    config.DISTRIBUTED.NUM_PROC_PER_NODE=1 \\\n",
        "    config.CHECKPOINT.DIR=\"/content/checkpoints\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.PARAMS_FILE=\"/content/resnet50-19c8e357.pth\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=\"trunk.base_model._feature_blocks.\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=\"\" \\\n",
        "    config.EXTRACT_FEATURES.CHUNK_THRESHOLD=-1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8fILq7VzyOu"
      },
      "source": [
        "And we are done!! We have the features, for layers `conv1, res2, res3, res4, res5, res5avg` in `checkpoints/*.npy`. Additionally we save the data indexes and targets for each image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otUmgl4ms96M",
        "outputId": "1efab004-88b2-4a2a-bbf3-fc44f20c909b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "log.txt\t\t\t\t\trank0_chunk0_train_conv1_features.npy\n",
            "rank0_chunk0_test_conv1_features.npy\trank0_chunk0_train_conv1_inds.npy\n",
            "rank0_chunk0_test_conv1_inds.npy\trank0_chunk0_train_conv1_targets.npy\n",
            "rank0_chunk0_test_conv1_targets.npy\trank0_chunk0_train_res2_features.npy\n",
            "rank0_chunk0_test_res2_features.npy\trank0_chunk0_train_res2_inds.npy\n",
            "rank0_chunk0_test_res2_inds.npy\t\trank0_chunk0_train_res2_targets.npy\n",
            "rank0_chunk0_test_res2_targets.npy\trank0_chunk0_train_res3_features.npy\n",
            "rank0_chunk0_test_res3_features.npy\trank0_chunk0_train_res3_inds.npy\n",
            "rank0_chunk0_test_res3_inds.npy\t\trank0_chunk0_train_res3_targets.npy\n",
            "rank0_chunk0_test_res3_targets.npy\trank0_chunk0_train_res4_features.npy\n",
            "rank0_chunk0_test_res4_features.npy\trank0_chunk0_train_res4_inds.npy\n",
            "rank0_chunk0_test_res4_inds.npy\t\trank0_chunk0_train_res4_targets.npy\n",
            "rank0_chunk0_test_res4_targets.npy\trank0_chunk0_train_res5avg_features.npy\n",
            "rank0_chunk0_test_res5avg_features.npy\trank0_chunk0_train_res5avg_inds.npy\n",
            "rank0_chunk0_test_res5avg_inds.npy\trank0_chunk0_train_res5avg_targets.npy\n",
            "rank0_chunk0_test_res5avg_targets.npy\trank0_chunk0_train_res5_features.npy\n",
            "rank0_chunk0_test_res5_features.npy\trank0_chunk0_train_res5_inds.npy\n",
            "rank0_chunk0_test_res5_inds.npy\t\trank0_chunk0_train_res5_targets.npy\n",
            "rank0_chunk0_test_res5_targets.npy\ttrain_config.yaml\n"
          ]
        }
      ],
      "source": [
        "!ls /content/checkpoints/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOpdq7hIDZL7"
      },
      "source": [
        "# Loading Extracted Trunk Features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73akRkxZI_92"
      },
      "source": [
        "We also offer a clean and easy to use [API](https://github.com/facebookresearch/vissl/blob/v0.1.6/vissl/utils/extract_features_utils.py) for loading and manipulating the extracted features. The features will have shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm8SltGyDrEI",
        "outputId": "c88e91b6-b36a-48e2-84b2-be737d518715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Res5 test features have the following shape: (10, 2048, 2, 2)\n",
            "Res5 test indexes have the following shape: (10,)\n",
            "Res5 test targets have the following shape: (10, 1)\n"
          ]
        }
      ],
      "source": [
        "from vissl.utils.extract_features_utils import ExtractedFeaturesLoader\n",
        "\n",
        "# We will load the res5 test features\n",
        "features = ExtractedFeaturesLoader.load_features(\n",
        "  input_dir=\"/content/checkpoints/\",\n",
        "  split=\"test\", \n",
        "  layer=\"res5\"\n",
        ")\n",
        "\n",
        "feature_shape = features['features'].shape\n",
        "indeces_shape = features['inds'].shape\n",
        "targets_shape = features['targets'].shape\n",
        "\n",
        "print(f\"Res5 test features have the following shape: {feature_shape}\")\n",
        "print(f\"Res5 test indexes have the following shape: {indeces_shape}\")\n",
        "print(f\"Res5 test targets have the following shape: {targets_shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddM7NKqjXchY"
      },
      "source": [
        "# Download Torchvision Model Compatible with VISSL Heads "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLSjrpcWXbPp"
      },
      "source": [
        "Next, we will extract the features from the HEAD of the model. First we must download a VISSL compatible checkpoint: while we can load the torchvision TRUNK into vissl without any changes, we must slightly reformat the checkpoint to load the HEAD. \n",
        "\n",
        "See [here](https://github.com/facebookresearch/vissl/blob/main/extra_scripts/convert_vissl_to_torchvision.py) as an example for the vissl checkpoint format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJ7XC21J4st9"
      },
      "outputs": [],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/vissl/tutorials/resnet_50_torchvision_vissl_compatible.torch -P /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2esdj4WQ-Yb",
        "outputId": "0c24ec59-b860-4f18-df58-a75e14994f5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "####### overrides: ['hydra.verbose=true', 'config=feature_extraction/extract_resnet_in1k_8gpu', '+config/feature_extraction/with_head=rn50_supervised.yaml', 'config.DATA.TRAIN.DATA_SOURCES=[disk_folder]', 'config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]', 'config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2', 'config.DATA.TEST.DATA_SOURCES=[disk_folder]', 'config.DATA.TEST.LABEL_SOURCES=[disk_folder]', 'config.DATA.TEST.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TEST.BATCHSIZE_PER_REPLICA=2', 'config.DISTRIBUTED.NUM_NODES=1', 'config.DISTRIBUTED.NUM_PROC_PER_NODE=1', 'config.CHECKPOINT.DIR=/content/checkpoints', 'config.MODEL.WEIGHTS_INIT.PARAMS_FILE=/content/resnet_50_torchvision_vissl_compatible.torch', 'hydra.verbose=true']\n",
            "INFO 2021-10-14 19:03:35,049 distributed_launcher.py: 184: Spawning process for node_id: 0, local_rank: 0, dist_rank: 0, dist_run_id: localhost:43987\n",
            "INFO 2021-10-14 19:03:35,050 extract_features.py:  80: Env set for rank: 0, dist_rank: 0\n",
            "INFO 2021-10-14 19:03:35,050 env.py:  50: CLICOLOR:\t1\n",
            "INFO 2021-10-14 19:03:35,050 env.py:  50: CLOUDSDK_CONFIG:\t/content/.config\n",
            "INFO 2021-10-14 19:03:35,050 env.py:  50: CLOUDSDK_PYTHON:\tpython3\n",
            "INFO 2021-10-14 19:03:35,050 env.py:  50: COLAB_GPU:\t1\n",
            "INFO 2021-10-14 19:03:35,050 env.py:  50: CUDA_VERSION:\t11.1.1\n",
            "INFO 2021-10-14 19:03:35,051 env.py:  50: CUDNN_VERSION:\t8.0.5.39\n",
            "INFO 2021-10-14 19:03:35,051 env.py:  50: DATALAB_SETTINGS_OVERRIDES:\t{\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=\\\"172.28.0.2\\\"\"],\"debugAdapterMultiplexerPath\":\"/usr/local/bin/dap_multiplexer\",\"enableLsp\":true}\n",
            "INFO 2021-10-14 19:03:35,051 env.py:  50: DEBIAN_FRONTEND:\tnoninteractive\n",
            "INFO 2021-10-14 19:03:35,051 env.py:  50: ENV:\t/root/.bashrc\n",
            "INFO 2021-10-14 19:03:35,051 env.py:  50: GCE_METADATA_TIMEOUT:\t0\n",
            "INFO 2021-10-14 19:03:35,051 env.py:  50: GCS_READ_CACHE_BLOCK_SIZE_MB:\t16\n",
            "INFO 2021-10-14 19:03:35,051 env.py:  50: GIT_PAGER:\tcat\n",
            "INFO 2021-10-14 19:03:35,052 env.py:  50: GLIBCPP_FORCE_NEW:\t1\n",
            "INFO 2021-10-14 19:03:35,052 env.py:  50: GLIBCXX_FORCE_NEW:\t1\n",
            "INFO 2021-10-14 19:03:35,052 env.py:  50: HOME:\t/root\n",
            "INFO 2021-10-14 19:03:35,052 env.py:  50: HOSTNAME:\t3af1980960bc\n",
            "INFO 2021-10-14 19:03:35,052 env.py:  50: JPY_PARENT_PID:\t65\n",
            "INFO 2021-10-14 19:03:35,052 env.py:  50: LANG:\ten_US.UTF-8\n",
            "INFO 2021-10-14 19:03:35,052 env.py:  50: LAST_FORCED_REBUILD:\t20211007\n",
            "INFO 2021-10-14 19:03:35,052 env.py:  50: LD_LIBRARY_PATH:\t/usr/lib64-nvidia\n",
            "INFO 2021-10-14 19:03:35,053 env.py:  50: LD_PRELOAD:\t/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4\n",
            "INFO 2021-10-14 19:03:35,053 env.py:  50: LIBRARY_PATH:\t/usr/local/cuda/lib64/stubs\n",
            "INFO 2021-10-14 19:03:35,053 env.py:  50: LOCAL_RANK:\t0\n",
            "INFO 2021-10-14 19:03:35,053 env.py:  50: MPLBACKEND:\tmodule://ipykernel.pylab.backend_inline\n",
            "INFO 2021-10-14 19:03:35,053 env.py:  50: NCCL_VERSION:\t2.7.8\n",
            "INFO 2021-10-14 19:03:35,053 env.py:  50: NO_GCE_CHECK:\tTrue\n",
            "INFO 2021-10-14 19:03:35,053 env.py:  50: NVIDIA_DRIVER_CAPABILITIES:\tcompute,utility\n",
            "INFO 2021-10-14 19:03:35,054 env.py:  50: NVIDIA_REQUIRE_CUDA:\tcuda>=11.1 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 brand=tesla,driver>=450,driver<451\n",
            "INFO 2021-10-14 19:03:35,054 env.py:  50: NVIDIA_VISIBLE_DEVICES:\tall\n",
            "INFO 2021-10-14 19:03:35,054 env.py:  50: OLDPWD:\t/\n",
            "INFO 2021-10-14 19:03:35,054 env.py:  50: PAGER:\tcat\n",
            "INFO 2021-10-14 19:03:35,054 env.py:  50: PATH:\t/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n",
            "INFO 2021-10-14 19:03:35,054 env.py:  50: PWD:\t/content/vissl\n",
            "INFO 2021-10-14 19:03:35,054 env.py:  50: PYDEVD_USE_FRAME_EVAL:\tNO\n",
            "INFO 2021-10-14 19:03:35,054 env.py:  50: PYTHONPATH:\t/env/python\n",
            "INFO 2021-10-14 19:03:35,055 env.py:  50: PYTHONWARNINGS:\tignore:::pip._internal.cli.base_command\n",
            "INFO 2021-10-14 19:03:35,055 env.py:  50: RANK:\t0\n",
            "INFO 2021-10-14 19:03:35,055 env.py:  50: SHELL:\t/bin/bash\n",
            "INFO 2021-10-14 19:03:35,055 env.py:  50: SHLVL:\t1\n",
            "INFO 2021-10-14 19:03:35,055 env.py:  50: TBE_CREDS_ADDR:\t172.28.0.1:8008\n",
            "INFO 2021-10-14 19:03:35,055 env.py:  50: TERM:\txterm-color\n",
            "INFO 2021-10-14 19:03:35,055 env.py:  50: TF_FORCE_GPU_ALLOW_GROWTH:\ttrue\n",
            "INFO 2021-10-14 19:03:35,055 env.py:  50: WORLD_SIZE:\t1\n",
            "INFO 2021-10-14 19:03:35,056 env.py:  50: _:\t/usr/bin/python3\n",
            "INFO 2021-10-14 19:03:35,056 env.py:  50: __EGL_VENDOR_LIBRARY_DIRS:\t/usr/lib64-nvidia:/usr/share/glvnd/egl_vendor.d/\n",
            "INFO 2021-10-14 19:03:35,056 misc.py: 161: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-10-14 19:03:35,056 extract_features.py:  91: Setting seed....\n",
            "INFO 2021-10-14 19:03:35,056 misc.py: 173: MACHINE SEED: 0\n",
            "INFO 2021-10-14 19:03:35,058 hydra_config.py: 131: Training with config:\n",
            "INFO 2021-10-14 19:03:35,065 hydra_config.py: 140: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,\n",
            "                'AUTO_RESUME': True,\n",
            "                'BACKEND': 'disk',\n",
            "                'CHECKPOINT_FREQUENCY': 1,\n",
            "                'CHECKPOINT_ITER_FREQUENCY': -1,\n",
            "                'DIR': '/content/checkpoints',\n",
            "                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,\n",
            "                'OVERWRITE_EXISTING': False,\n",
            "                'USE_SYMLINK_CHECKPOINT_FOR_RESUME': False},\n",
            " 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',\n",
            "                'DATA_LIMIT': -1,\n",
            "                'DATA_LIMIT_SAMPLING': {'SEED': 0},\n",
            "                'FEATURES': {'DATASET_NAME': '',\n",
            "                             'DATA_PARTITION': 'TRAIN',\n",
            "                             'DIMENSIONALITY_REDUCTION': 0,\n",
            "                             'EXTRACT': False,\n",
            "                             'LAYER_NAME': '',\n",
            "                             'PATH': '.',\n",
            "                             'TEST_PARTITION': 'TEST'},\n",
            "                'NUM_CLUSTERS': 16000,\n",
            "                'NUM_ITER': 50,\n",
            "                'OUTPUT_DIR': '.'},\n",
            " 'DATA': {'DDP_BUCKET_CAP_MB': 25,\n",
            "          'ENABLE_ASYNC_GPU_COPY': True,\n",
            "          'NUM_DATALOADER_WORKERS': 5,\n",
            "          'PIN_MEMORY': True,\n",
            "          'TEST': {'BASE_DATASET': 'generic_ssl',\n",
            "                   'BATCHSIZE_PER_REPLICA': 2,\n",
            "                   'COLLATE_FUNCTION': 'default_collate',\n",
            "                   'COLLATE_FUNCTION_PARAMS': {},\n",
            "                   'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',\n",
            "                   'COPY_TO_LOCAL_DISK': False,\n",
            "                   'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                   'DATA_LIMIT': -1,\n",
            "                   'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,\n",
            "                                           'SEED': 0,\n",
            "                                           'SKIP_NUM_SAMPLES': 0},\n",
            "                   'DATA_PATHS': [],\n",
            "                   'DATA_SOURCES': ['disk_folder'],\n",
            "                   'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                   'DROP_LAST': False,\n",
            "                   'ENABLE_QUEUE_DATASET': False,\n",
            "                   'INPUT_KEY_NAMES': ['data'],\n",
            "                   'LABEL_PATHS': [],\n",
            "                   'LABEL_SOURCES': ['disk_folder'],\n",
            "                   'LABEL_TYPE': 'standard',\n",
            "                   'MMAP_MODE': False,\n",
            "                   'NEW_IMG_PATH_PREFIX': '',\n",
            "                   'RANDOM_SYNTHETIC_IMAGES': False,\n",
            "                   'REMOVE_IMG_PATH_PREFIX': '',\n",
            "                   'TARGET_KEY_NAMES': ['label'],\n",
            "                   'TRANSFORMS': [{'name': 'Resize', 'size': 256},\n",
            "                                  {'name': 'CenterCrop', 'size': 224},\n",
            "                                  {'name': 'ToTensor'},\n",
            "                                  {'mean': [0.485, 0.456, 0.406],\n",
            "                                   'name': 'Normalize',\n",
            "                                   'std': [0.229, 0.224, 0.225]}],\n",
            "                   'USE_DEBUGGING_SAMPLER': False,\n",
            "                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},\n",
            "          'TRAIN': {'BASE_DATASET': 'generic_ssl',\n",
            "                    'BATCHSIZE_PER_REPLICA': 2,\n",
            "                    'COLLATE_FUNCTION': 'default_collate',\n",
            "                    'COLLATE_FUNCTION_PARAMS': {},\n",
            "                    'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',\n",
            "                    'COPY_TO_LOCAL_DISK': False,\n",
            "                    'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                    'DATA_LIMIT': -1,\n",
            "                    'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,\n",
            "                                            'SEED': 0,\n",
            "                                            'SKIP_NUM_SAMPLES': 0},\n",
            "                    'DATA_PATHS': [],\n",
            "                    'DATA_SOURCES': ['disk_folder'],\n",
            "                    'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                    'DROP_LAST': False,\n",
            "                    'ENABLE_QUEUE_DATASET': False,\n",
            "                    'INPUT_KEY_NAMES': ['data'],\n",
            "                    'LABEL_PATHS': [],\n",
            "                    'LABEL_SOURCES': ['disk_folder'],\n",
            "                    'LABEL_TYPE': 'sample_index',\n",
            "                    'MMAP_MODE': False,\n",
            "                    'NEW_IMG_PATH_PREFIX': '',\n",
            "                    'RANDOM_SYNTHETIC_IMAGES': False,\n",
            "                    'REMOVE_IMG_PATH_PREFIX': '',\n",
            "                    'TARGET_KEY_NAMES': ['label'],\n",
            "                    'TRANSFORMS': [{'name': 'Resize', 'size': 256},\n",
            "                                   {'name': 'CenterCrop', 'size': 224},\n",
            "                                   {'name': 'ToTensor'},\n",
            "                                   {'mean': [0.485, 0.456, 0.406],\n",
            "                                    'name': 'Normalize',\n",
            "                                    'std': [0.229, 0.224, 0.225]}],\n",
            "                    'USE_DEBUGGING_SAMPLER': False,\n",
            "                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},\n",
            " 'DISTRIBUTED': {'BACKEND': 'nccl',\n",
            "                 'BROADCAST_BUFFERS': True,\n",
            "                 'INIT_METHOD': 'tcp',\n",
            "                 'MANUAL_GRADIENT_REDUCTION': False,\n",
            "                 'NCCL_DEBUG': False,\n",
            "                 'NCCL_SOCKET_NTHREADS': '',\n",
            "                 'NUM_NODES': 1,\n",
            "                 'NUM_PROC_PER_NODE': 1,\n",
            "                 'RUN_ID': 'auto'},\n",
            " 'EXTRACT_FEATURES': {'CHUNK_THRESHOLD': 0, 'OUTPUT_DIR': ''},\n",
            " 'HOOKS': {'LOG_GPU_STATS': True,\n",
            "           'MEMORY_SUMMARY': {'DUMP_MEMORY_ON_EXCEPTION': False,\n",
            "                              'LOG_ITERATION_NUM': 0,\n",
            "                              'PRINT_MEMORY_SUMMARY': True},\n",
            "           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,\n",
            "                                'INPUT_SHAPE': [3, 224, 224]},\n",
            "           'PERF_STATS': {'MONITOR_PERF_STATS': False,\n",
            "                          'PERF_STAT_FREQUENCY': -1,\n",
            "                          'ROLLING_BTIME_FREQ': -1},\n",
            "           'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': 'tensorboard',\n",
            "                                 'FLUSH_EVERY_N_MIN': 5,\n",
            "                                 'LOG_DIR': '.',\n",
            "                                 'LOG_PARAMS': True,\n",
            "                                 'LOG_PARAMS_EVERY_N_ITERS': 310,\n",
            "                                 'LOG_PARAMS_GRADIENTS': True,\n",
            "                                 'USE_TENSORBOARD': False}},\n",
            " 'IMG_RETRIEVAL': {'CROP_QUERY_ROI': False,\n",
            "                   'DATASET_PATH': '',\n",
            "                   'DEBUG_MODE': False,\n",
            "                   'EVAL_BINARY_PATH': '',\n",
            "                   'EVAL_DATASET_NAME': 'Paris',\n",
            "                   'FEATS_PROCESSING_TYPE': '',\n",
            "                   'GEM_POOL_POWER': 4.0,\n",
            "                   'IMG_SCALINGS': [1],\n",
            "                   'NORMALIZE_FEATURES': True,\n",
            "                   'NUM_DATABASE_SAMPLES': -1,\n",
            "                   'NUM_QUERY_SAMPLES': -1,\n",
            "                   'NUM_TRAINING_SAMPLES': -1,\n",
            "                   'N_PCA': 512,\n",
            "                   'RESIZE_IMG': 1024,\n",
            "                   'SAVE_FEATURES': False,\n",
            "                   'SAVE_RETRIEVAL_RANKINGS_SCORES': True,\n",
            "                   'SIMILARITY_MEASURE': 'cosine_similarity',\n",
            "                   'SPATIAL_LEVELS': 3,\n",
            "                   'TRAIN_DATASET_NAME': 'Oxford',\n",
            "                   'TRAIN_PCA_WHITENING': True,\n",
            "                   'USE_DISTRACTORS': False,\n",
            "                   'WHITEN_IMG_LIST': ''},\n",
            " 'LOG_FREQUENCY': 10,\n",
            " 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},\n",
            "          'barlow_twins_loss': {'embedding_dim': 8192,\n",
            "                                'lambda_': 0.0051,\n",
            "                                'scale_loss': 0.024},\n",
            "          'bce_logits_multiple_output_single_target': {'normalize_output': False,\n",
            "                                                       'reduction': 'none',\n",
            "                                                       'world_size': 1},\n",
            "          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,\n",
            "                                                          'normalize_output': False,\n",
            "                                                          'reduction': 'mean',\n",
            "                                                          'temperature': 1.0,\n",
            "                                                          'weight': None},\n",
            "          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,\n",
            "                                 'DROP_LAST': True,\n",
            "                                 'kmeans_iters': 10,\n",
            "                                 'memory_params': {'crops_for_mb': [0],\n",
            "                                                   'embedding_dim': 128},\n",
            "                                 'num_clusters': [3000, 3000, 3000],\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_train_samples': -1,\n",
            "                                 'temperature': 0.1},\n",
            "          'dino_loss': {'crops_for_teacher': [0, 1],\n",
            "                        'ema_center': 0.9,\n",
            "                        'momentum': 0.996,\n",
            "                        'normalize_last_layer': True,\n",
            "                        'output_dim': 65536,\n",
            "                        'student_temp': 0.1,\n",
            "                        'teacher_temp_max': 0.07,\n",
            "                        'teacher_temp_min': 0.04,\n",
            "                        'teacher_temp_warmup_iters': 37500},\n",
            "          'moco_loss': {'embedding_dim': 128,\n",
            "                        'momentum': 0.999,\n",
            "                        'queue_size': 65536,\n",
            "                        'temperature': 0.2},\n",
            "          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                               'embedding_dim': 128,\n",
            "                                                               'world_size': 64},\n",
            "                                             'num_crops': 2,\n",
            "                                             'temperature': 0.1},\n",
            "          'name': 'CrossEntropyLoss',\n",
            "          'nce_loss_with_memory': {'loss_type': 'nce',\n",
            "                                   'loss_weights': [1.0],\n",
            "                                   'memory_params': {'embedding_dim': 128,\n",
            "                                                     'memory_size': -1,\n",
            "                                                     'momentum': 0.5,\n",
            "                                                     'norm_init': True,\n",
            "                                                     'update_mem_on_forward': True},\n",
            "                                   'negative_sampling_params': {'num_negatives': 16000,\n",
            "                                                                'type': 'random'},\n",
            "                                   'norm_constant': -1,\n",
            "                                   'norm_embedding': True,\n",
            "                                   'num_train_samples': -1,\n",
            "                                   'temperature': 0.07,\n",
            "                                   'update_mem_with_emb_index': -100},\n",
            "          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                     'embedding_dim': 128,\n",
            "                                                     'world_size': 64},\n",
            "                                   'temperature': 0.1},\n",
            "          'swav_loss': {'crops_for_assign': [0, 1],\n",
            "                        'embedding_dim': 128,\n",
            "                        'epsilon': 0.05,\n",
            "                        'normalize_last_layer': True,\n",
            "                        'num_crops': 2,\n",
            "                        'num_iters': 3,\n",
            "                        'num_prototypes': [3000],\n",
            "                        'output_dir': '.',\n",
            "                        'queue': {'local_queue_length': 0,\n",
            "                                  'queue_length': 0,\n",
            "                                  'start_iter': 0},\n",
            "                        'temp_hard_assignment_iters': 0,\n",
            "                        'temperature': 0.1,\n",
            "                        'use_double_precision': False},\n",
            "          'swav_momentum_loss': {'crops_for_assign': [0, 1],\n",
            "                                 'embedding_dim': 128,\n",
            "                                 'epsilon': 0.05,\n",
            "                                 'momentum': 0.99,\n",
            "                                 'momentum_eval_mode_iter_start': 0,\n",
            "                                 'normalize_last_layer': True,\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_iters': 3,\n",
            "                                 'num_prototypes': [3000],\n",
            "                                 'queue': {'local_queue_length': 0,\n",
            "                                           'queue_length': 0,\n",
            "                                           'start_iter': 0},\n",
            "                                 'temperature': 0.1,\n",
            "                                 'use_double_precision': False}},\n",
            " 'MACHINE': {'DEVICE': 'gpu'},\n",
            " 'METERS': {'accuracy_list_meter': {'meter_names': [],\n",
            "                                    'num_meters': 1,\n",
            "                                    'topk_values': [1]},\n",
            "            'enable_training_meter': True,\n",
            "            'mean_ap_list_meter': {'max_cpu_capacity': -1,\n",
            "                                   'meter_names': [],\n",
            "                                   'num_classes': 9605,\n",
            "                                   'num_meters': 1},\n",
            "            'name': ''},\n",
            " 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,\n",
            "                                        'USE_ACTIVATION_CHECKPOINTING': False},\n",
            "           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'},\n",
            "                          'AMP_TYPE': 'apex',\n",
            "                          'USE_AMP': False},\n",
            "           'CUDA_CACHE': {'CLEAR_CUDA_CACHE': False, 'CLEAR_FREQ': 100},\n",
            "           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': True,\n",
            "                                     'EVAL_TRUNK_AND_HEAD': True,\n",
            "                                     'EXTRACT_TRUNK_FEATURES_ONLY': False,\n",
            "                                     'FREEZE_TRUNK_AND_HEAD': True,\n",
            "                                     'FREEZE_TRUNK_ONLY': False,\n",
            "                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [],\n",
            "                                     'SHOULD_FLATTEN_FEATS': True},\n",
            "           'FSDP_CONFIG': {'AUTO_WRAP_THRESHOLD': 0,\n",
            "                           'bucket_cap_mb': 0,\n",
            "                           'clear_autocast_cache': True,\n",
            "                           'compute_dtype': torch.float32,\n",
            "                           'flatten_parameters': True,\n",
            "                           'fp32_reduce_scatter': False,\n",
            "                           'mixed_precision': True,\n",
            "                           'verbose': True},\n",
            "           'GRAD_CLIP': {'MAX_NORM': 1, 'NORM_TYPE': 2, 'USE_GRAD_CLIP': False},\n",
            "           'HEAD': {'BATCHNORM_EPS': 1e-05,\n",
            "                    'BATCHNORM_MOMENTUM': 0.1,\n",
            "                    'PARAMS': [['mlp', {'dims': [2048, 1000]}]],\n",
            "                    'PARAMS_MULTIPLIER': 1.0},\n",
            "           'INPUT_TYPE': 'rgb',\n",
            "           'MULTI_INPUT_HEAD_MAPPING': [],\n",
            "           'NON_TRAINABLE_PARAMS': [],\n",
            "           'SHARDED_DDP_SETUP': {'USE_SDP': False, 'reduce_buffer_size': -1},\n",
            "           'SINGLE_PASS_EVERY_CROP': False,\n",
            "           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': False,\n",
            "                              'GROUP_SIZE': -1,\n",
            "                              'SYNC_BN_TYPE': 'pytorch'},\n",
            "           'TEMP_FROZEN_PARAMS_ITER_MAP': [],\n",
            "           'TRUNK': {'CONVIT': {'CLASS_TOKEN_IN_LOCAL_LAYERS': False,\n",
            "                                'LOCALITY_DIM': 10,\n",
            "                                'LOCALITY_STRENGTH': 1.0,\n",
            "                                'N_GPSA_LAYERS': 10,\n",
            "                                'USE_LOCAL_INIT': True},\n",
            "                     'EFFICIENT_NETS': {},\n",
            "                     'NAME': 'resnet',\n",
            "                     'REGNET': {},\n",
            "                     'RESNETS': {'DEPTH': 50,\n",
            "                                 'GROUPNORM_GROUPS': 32,\n",
            "                                 'GROUPS': 1,\n",
            "                                 'LAYER4_STRIDE': 2,\n",
            "                                 'NORM': 'BatchNorm',\n",
            "                                 'STANDARDIZE_CONVOLUTIONS': False,\n",
            "                                 'WIDTH_MULTIPLIER': 1,\n",
            "                                 'WIDTH_PER_GROUP': 64,\n",
            "                                 'ZERO_INIT_RESIDUAL': False},\n",
            "                     'VISION_TRANSFORMERS': {'ATTENTION_DROPOUT_RATE': 0,\n",
            "                                             'CLASSIFIER': 'token',\n",
            "                                             'DROPOUT_RATE': 0,\n",
            "                                             'DROP_PATH_RATE': 0,\n",
            "                                             'HIDDEN_DIM': 768,\n",
            "                                             'IMAGE_SIZE': 224,\n",
            "                                             'MLP_DIM': 3072,\n",
            "                                             'NUM_HEADS': 12,\n",
            "                                             'NUM_LAYERS': 12,\n",
            "                                             'PATCH_SIZE': 16,\n",
            "                                             'QKV_BIAS': False,\n",
            "                                             'QK_SCALE': False,\n",
            "                                             'name': None},\n",
            "                     'XCIT': {'ATTENTION_DROPOUT_RATE': 0,\n",
            "                              'DROPOUT_RATE': 0,\n",
            "                              'DROP_PATH_RATE': 0.05,\n",
            "                              'ETA': 1,\n",
            "                              'HIDDEN_DIM': 384,\n",
            "                              'IMAGE_SIZE': 224,\n",
            "                              'NUM_HEADS': 8,\n",
            "                              'NUM_LAYERS': 12,\n",
            "                              'PATCH_SIZE': 16,\n",
            "                              'QKV_BIAS': True,\n",
            "                              'QK_SCALE': False,\n",
            "                              'TOKENS_NORM': True,\n",
            "                              'name': None}},\n",
            "           'WEIGHTS_INIT': {'APPEND_PREFIX': '',\n",
            "                            'PARAMS_FILE': '/content/resnet_50_torchvision_vissl_compatible.torch',\n",
            "                            'REMOVE_PREFIX': '',\n",
            "                            'SKIP_LAYERS': ['num_batches_tracked'],\n",
            "                            'STATE_DICT_KEY_NAME': 'classy_state_dict'},\n",
            "           '_MODEL_INIT_SEED': 0},\n",
            " 'MONITORING': {'MONITOR_ACTIVATION_STATISTICS': 0},\n",
            " 'MULTI_PROCESSING_METHOD': 'forkserver',\n",
            " 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},\n",
            " 'OPTIMIZER': {'betas': [0.9, 0.999],\n",
            "               'construct_single_param_group_only': False,\n",
            "               'head_optimizer_params': {'use_different_lr': False,\n",
            "                                         'use_different_wd': False,\n",
            "                                         'weight_decay': 0.0001},\n",
            "               'larc_config': {'clip': False,\n",
            "                               'eps': 1e-08,\n",
            "                               'trust_coefficient': 0.001},\n",
            "               'momentum': 0.9,\n",
            "               'name': 'sgd',\n",
            "               'nesterov': False,\n",
            "               'non_regularized_parameters': [],\n",
            "               'num_epochs': 90,\n",
            "               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': False,\n",
            "                                                               'base_lr_batch_size': 256,\n",
            "                                                               'base_value': 0.1,\n",
            "                                                               'scaling_type': 'linear'},\n",
            "                                           'end_value': 0.0,\n",
            "                                           'interval_scaling': [],\n",
            "                                           'lengths': [],\n",
            "                                           'milestones': [30, 60],\n",
            "                                           'name': 'multistep',\n",
            "                                           'schedulers': [],\n",
            "                                           'start_value': 0.1,\n",
            "                                           'update_interval': 'epoch',\n",
            "                                           'value': 0.1,\n",
            "                                           'values': [0.1, 0.01, 0.001]},\n",
            "                                    'lr_head': {'auto_lr_scaling': {'auto_scale': False,\n",
            "                                                                    'base_lr_batch_size': 256,\n",
            "                                                                    'base_value': 0.1,\n",
            "                                                                    'scaling_type': 'linear'},\n",
            "                                                'end_value': 0.0,\n",
            "                                                'interval_scaling': [],\n",
            "                                                'lengths': [],\n",
            "                                                'milestones': [30, 60],\n",
            "                                                'name': 'multistep',\n",
            "                                                'schedulers': [],\n",
            "                                                'start_value': 0.1,\n",
            "                                                'update_interval': 'epoch',\n",
            "                                                'value': 0.1,\n",
            "                                                'values': [0.1, 0.01, 0.001]}},\n",
            "               'regularize_bias': True,\n",
            "               'regularize_bn': False,\n",
            "               'use_larc': False,\n",
            "               'use_zero': False,\n",
            "               'weight_decay': 0.0001},\n",
            " 'PROFILING': {'MEMORY_PROFILING': {'TRACK_BY_LAYER_MEMORY': False},\n",
            "               'NUM_ITERATIONS': 10,\n",
            "               'OUTPUT_FOLDER': '.',\n",
            "               'PROFILED_RANKS': [0, 1],\n",
            "               'RUNTIME_PROFILING': {'LEGACY_PROFILER': False,\n",
            "                                     'PROFILE_CPU': True,\n",
            "                                     'PROFILE_GPU': True,\n",
            "                                     'USE_PROFILER': False},\n",
            "               'START_ITERATION': 0,\n",
            "               'STOP_TRAINING_AFTER_PROFILING': False,\n",
            "               'WARMUP_ITERATIONS': 0},\n",
            " 'REPRODUCIBILITY': {'CUDDN_DETERMINISTIC': False},\n",
            " 'SEED_VALUE': 0,\n",
            " 'SLURM': {'ADDITIONAL_PARAMETERS': {},\n",
            "           'COMMENT': 'vissl job',\n",
            "           'CONSTRAINT': '',\n",
            "           'LOG_FOLDER': '.',\n",
            "           'MEM_GB': 250,\n",
            "           'NAME': 'vissl',\n",
            "           'NUM_CPU_PER_PROC': 8,\n",
            "           'PARTITION': '',\n",
            "           'PORT_ID': 40050,\n",
            "           'TIME_HOURS': 72,\n",
            "           'TIME_MINUTES': 0,\n",
            "           'USE_SLURM': False},\n",
            " 'SVM': {'cls_list': [],\n",
            "         'costs': {'base': -1.0,\n",
            "                   'costs_list': [0.1, 0.01],\n",
            "                   'power_range': [4, 20]},\n",
            "         'cross_val_folds': 3,\n",
            "         'dual': True,\n",
            "         'force_retrain': False,\n",
            "         'loss': 'squared_hinge',\n",
            "         'low_shot': {'dataset_name': 'voc',\n",
            "                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],\n",
            "                      'sample_inds': [1, 2, 3, 4, 5]},\n",
            "         'max_iter': 2000,\n",
            "         'normalize': True,\n",
            "         'penalty': 'l2'},\n",
            " 'TEST_EVERY_NUM_EPOCH': 1,\n",
            " 'TEST_MODEL': True,\n",
            " 'TEST_ONLY': False,\n",
            " 'TRAINER': {'TASK_NAME': 'self_supervision_task',\n",
            "             'TRAIN_STEP_NAME': 'standard_train_step'},\n",
            " 'VERBOSE': False}\n",
            "INFO 2021-10-14 19:03:35,728 extract_features.py: 103: System config:\n",
            "-------------------  ---------------------------------------------------------------\n",
            "sys.platform         linux\n",
            "Python               3.7.12 (default, Sep 10 2021, 00:21:48) [GCC 7.5.0]\n",
            "numpy                1.19.5\n",
            "Pillow               7.1.2\n",
            "vissl                0.1.6 @/content/vissl/vissl\n",
            "GPU available        True\n",
            "GPU 0                Tesla K80\n",
            "CUDA_HOME            /usr/local/cuda\n",
            "torchvision          0.9.0+cu101 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "hydra                1.0.7 @/usr/local/lib/python3.7/dist-packages/hydra\n",
            "classy_vision        0.7.0.dev @/usr/local/lib/python3.7/dist-packages/classy_vision\n",
            "tensorboard          2.6.0\n",
            "apex                 0.1 @/usr/local/lib/python3.7/dist-packages/apex\n",
            "cv2                  4.1.2\n",
            "PyTorch              1.8.0+cu101 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build  False\n",
            "-------------------  ---------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 10.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.1, CUDNN_VERSION=7.6.3, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
            "\n",
            "CPU info:\n",
            "-------------------  ------------------------------\n",
            "Architecture         x86_64\n",
            "CPU op-mode(s)       32-bit, 64-bit\n",
            "Byte Order           Little Endian\n",
            "CPU(s)               2\n",
            "On-line CPU(s) list  0,1\n",
            "Thread(s) per core   2\n",
            "Core(s) per socket   1\n",
            "Socket(s)            1\n",
            "NUMA node(s)         1\n",
            "Vendor ID            GenuineIntel\n",
            "CPU family           6\n",
            "Model                63\n",
            "Model name           Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "Stepping             0\n",
            "CPU MHz              2299.998\n",
            "BogoMIPS             4599.99\n",
            "Hypervisor vendor    KVM\n",
            "Virtualization type  full\n",
            "L1d cache            32K\n",
            "L1i cache            32K\n",
            "L2 cache             256K\n",
            "L3 cache             46080K\n",
            "NUMA node0 CPU(s)    0,1\n",
            "-------------------  ------------------------------\n",
            "INFO 2021-10-14 19:03:35,728 trainer_main.py: 113: Using Distributed init method: tcp://localhost:43987, world_size: 1, rank: 0\n",
            "INFO 2021-10-14 19:03:35,729 distributed_c10d.py: 187: Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "INFO 2021-10-14 19:03:35,730 trainer_main.py: 134: | initialized host 3af1980960bc as rank 0 (0)\n",
            "INFO 2021-10-14 19:03:37,831 train_task.py: 181: Not using Automatic Mixed Precision\n",
            "INFO 2021-10-14 19:03:37,832 ssl_dataset.py: 157: Rank: 0 split: TEST Data files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-10-14 19:03:37,833 ssl_dataset.py: 160: Rank: 0 split: TEST Label files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-10-14 19:03:37,833 disk_dataset.py:  86: Loaded 10 samples from folder /content/dummy_data/val\n",
            "INFO 2021-10-14 19:03:37,833 ssl_dataset.py: 157: Rank: 0 split: TRAIN Data files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-10-14 19:03:37,834 ssl_dataset.py: 160: Rank: 0 split: TRAIN Label files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-10-14 19:03:37,834 disk_dataset.py:  86: Loaded 10 samples from folder /content/dummy_data/train\n",
            "INFO 2021-10-14 19:03:37,834 misc.py: 161: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-10-14 19:03:37,834 __init__.py: 126: Created the Distributed Sampler....\n",
            "INFO 2021-10-14 19:03:37,834 __init__.py: 101: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "INFO 2021-10-14 19:03:37,835 __init__.py: 215: Wrapping the dataloader to async device copies\n",
            "INFO 2021-10-14 19:03:37,836 misc.py: 161: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-10-14 19:03:37,836 __init__.py: 126: Created the Distributed Sampler....\n",
            "INFO 2021-10-14 19:03:37,836 __init__.py: 101: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "INFO 2021-10-14 19:03:37,836 __init__.py: 215: Wrapping the dataloader to async device copies\n",
            "INFO 2021-10-14 19:03:37,836 train_task.py: 449: Building model....\n",
            "INFO 2021-10-14 19:03:37,837 resnext.py:  68: ResNeXT trunk, supports activation checkpointing. Deactivated\n",
            "INFO 2021-10-14 19:03:37,837 resnext.py:  88: Building model: ResNeXt50-1x64d-w1-BatchNorm2d\n",
            "INFO 2021-10-14 19:03:38,591 train_task.py: 473: config.MODEL.FEATURE_EVAL_SETTINGS.FREEZE_TRUNK_AND_HEAD=True, will freeze trunk and head...\n",
            "INFO 2021-10-14 19:03:38,591 base_ssl_model.py: 206: Freezing model...\n",
            "INFO 2021-10-14 19:03:38,592 base_ssl_model.py: 194: Freezing model trunk...\n",
            "INFO 2021-10-14 19:03:38,592 base_ssl_model.py: 185: Freezing model heads...\n",
            "INFO 2021-10-14 19:03:38,593 train_task.py: 423: Initializing model from: /content/resnet_50_torchvision_vissl_compatible.torch\n",
            "INFO 2021-10-14 19:03:38,593 util.py: 276: Attempting to load checkpoint from /content/resnet_50_torchvision_vissl_compatible.torch\n",
            "INFO 2021-10-14 19:03:38,657 util.py: 281: Loaded checkpoint from /content/resnet_50_torchvision_vissl_compatible.torch\n",
            "INFO 2021-10-14 19:03:38,657 util.py: 240: Broadcasting checkpoint loaded from /content/resnet_50_torchvision_vissl_compatible.torch\n",
            "INFO 2021-10-14 19:03:42,391 train_task.py: 429: Checkpoint loaded: /content/resnet_50_torchvision_vissl_compatible.torch...\n",
            "INFO 2021-10-14 19:03:42,393 checkpoint.py: 886: Loaded: trunk._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,393 checkpoint.py: 886: Loaded: trunk._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,393 checkpoint.py: 886: Loaded: trunk._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,393 checkpoint.py: 886: Loaded: trunk._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,393 checkpoint.py: 886: Loaded: trunk._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,393 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,394 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,394 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,394 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,394 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,394 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,394 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,395 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,395 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,395 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,395 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,395 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,395 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,396 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,396 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,396 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,396 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,396 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,396 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,396 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,397 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,397 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,397 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,397 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,397 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,397 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,397 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,398 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,398 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,398 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,398 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,398 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,398 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,399 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,399 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,399 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,399 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,399 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,399 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,399 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,400 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,400 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,400 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,400 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,400 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,400 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,400 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,400 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,401 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,401 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,401 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,401 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,401 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,401 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,401 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,402 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,402 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,402 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,402 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,402 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,402 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer1.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,402 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,403 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,403 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,403 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,403 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,403 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,404 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,404 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,404 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,404 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,404 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,404 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,404 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,405 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,405 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,405 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,405 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,405 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,405 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,406 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,406 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,406 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,406 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,406 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,406 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,407 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,407 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,407 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,407 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,407 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,407 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,408 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,408 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,408 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,408 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,408 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,408 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,408 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,409 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,409 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,409 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,409 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,409 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,409 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,410 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,410 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,410 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,410 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,410 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,410 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,411 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,411 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,411 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,456 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,457 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,457 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,457 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,457 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,457 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,458 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,458 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,458 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,458 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,458 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,459 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,459 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.3.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,459 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,459 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,460 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,460 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,460 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,460 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.3.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,460 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,461 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,461 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,461 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,461 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,462 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer2.3.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,462 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,462 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,462 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,462 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,463 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,463 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,464 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,464 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,464 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,464 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,464 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,464 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,465 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,465 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,465 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,465 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,465 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,465 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,466 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,466 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,466 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,466 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,466 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,467 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,467 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,467 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,467 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,467 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,468 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,468 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,468 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,468 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,469 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,469 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,469 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,469 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,469 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,469 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,470 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,470 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,470 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,470 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,470 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,471 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,471 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,471 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,471 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,471 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,472 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,472 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,472 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,472 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,473 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,473 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,473 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,473 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,473 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,473 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,474 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,474 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,474 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,474 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,474 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,475 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,475 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,475 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.3.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,475 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,476 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,476 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,476 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,476 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,476 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.3.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,477 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,477 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,477 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,477 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,477 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,477 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.3.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,478 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,478 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,478 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,478 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,478 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,478 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.4.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,479 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,479 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,479 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,479 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,479 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,479 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.4.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,480 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,480 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,480 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,480 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,481 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,481 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.4.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,481 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,481 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,481 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,481 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,482 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,482 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.5.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,483 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,483 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,483 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,483 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,483 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,483 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.5.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,484 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,484 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,484 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,484 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,484 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,484 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer3.5.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,485 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,485 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,485 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,485 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,485 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,486 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,488 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,488 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,488 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,488 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,488 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,564 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,565 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,566 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,566 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,566 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,566 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,567 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,569 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,569 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,569 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,570 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,570 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,570 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,571 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,571 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,571 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,572 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,572 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,572 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,574 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,574 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,574 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,575 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,575 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,575 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,576 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,576 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,576 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,577 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,577 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,577 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,578 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,578 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,578 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,579 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,579 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,579 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,581 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,581 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,582 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,582 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,582 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,582 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,583 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,583 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,583 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,584 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,584 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,584 checkpoint.py: 851: Ignored layer:\ttrunk._feature_blocks.layer4.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-14 19:03:42,586 checkpoint.py: 886: Loaded: heads.0.clf.0.weight                                            of shape: torch.Size([1000, 2048]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,586 checkpoint.py: 886: Loaded: heads.0.clf.0.bias                                              of shape: torch.Size([1000]) from checkpoint\n",
            "INFO 2021-10-14 19:03:42,586 checkpoint.py: 901: Extra layers not loaded from checkpoint: []\n",
            "INFO 2021-10-14 19:03:42,645 trainer_main.py: 352: Model is:\n",
            " Classy <class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'>:\n",
            "BaseSSLMultiInputOutputModel(\n",
            "  (_heads): ModuleDict()\n",
            "  (trunk): ResNeXt(\n",
            "    (_feature_blocks): ModuleDict(\n",
            "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1_relu): ReLU(inplace=True)\n",
            "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (layer1): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer2): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer3): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (4): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (5): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer4): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), bias=False)\n",
            "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "      (flatten): Flatten()\n",
            "    )\n",
            "  )\n",
            "  (heads): ModuleList(\n",
            "    (0): MLP(\n",
            "      (clf): Sequential(\n",
            "        (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (dummy_layer): Linear(in_features=4, out_features=4, bias=True)\n",
            ")\n",
            "INFO 2021-10-14 19:03:42,668 trainer_main.py: 362: ============== Split: TEST =======================\n",
            "INFO 2021-10-14 19:03:42,668 trainer_main.py: 363: Extracting features for partition: test\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-10-14 19:03:48,176 trainer_main.py: 423: Model set to eval mode during feature extraction...\n",
            "INFO 2021-10-14 19:03:49,548 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_heads_features.npy\n",
            "INFO 2021-10-14 19:03:49,549 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_heads_features.npy\n",
            "INFO 2021-10-14 19:03:49,549 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:49,549 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:49,550 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:49,550 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:49,573 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk1_test_heads_features.npy\n",
            "INFO 2021-10-14 19:03:49,573 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk1_test_heads_features.npy\n",
            "INFO 2021-10-14 19:03:49,573 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk1_test_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:49,574 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk1_test_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:49,574 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk1_test_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:49,574 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk1_test_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:49,596 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk2_test_heads_features.npy\n",
            "INFO 2021-10-14 19:03:49,597 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk2_test_heads_features.npy\n",
            "INFO 2021-10-14 19:03:49,597 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk2_test_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:49,597 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk2_test_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:49,597 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk2_test_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:49,598 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk2_test_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:49,620 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk3_test_heads_features.npy\n",
            "INFO 2021-10-14 19:03:49,621 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk3_test_heads_features.npy\n",
            "INFO 2021-10-14 19:03:49,621 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk3_test_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:49,621 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk3_test_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:49,622 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk3_test_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:49,622 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk3_test_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:49,679 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk4_test_heads_features.npy\n",
            "INFO 2021-10-14 19:03:49,680 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk4_test_heads_features.npy\n",
            "INFO 2021-10-14 19:03:49,680 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk4_test_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:49,681 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk4_test_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:49,681 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk4_test_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:49,681 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk4_test_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:49,681 trainer_main.py: 366: Done getting features for partition: test\n",
            "INFO 2021-10-14 19:03:49,681 trainer_main.py: 362: ============== Split: TRAIN =======================\n",
            "INFO 2021-10-14 19:03:49,682 trainer_main.py: 363: Extracting features for partition: train\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-10-14 19:03:55,125 trainer_main.py: 423: Model set to eval mode during feature extraction...\n",
            "INFO 2021-10-14 19:03:55,154 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_heads_features.npy\n",
            "INFO 2021-10-14 19:03:55,154 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_heads_features.npy\n",
            "INFO 2021-10-14 19:03:55,154 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:55,155 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:55,155 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:55,156 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:55,178 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk1_train_heads_features.npy\n",
            "INFO 2021-10-14 19:03:55,178 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk1_train_heads_features.npy\n",
            "INFO 2021-10-14 19:03:55,178 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk1_train_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:55,179 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk1_train_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:55,179 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk1_train_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:55,179 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk1_train_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:55,201 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk2_train_heads_features.npy\n",
            "INFO 2021-10-14 19:03:55,202 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk2_train_heads_features.npy\n",
            "INFO 2021-10-14 19:03:55,202 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk2_train_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:55,202 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk2_train_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:55,203 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk2_train_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:55,203 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk2_train_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:55,225 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk3_train_heads_features.npy\n",
            "INFO 2021-10-14 19:03:55,226 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk3_train_heads_features.npy\n",
            "INFO 2021-10-14 19:03:55,226 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk3_train_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:55,226 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk3_train_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:55,226 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk3_train_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:55,227 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk3_train_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:55,292 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk4_train_heads_features.npy\n",
            "INFO 2021-10-14 19:03:55,293 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk4_train_heads_features.npy\n",
            "INFO 2021-10-14 19:03:55,293 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk4_train_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:55,293 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk4_train_heads_targets.npy\n",
            "INFO 2021-10-14 19:03:55,293 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk4_train_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:55,294 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk4_train_heads_inds.npy\n",
            "INFO 2021-10-14 19:03:55,294 trainer_main.py: 366: Done getting features for partition: train\n",
            "INFO 2021-10-14 19:03:55,381 extract_features.py: 108: All Done!\n",
            "INFO 2021-10-14 19:03:55,381 logger.py:  73: Shutting down loggers...\n",
            "INFO 2021-10-14 19:03:55,382 distributed_launcher.py: 168: All Done!\n",
            "INFO 2021-10-14 19:03:55,382 logger.py:  73: Shutting down loggers...\n"
          ]
        }
      ],
      "source": [
        "!python3 tools/run_distributed_engines.py \\\n",
        "    hydra.verbose=true \\\n",
        "    config=feature_extraction/extract_resnet_in1k_8gpu \\\n",
        "    +config/feature_extraction/with_head=rn50_supervised.yaml \\\n",
        "    config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DATA.TEST.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TEST.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DISTRIBUTED.NUM_NODES=1 \\\n",
        "    config.DISTRIBUTED.NUM_PROC_PER_NODE=1 \\\n",
        "    config.CHECKPOINT.DIR=\"/content/checkpoints\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.PARAMS_FILE=\"/content/resnet_50_torchvision_vissl_compatible.torch\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HT6UsjqUXeq"
      },
      "source": [
        "And we are done!! We have the features for the output of the HEAD. Here we have output the features, the data indexes, and the targets of each image. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKe9jGPZUWOe",
        "outputId": "05d0725c-c064-4059-9aa5-8ade9ed9f8ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rank0_chunk0_test_heads_features.npy\n",
            "rank0_chunk0_test_heads_inds.npy\n",
            "rank0_chunk0_test_heads_targets.npy\n",
            "rank0_chunk0_train_heads_features.npy\n",
            "rank0_chunk0_train_heads_inds.npy\n",
            "rank0_chunk0_train_heads_targets.npy\n",
            "rank0_chunk1_test_heads_features.npy\n",
            "rank0_chunk1_test_heads_inds.npy\n",
            "rank0_chunk1_test_heads_targets.npy\n",
            "rank0_chunk1_train_heads_features.npy\n",
            "rank0_chunk1_train_heads_inds.npy\n",
            "rank0_chunk1_train_heads_targets.npy\n",
            "rank0_chunk2_test_heads_features.npy\n",
            "rank0_chunk2_test_heads_inds.npy\n",
            "rank0_chunk2_test_heads_targets.npy\n",
            "rank0_chunk2_train_heads_features.npy\n",
            "rank0_chunk2_train_heads_inds.npy\n",
            "rank0_chunk2_train_heads_targets.npy\n",
            "rank0_chunk3_test_heads_features.npy\n",
            "rank0_chunk3_test_heads_inds.npy\n",
            "rank0_chunk3_test_heads_targets.npy\n",
            "rank0_chunk3_train_heads_features.npy\n",
            "rank0_chunk3_train_heads_inds.npy\n",
            "rank0_chunk3_train_heads_targets.npy\n",
            "rank0_chunk4_test_heads_features.npy\n",
            "rank0_chunk4_test_heads_inds.npy\n",
            "rank0_chunk4_test_heads_targets.npy\n",
            "rank0_chunk4_train_heads_features.npy\n",
            "rank0_chunk4_train_heads_inds.npy\n",
            "rank0_chunk4_train_heads_targets.npy\n"
          ]
        }
      ],
      "source": [
        "!ls /content/checkpoints/ | grep heads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ3lnT4kI4sD"
      },
      "source": [
        "# Extract the Output of the Model Head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT7dYR8NQ9_0"
      },
      "source": [
        "We are ready to extract the HEAD now. We will reuse the same dataset and base configuration and change a few configuration options. \n",
        "\n",
        "In the launch_distributed command above, we will replace \n",
        "\n",
        "\n",
        "```\n",
        "+config/trunk_only=feature_extraction/trunk_only=rn50_layers.yaml \\\n",
        "```\n",
        "\n",
        "with the following:\n",
        "\n",
        "```\n",
        "+config/trunk_only=feature_extraction/with_head=rn50_supervised.yaml \\\n",
        "```\n",
        "\n",
        "Taking a look at the differences between the two config options\n",
        "\n",
        "\n",
        "```yaml\n",
        "# feature_extraction/trunk_only/rn50_layers.yaml\n",
        "# @package _global_\n",
        "config:\n",
        "  MODEL:\n",
        "    FEATURE_EVAL_SETTINGS:\n",
        "      EVAL_MODE_ON: True\n",
        "      FREEZE_TRUNK_ONLY: True\n",
        "      EXTRACT_TRUNK_FEATURES_ONLY: True\n",
        "      SHOULD_FLATTEN_FEATS: False\n",
        "      LINEAR_EVAL_FEAT_POOL_OPS_MAP: [\n",
        "        [\"conv1\", [\"AvgPool2d\", [[10, 10], 10, 4]]],\n",
        "        [\"res2\", [\"AvgPool2d\", [[16, 16], 8, 0]]],\n",
        "        [\"res3\", [\"AvgPool2d\", [[13, 13], 5, 0]]],\n",
        "        [\"res4\", [\"AvgPool2d\", [[8, 8], 3, 0]]],\n",
        "        [\"res5\", [\"AvgPool2d\", [[6, 6], 1, 0]]],\n",
        "        [\"res5avg\", [\"Identity\", []]],\n",
        "      ]\n",
        "    TRUNK:\n",
        "      NAME: resnet\n",
        "      RESNETS:\n",
        "        DEPTH: 50\n",
        "  EXTRACT_FEATURES:\n",
        "    CHUNK_THRESHOLD: -1\n",
        "```\n",
        "\n",
        "```yaml\n",
        "# feature_extraction/with_head/rn50_supervised.yaml\n",
        "# @package _global_\n",
        "config:\n",
        "  MODEL:\n",
        "    FEATURE_EVAL_SETTINGS:\n",
        "      EVAL_MODE_ON: True\n",
        "      FREEZE_TRUNK_AND_HEAD: True\n",
        "      EVAL_TRUNK_AND_HEAD: True\n",
        "    TRUNK:\n",
        "      NAME: resnet\n",
        "      RESNETS:\n",
        "        DEPTH: 50\n",
        "    HEAD:\n",
        "      PARAMS: [\n",
        "        [\"mlp\", {\"dims\": [2048, 1000]}],\n",
        "      ]\n",
        "  EXTRACT_FEATURES:\n",
        "    CHUNK_THRESHOLD: -1\n",
        "```\n",
        "\n",
        "- For both configs we set `EVAL_MODE_ON: True`.\n",
        "- Since we are not training, we want to freeze the weights. For extracting the TRUNK, we set: `FREEZE_TRUNK_ONLY: True`, whereas for extracting the HEAD, we set `FREEZE_TRUNK_AND_HEAD: True`. \n",
        "- To extract the TRUNK features, we set `EXTRACT_TRUNK_FEATURES_ONLY: True`, since we want to preserve the tensor's shape, we set `SHOULD_FLATTEN_FEATS: False`, and finally we specify the layers we want to extract in `LINEAR_EVAL_FEAT_POOL_OPS_MAP`.\n",
        "- To extract the HEAD, we set `EVAL_TRUNK_AND_HEAD: True`. We also need to specify the HEAD model, here we have a (2048,1000),fully-connected linear layer from the TRUNK to the model output. And finally, \n",
        "- Finally CHUNK_THRESHOLD controls how many features to accumulate before writing them to disk. The option of `-1` means to keep all in memory before writing to disk.\n",
        "\n",
        "As a reminder please check the `vissl/config/defaults.yaml` file for more information on all config options."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5rUvPxZE5B5"
      },
      "source": [
        "# Loading Extracted Head Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEjEwNLHJqZM"
      },
      "source": [
        "Using the same [API](https://github.com/facebookresearch/vissl/blob/v0.1.6/vissl/utils/extract_features_utils.py) as above, we can load the HEAD features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4WjC3B9EtWJ",
        "outputId": "62d41223-d45c-4ff7-900d-436560e32f1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Head train features have the following shape: (10, 1000)\n",
            "Head train indexes have the following shape: (10,)\n",
            "Head train targets have the following shape: (10, 1)\n"
          ]
        }
      ],
      "source": [
        "from vissl.utils.extract_features_utils import ExtractedFeaturesLoader\n",
        "\n",
        "# We will load the res5 test features\n",
        "features = ExtractedFeaturesLoader.load_features(\n",
        "  input_dir=\"/content/checkpoints/\",\n",
        "  split=\"train\", \n",
        "  layer=\"heads\"\n",
        ")\n",
        "\n",
        "# Access the shapes of each of the features.\n",
        "feature_shape = features['features'].shape\n",
        "indeces_shape = features['inds'].shape\n",
        "targets_shape = features['targets'].shape\n",
        "\n",
        "print(f\"Head train features have the following shape: {feature_shape}\")\n",
        "print(f\"Head train indexes have the following shape: {indeces_shape}\")\n",
        "print(f\"Head train targets have the following shape: {targets_shape}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Feature Extraction V0.1.6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
