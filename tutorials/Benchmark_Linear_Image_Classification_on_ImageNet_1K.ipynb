{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Benchmark Linear Image Classification on ImageNet-1K.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XzxTZfKwFNo"
      },
      "source": [
        "# Benchmark Linear Image Classification on ImageNet-1K\n",
        "\n",
        "In this tutorial, we look at a simple example of how to use VISSL to run linear image classification benchmark for [ResNet-50 Torchvision pre-trained model](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L16). This benchmark freezes the model trunk and attaches a linear MLP on top of the trunk features.\n",
        "\n",
        "You can make a copy of this tutorial by `File -> Open in playground mode` and make changes there. DO NOT request access to this tutorial.\n",
        "\n",
        "**NOTE:** Please ensure your Collab Notebook has GPU available. To ensure/select this, simple follow: `Edit -> Notebook Settings -> select GPU`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VohdWhBSw69e"
      },
      "source": [
        "## Install VISSL\n",
        "\n",
        "Installing VISSL is pretty straightfoward. We will use pip binaries of VISSL and follow instructions from [here](https://github.com/facebookresearch/vissl/blob/master/INSTALL.md#install-vissl-pip-package)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5ISg59KTOqU"
      },
      "source": [
        "# Install: PyTorch (we assume 1.5.1 but VISSL works with all PyTorch versions >=1.4)\n",
        "!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install opencv\n",
        "!pip install opencv-python\n",
        "\n",
        "# install apex by checking system settings: cuda version, pytorch version, python version\n",
        "import sys\n",
        "import torch\n",
        "version_str=\"\".join([\n",
        "    f\"py3{sys.version_info.minor}_cu\",\n",
        "    torch.version.cuda.replace(\".\",\"\"),\n",
        "    f\"_pyt{torch.__version__[0:5:2]}\"\n",
        "])\n",
        "print(version_str)\n",
        "\n",
        "# install apex (pre-compiled with optimizer C++ extensions and CUDA kernels)\n",
        "!pip install apex -f https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/{version_str}/download.html\n",
        "\n",
        "# install VISSL\n",
        "!pip install vissl -f https://dl.fbaipublicfiles.com/vissl/packaging/visslwheels/download.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Fxe3MWxqsI"
      },
      "source": [
        "VISSL should be successfuly installed by now and all the dependencies should be available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np6atgoOTPrA"
      },
      "source": [
        "import vissl\n",
        "import tensorboard\n",
        "import apex\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFEHZ4KdxzWq"
      },
      "source": [
        "## YAML config file for Linear benchmark\n",
        "\n",
        "VISSL provides yaml configuration files for all benchmark tasks including linear image classification on ImageNet [here](https://github.com/facebookresearch/vissl/tree/master/configs/config/benchmark). \n",
        "\n",
        "For the purpose of this tutorial, we will use [this config file](https://github.com/facebookresearch/vissl/blob/master/configs/config/test/integration_test/quick_eval_in1k_linear_imagefolder_head.yaml) for training a linear classifier on the trunk output of ResNet-50 supervised model on 1-gpu. Let's go ahead and download the [example config file](https://github.com/facebookresearch/vissl/blob/master/configs/config/test/integration_test/quick_eval_in1k_linear_imagefolder_head.yaml).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ufyNAeUaDSs"
      },
      "source": [
        "!mkdir -p configs/config\n",
        "!wget -q -O configs/__init__.py https://dl.fbaipublicfiles.com/vissl/tutorials/configs/__init__.py \n",
        "!wget -q -O configs/config/eval_in1k_linear_imagefolder_head.yaml https://dl.fbaipublicfiles.com/vissl/tutorials/configs/eval_in1k_linear_imagefolder_head.yaml"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxMXLYLpsJXj"
      },
      "source": [
        "## Download the ResNet-50 weights from Torchvision\n",
        "\n",
        "We download the weights from the [torchvision ResNet50 model](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L16):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv0quZwFsWxs"
      },
      "source": [
        "!wget https://download.pytorch.org/models/resnet50-19c8e357.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndNMJGSRyffl"
      },
      "source": [
        "## Builtin training tool in VISSL\n",
        "\n",
        "VISSL also provides a [helper python tool](https://github.com/facebookresearch/vissl/blob/master/tools/run_distributed_engines.py) that allows to use VISSL for training purposes. This tool offers:\n",
        "- allows training and feature extraction both using VISSL. \n",
        "- also allows training on 1-gpu or multi-gpu. \n",
        "- can be used to launch multi-machine distributed training.\n",
        "\n",
        "Let's go ahead and download this tool directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6io7qQWzCbw"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/vissl/tutorials/run_distributed_engines.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0hng2EPY7pr"
      },
      "source": [
        "## Creating a custom data\n",
        "\n",
        "For the purpose of this tutorial, since we don't have ImageNet on the disk, we will create a dummy dataset by copying an image from COCO dataset in ImageNet dataset folder style as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-sy6nD-RfwB"
      },
      "source": [
        "!mkdir -p dummy_data/train/class1\n",
        "!mkdir -p dummy_data/train/class2\n",
        "!mkdir -p dummy_data/val/class1\n",
        "!mkdir -p dummy_data/val/class2\n",
        "\n",
        "# create 2 classes in train and add 2 images per class\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img5.jpg\n",
        "\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img5.jpg\n",
        "\n",
        "# create 2 classes in val and add 2 images per class\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img5.jpg\n",
        "\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img5.jpg\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPGCiTsXZeW3"
      },
      "source": [
        "## Using the custom data in VISSL\n",
        "\n",
        "Next step for us is to register the dummy data we created above with VISSL. Registering the dataset involves telling VISSL about the dataset name and the paths for the dataset. For this, we create a simple json file with the metadata and save it to `configs/config/dataset_catalog.py` file.\n",
        "\n",
        "**NOTE**: VISSL uses the specific `dataset_catalog.json` under the path `configs/config/dataset_catalog.json`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8Q6LCqaWjl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc12d947-6602-41da-a47a-c930a055c529"
      },
      "source": [
        "json_data = {\n",
        "    \"dummy_data_folder\": {\n",
        "      \"train\": [\n",
        "        \"/content/dummy_data/train\", \"/content/dummy_data/train\"\n",
        "      ],\n",
        "      \"val\": [\n",
        "        \"/content/dummy_data/val\", \"/content/dummy_data/val\"\n",
        "      ]\n",
        "    }\n",
        "}\n",
        "\n",
        "# use VISSL's api to save or you can use your custom code.\n",
        "from vissl.utils.io import save_file\n",
        "save_file(json_data, \"/content/configs/config/dataset_catalog.json\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otN1pB32cBHK"
      },
      "source": [
        "Next, we verify that the dataset is registered with VISSL. For that we query VISSL's dataset catalog as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZBhH-s5bcHd",
        "outputId": "693e5446-f777-4761-a39b-e33cd9162586"
      },
      "source": [
        "from vissl.data.dataset_catalog import VisslDatasetCatalog\n",
        "\n",
        "# list all the datasets that exist in catalog\n",
        "print(VisslDatasetCatalog.list())\n",
        "\n",
        "# get the metadata of dummy_data_folder dataset\n",
        "print(VisslDatasetCatalog.get(\"dummy_data_folder\"))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dummy_data_folder']\n",
            "{'train': ['/content/dummy_data/train', '/content/dummy_data/train'], 'val': ['/content/dummy_data/val', '/content/dummy_data/val']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaUMDwMdzYHN"
      },
      "source": [
        "## Training linear classifier on trunk output\n",
        "\n",
        "We are ready to train the linear classifier now. For the purpose of this tutorial, we will use synthetic dataset and train on dummy images. VISSL supports training on wide range of datasets and allows adding custom datasets. Please see VISSL documentation on how to use the datasets. To train on ImageNet instead: assuming your ImageNet dataset folder path is `/path/to/my/imagenet/folder/`, you can add the following command line \n",
        "input to your training command: \n",
        "```\n",
        "config.DATA.TRAIN.DATASET_NAMES=[imagenet1k_folder] \\\n",
        "config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "config.DATA.TRAIN.DATA_PATHS=[\"/path/to/my/imagenet/folder/train\"] \\\n",
        "config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM7IigSpONW0"
      },
      "source": [
        "The training command looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v0HvauIj9S2",
        "outputId": "3516be61-b100-47c4-89f4-7c15064d4190"
      },
      "source": [
        "!python3 run_distributed_engines.py \\\n",
        "    hydra.verbose=true \\\n",
        "    config=eval_in1k_linear_imagefolder_head \\\n",
        "    config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DATA.TEST.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TEST.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DISTRIBUTED.NUM_NODES=1 \\\n",
        "    config.DISTRIBUTED.NUM_PROC_PER_NODE=1 \\\n",
        "    config.CHECKPOINT.DIR=\"./checkpoints\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.PARAMS_FILE=\"/content/resnet50-19c8e357.pth\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=\"trunk._feature_blocks.\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=\"\"\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "####### overrides: ['hydra.verbose=true', 'config=eval_in1k_linear_imagefolder_head', 'config.DATA.TRAIN.DATA_SOURCES=[disk_folder]', 'config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]', 'config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2', 'config.DATA.TEST.DATA_SOURCES=[disk_folder]', 'config.DATA.TEST.LABEL_SOURCES=[disk_folder]', 'config.DATA.TEST.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TEST.BATCHSIZE_PER_REPLICA=2', 'config.DISTRIBUTED.NUM_NODES=1', 'config.DISTRIBUTED.NUM_PROC_PER_NODE=1', 'config.CHECKPOINT.DIR=./checkpoints', 'config.MODEL.WEIGHTS_INIT.PARAMS_FILE=/content/resnet50-19c8e357.pth', 'config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=trunk._feature_blocks.', 'config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=', 'hydra.verbose=true']\n",
            "INFO 2021-01-13 21:58:46,864 __init__.py:  32: Provided Config has latest version: 1\n",
            "INFO 2021-01-13 21:58:46,864 run_distributed_engines.py: 121: Spawning process for node_id: 0, local_rank: 0, dist_rank: 0, dist_run_id: localhost:56753\n",
            "INFO 2021-01-13 21:58:46,864 train.py:  42: Env set for rank: 0, dist_rank: 0\n",
            "INFO 2021-01-13 21:58:46,865 env.py:  24: CLICOLOR:\t1\n",
            "INFO 2021-01-13 21:58:46,865 env.py:  24: CLOUDSDK_CONFIG:\t/content/.config\n",
            "INFO 2021-01-13 21:58:46,865 env.py:  24: CLOUDSDK_PYTHON:\tpython3\n",
            "INFO 2021-01-13 21:58:46,865 env.py:  24: COLAB_GPU:\t1\n",
            "INFO 2021-01-13 21:58:46,865 env.py:  24: CUDA_PKG_VERSION:\t10-1=10.1.243-1\n",
            "INFO 2021-01-13 21:58:46,865 env.py:  24: CUDA_VERSION:\t10.1.243\n",
            "INFO 2021-01-13 21:58:46,865 env.py:  24: CUDNN_VERSION:\t7.6.5.32\n",
            "INFO 2021-01-13 21:58:46,865 env.py:  24: DATALAB_SETTINGS_OVERRIDES:\t{\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=\\\"172.28.0.2\\\"\"],\"debugAdapterMultiplexerPath\":\"/usr/local/bin/dap_multiplexer\"}\n",
            "INFO 2021-01-13 21:58:46,865 env.py:  24: DEBIAN_FRONTEND:\tnoninteractive\n",
            "INFO 2021-01-13 21:58:46,865 env.py:  24: ENV:\t/root/.bashrc\n",
            "INFO 2021-01-13 21:58:46,865 env.py:  24: GCE_METADATA_TIMEOUT:\t0\n",
            "INFO 2021-01-13 21:58:46,865 env.py:  24: GCS_READ_CACHE_BLOCK_SIZE_MB:\t16\n",
            "INFO 2021-01-13 21:58:46,865 env.py:  24: GIT_PAGER:\tcat\n",
            "INFO 2021-01-13 21:58:46,865 env.py:  24: GLIBCPP_FORCE_NEW:\t1\n",
            "INFO 2021-01-13 21:58:46,865 env.py:  24: GLIBCXX_FORCE_NEW:\t1\n",
            "INFO 2021-01-13 21:58:46,865 env.py:  24: HOME:\t/root\n",
            "INFO 2021-01-13 21:58:46,866 env.py:  24: HOSTNAME:\t1e768c2ad305\n",
            "INFO 2021-01-13 21:58:46,866 env.py:  24: JPY_PARENT_PID:\t49\n",
            "INFO 2021-01-13 21:58:46,866 env.py:  24: LANG:\ten_US.UTF-8\n",
            "INFO 2021-01-13 21:58:46,866 env.py:  24: LAST_FORCED_REBUILD:\t20210105\n",
            "INFO 2021-01-13 21:58:46,866 env.py:  24: LD_LIBRARY_PATH:\t/usr/lib64-nvidia\n",
            "INFO 2021-01-13 21:58:46,866 env.py:  24: LD_PRELOAD:\t/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4\n",
            "INFO 2021-01-13 21:58:46,866 env.py:  24: LIBRARY_PATH:\t/usr/local/cuda/lib64/stubs\n",
            "INFO 2021-01-13 21:58:46,866 env.py:  24: LOCAL_RANK:\t0\n",
            "INFO 2021-01-13 21:58:46,866 env.py:  24: MPLBACKEND:\tmodule://ipykernel.pylab.backend_inline\n",
            "INFO 2021-01-13 21:58:46,866 env.py:  24: NCCL_VERSION:\t2.7.8\n",
            "INFO 2021-01-13 21:58:46,866 env.py:  24: NO_GCE_CHECK:\tTrue\n",
            "INFO 2021-01-13 21:58:46,866 env.py:  24: NVIDIA_DRIVER_CAPABILITIES:\tcompute,utility\n",
            "INFO 2021-01-13 21:58:46,866 env.py:  24: NVIDIA_REQUIRE_CUDA:\tcuda>=10.1 brand=tesla,driver>=396,driver<397 brand=tesla,driver>=410,driver<411 brand=tesla,driver>=418,driver<419\n",
            "INFO 2021-01-13 21:58:46,866 env.py:  24: NVIDIA_VISIBLE_DEVICES:\tall\n",
            "INFO 2021-01-13 21:58:46,866 env.py:  24: OLDPWD:\t/\n",
            "INFO 2021-01-13 21:58:46,866 env.py:  24: PAGER:\tcat\n",
            "INFO 2021-01-13 21:58:46,866 env.py:  24: PATH:\t/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n",
            "INFO 2021-01-13 21:58:46,866 env.py:  24: PWD:\t/content\n",
            "INFO 2021-01-13 21:58:46,867 env.py:  24: PYTHONPATH:\t/env/python\n",
            "INFO 2021-01-13 21:58:46,867 env.py:  24: PYTHONWARNINGS:\tignore:::pip._internal.cli.base_command\n",
            "INFO 2021-01-13 21:58:46,867 env.py:  24: RANK:\t0\n",
            "INFO 2021-01-13 21:58:46,867 env.py:  24: SHELL:\t/bin/bash\n",
            "INFO 2021-01-13 21:58:46,867 env.py:  24: SHLVL:\t1\n",
            "INFO 2021-01-13 21:58:46,867 env.py:  24: TBE_CREDS_ADDR:\t172.28.0.1:8008\n",
            "INFO 2021-01-13 21:58:46,867 env.py:  24: TERM:\txterm-color\n",
            "INFO 2021-01-13 21:58:46,867 env.py:  24: TF_FORCE_GPU_ALLOW_GROWTH:\ttrue\n",
            "INFO 2021-01-13 21:58:46,867 env.py:  24: WORLD_SIZE:\t1\n",
            "INFO 2021-01-13 21:58:46,867 env.py:  24: _:\t/usr/bin/python3\n",
            "INFO 2021-01-13 21:58:46,867 env.py:  24: __EGL_VENDOR_LIBRARY_DIRS:\t/usr/lib64-nvidia:/usr/share/glvnd/egl_vendor.d/\n",
            "INFO 2021-01-13 21:58:46,867 misc.py:  68: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-01-13 21:58:46,867 train.py:  53: Setting seed....\n",
            "INFO 2021-01-13 21:58:46,867 misc.py:  77: MACHINE SEED: 1\n",
            "INFO 2021-01-13 21:58:46,902 hydra_config.py: 122: Training with config:\n",
            "INFO 2021-01-13 21:58:46,905 hydra_config.py: 126: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,\n",
            "                'AUTO_RESUME': True,\n",
            "                'BACKEND': 'disk',\n",
            "                'CHECKPOINT_FREQUENCY': 2,\n",
            "                'CHECKPOINT_ITER_FREQUENCY': -1,\n",
            "                'DIR': './checkpoints',\n",
            "                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,\n",
            "                'OVERWRITE_EXISTING': True},\n",
            " 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',\n",
            "                'FEATURES': {'DATASET_NAME': '',\n",
            "                             'DATA_PARTITION': 'TRAIN',\n",
            "                             'LAYER_NAME': ''},\n",
            "                'NUM_CLUSTERS': 16000,\n",
            "                'N_ITER': 50},\n",
            " 'DATA': {'ENABLE_ASYNC_GPU_COPY': True,\n",
            "          'NUM_DATALOADER_WORKERS': 2,\n",
            "          'PIN_MEMORY': True,\n",
            "          'TEST': {'BATCHSIZE_PER_REPLICA': 2,\n",
            "                   'COLLATE_FUNCTION': 'default_collate',\n",
            "                   'COPY_DESTINATION_DIR': '',\n",
            "                   'COPY_TO_LOCAL_DISK': False,\n",
            "                   'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                   'DATA_LIMIT': 50,\n",
            "                   'DATA_PATHS': [],\n",
            "                   'DATA_SOURCES': ['disk_folder'],\n",
            "                   'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                   'DROP_LAST': False,\n",
            "                   'ENABLE_QUEUE_DATASET': False,\n",
            "                   'INPUT_KEY_NAMES': ['data'],\n",
            "                   'LABEL_PATHS': [],\n",
            "                   'LABEL_SOURCES': ['disk_folder'],\n",
            "                   'LABEL_TYPE': 'standard',\n",
            "                   'MMAP_MODE': True,\n",
            "                   'TARGET_KEY_NAMES': ['label'],\n",
            "                   'TRANSFORMS': [{'name': 'Resize', 'size': 256},\n",
            "                                  {'name': 'CenterCrop', 'size': 224},\n",
            "                                  {'name': 'ToTensor'},\n",
            "                                  {'mean': [0.485, 0.456, 0.406],\n",
            "                                   'name': 'Normalize',\n",
            "                                   'std': [0.229, 0.224, 0.225]}],\n",
            "                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},\n",
            "          'TRAIN': {'BATCHSIZE_PER_REPLICA': 2,\n",
            "                    'COLLATE_FUNCTION': 'default_collate',\n",
            "                    'COPY_DESTINATION_DIR': '',\n",
            "                    'COPY_TO_LOCAL_DISK': False,\n",
            "                    'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                    'DATA_LIMIT': 50,\n",
            "                    'DATA_PATHS': [],\n",
            "                    'DATA_SOURCES': ['disk_folder'],\n",
            "                    'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                    'DROP_LAST': False,\n",
            "                    'ENABLE_QUEUE_DATASET': False,\n",
            "                    'INPUT_KEY_NAMES': ['data'],\n",
            "                    'LABEL_PATHS': [],\n",
            "                    'LABEL_SOURCES': ['disk_folder'],\n",
            "                    'LABEL_TYPE': 'standard',\n",
            "                    'MMAP_MODE': True,\n",
            "                    'TARGET_KEY_NAMES': ['label'],\n",
            "                    'TRANSFORMS': [{'name': 'RandomResizedCrop', 'size': 224},\n",
            "                                   {'name': 'RandomHorizontalFlip'},\n",
            "                                   {'name': 'ToTensor'},\n",
            "                                   {'mean': [0.485, 0.456, 0.406],\n",
            "                                    'name': 'Normalize',\n",
            "                                    'std': [0.229, 0.224, 0.225]}],\n",
            "                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},\n",
            " 'DISTRIBUTED': {'BACKEND': 'nccl',\n",
            "                 'BROADCAST_BUFFERS': True,\n",
            "                 'INIT_METHOD': 'tcp',\n",
            "                 'MANUAL_GRADIENT_REDUCTION': False,\n",
            "                 'NCCL_DEBUG': False,\n",
            "                 'NUM_NODES': 1,\n",
            "                 'NUM_PROC_PER_NODE': 1,\n",
            "                 'RUN_ID': 'auto'},\n",
            " 'IMG_RETRIEVAL': {'DATASET_PATH': '',\n",
            "                   'EVAL_BINARY_PATH': '',\n",
            "                   'EVAL_DATASET_NAME': 'Paris',\n",
            "                   'FEATS_PROCESSING_TYPE': '',\n",
            "                   'GEM_POOL_POWER': 4.0,\n",
            "                   'N_PCA': 512,\n",
            "                   'RESIZE_IMG': 1024,\n",
            "                   'SHOULD_TRAIN_PCA_OR_WHITENING': True,\n",
            "                   'SPATIAL_LEVELS': 3,\n",
            "                   'TEMP_DIR': '/tmp/instance_retrieval/',\n",
            "                   'TRAIN_DATASET_NAME': 'Oxford',\n",
            "                   'WHITEN_IMG_LIST': ''},\n",
            " 'LOG_FREQUENCY': 10,\n",
            " 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},\n",
            "          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,\n",
            "                                                          'normalize_output': False,\n",
            "                                                          'reduction': 'mean',\n",
            "                                                          'weight': None},\n",
            "          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,\n",
            "                                 'DROP_LAST': True,\n",
            "                                 'kmeans_iters': 10,\n",
            "                                 'memory_params': {'crops_for_mb': [0],\n",
            "                                                   'embedding_dim': 128},\n",
            "                                 'num_clusters': [3000, 3000, 3000],\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_train_samples': -1,\n",
            "                                 'temperature': 0.1},\n",
            "          'moco_loss': {'embedding_dim': 128,\n",
            "                        'momentum': 0.999,\n",
            "                        'queue_size': 65536,\n",
            "                        'temperature': 0.2},\n",
            "          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                               'embedding_dim': 128,\n",
            "                                                               'world_size': 64},\n",
            "                                             'num_crops': 2,\n",
            "                                             'temperature': 0.1},\n",
            "          'name': 'cross_entropy_multiple_output_single_target',\n",
            "          'nce_loss_with_memory': {'loss_type': 'nce',\n",
            "                                   'loss_weights': [1.0],\n",
            "                                   'memory_params': {'embedding_dim': 128,\n",
            "                                                     'memory_size': -1,\n",
            "                                                     'momentum': 0.5,\n",
            "                                                     'norm_init': True,\n",
            "                                                     'update_mem_on_forward': True},\n",
            "                                   'negative_sampling_params': {'num_negatives': 16000,\n",
            "                                                                'type': 'random'},\n",
            "                                   'norm_constant': -1,\n",
            "                                   'norm_embedding': True,\n",
            "                                   'num_train_samples': -1,\n",
            "                                   'temperature': 0.07,\n",
            "                                   'update_mem_with_emb_index': -100},\n",
            "          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                     'embedding_dim': 128,\n",
            "                                                     'world_size': 64},\n",
            "                                   'temperature': 0.1},\n",
            "          'swav_loss': {'crops_for_assign': [0, 1],\n",
            "                        'embedding_dim': 128,\n",
            "                        'epsilon': 0.05,\n",
            "                        'normalize_last_layer': True,\n",
            "                        'num_crops': 2,\n",
            "                        'num_iters': 3,\n",
            "                        'num_prototypes': [3000],\n",
            "                        'queue': {'local_queue_length': 0,\n",
            "                                  'queue_length': 0,\n",
            "                                  'start_iter': 0},\n",
            "                        'temperature': 0.1,\n",
            "                        'use_double_precision': False}},\n",
            " 'MACHINE': {'DEVICE': 'gpu'},\n",
            " 'METERS': {'accuracy_list_meter': {'meter_names': [],\n",
            "                                    'num_meters': 1,\n",
            "                                    'topk_values': [1, 5]}},\n",
            " 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,\n",
            "                                        'USE_ACTIVATION_CHECKPOINTING': False},\n",
            "           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'}, 'USE_AMP': False},\n",
            "           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': True,\n",
            "                                     'EVAL_TRUNK_AND_HEAD': False,\n",
            "                                     'EXTRACT_TRUNK_FEATURES_ONLY': False,\n",
            "                                     'FREEZE_TRUNK_AND_HEAD': False,\n",
            "                                     'FREEZE_TRUNK_ONLY': True,\n",
            "                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [],\n",
            "                                     'SHOULD_FLATTEN_FEATS': False},\n",
            "           'HEAD': {'BATCHNORM_EPS': 1e-05,\n",
            "                    'BATCHNORM_MOMENTUM': 0.1,\n",
            "                    'PARAMS': [['eval_mlp',\n",
            "                                {'dims': [2048, 1000], 'in_channels': 2048}]]},\n",
            "           'INPUT_TYPE': 'rgb',\n",
            "           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,\n",
            "                                'INPUT_SHAPE': [3, 224, 224]},\n",
            "           'MULTI_INPUT_HEAD_MAPPING': [],\n",
            "           'NON_TRAINABLE_PARAMS': [],\n",
            "           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': True,\n",
            "                              'GROUP_SIZE': 0,\n",
            "                              'SYNC_BN_TYPE': 'pytorch'},\n",
            "           'TEMP_FROZEN_PARAMS_ITER_MAP': [],\n",
            "           'TRUNK': {'NAME': 'resnet',\n",
            "                     'TRUNK_PARAMS': {'EFFICIENT_NETS': {},\n",
            "                                      'REGNETS': {},\n",
            "                                      'RESNETS': {'DEPTH': 50,\n",
            "                                                  'GROUPS': 1,\n",
            "                                                  'LAYER4_STRIDE': 2,\n",
            "                                                  'NORM': 'BatchNorm',\n",
            "                                                  'WIDTH_MULTIPLIER': 1,\n",
            "                                                  'WIDTH_PER_GROUP': 64,\n",
            "                                                  'ZERO_INIT_RESIDUAL': False}}},\n",
            "           'WEIGHTS_INIT': {'APPEND_PREFIX': 'trunk._feature_blocks.',\n",
            "                            'PARAMS_FILE': '/content/resnet50-19c8e357.pth',\n",
            "                            'REMOVE_PREFIX': '',\n",
            "                            'SKIP_LAYERS': ['num_batches_tracked'],\n",
            "                            'STATE_DICT_KEY_NAME': ''}},\n",
            " 'MONITOR_PERF_STATS': True,\n",
            " 'MULTI_PROCESSING_METHOD': 'forkserver',\n",
            " 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},\n",
            " 'OPTIMIZER': {'larc_config': {'clip': False,\n",
            "                               'eps': 1e-08,\n",
            "                               'trust_coefficient': 0.001},\n",
            "               'momentum': 0.9,\n",
            "               'name': 'sgd',\n",
            "               'nesterov': True,\n",
            "               'num_epochs': 2,\n",
            "               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': False,\n",
            "                                                               'base_lr_batch_size': 256,\n",
            "                                                               'base_value': 0.1},\n",
            "                                           'end_value': 0.0,\n",
            "                                           'interval_scaling': [],\n",
            "                                           'lengths': [],\n",
            "                                           'milestones': [1],\n",
            "                                           'name': 'multistep',\n",
            "                                           'schedulers': [],\n",
            "                                           'start_value': 0.1,\n",
            "                                           'update_interval': 'epoch',\n",
            "                                           'value': 0.1,\n",
            "                                           'values': [0.01, 0.001]}},\n",
            "               'regularize_bias': True,\n",
            "               'regularize_bn': False,\n",
            "               'use_larc': False,\n",
            "               'weight_decay': 0.0005},\n",
            " 'PERF_STAT_FREQUENCY': -1,\n",
            " 'ROLLING_BTIME_FREQ': -1,\n",
            " 'SEED_VALUE': 1,\n",
            " 'SVM': {'cls_list': [],\n",
            "         'costs': {'base': -1.0,\n",
            "                   'costs_list': [0.1, 0.01],\n",
            "                   'power_range': [4, 20]},\n",
            "         'cross_val_folds': 3,\n",
            "         'dual': True,\n",
            "         'force_retrain': False,\n",
            "         'loss': 'squared_hinge',\n",
            "         'low_shot': {'dataset_name': 'voc',\n",
            "                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],\n",
            "                      'sample_inds': [1, 2, 3, 4, 5]},\n",
            "         'max_iter': 2000,\n",
            "         'normalize': True,\n",
            "         'penalty': 'l2'},\n",
            " 'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': '',\n",
            "                       'FLUSH_EVERY_N_MIN': 5,\n",
            "                       'LOG_ACTIVATIONS': True,\n",
            "                       'LOG_DIR': '.',\n",
            "                       'USE_TENSORBOARD': False},\n",
            " 'TEST_EVERY_NUM_EPOCH': 2,\n",
            " 'TEST_MODEL': True,\n",
            " 'TEST_ONLY': False,\n",
            " 'TRAINER': {'TRAIN_STEP_NAME': 'standard_train_step'},\n",
            " 'VERBOSE': True}\n",
            "INFO 2021-01-13 21:58:47,289 train.py:  65: System config:\n",
            "-------------------  ---------------------------------------------------------------\n",
            "sys.platform         linux\n",
            "Python               3.6.9 (default, Oct  8 2020, 12:12:24) [GCC 8.4.0]\n",
            "numpy                1.19.5\n",
            "Pillow               7.0.0\n",
            "vissl                0.1.3 @/usr/local/lib/python3.6/dist-packages/vissl\n",
            "GPU available        True\n",
            "GPU 0                Tesla T4\n",
            "CUDA_HOME            /usr/local/cuda\n",
            "torchvision          0.6.1+cu101 @/usr/local/lib/python3.6/dist-packages/torchvision\n",
            "hydra                1.0.5 @/usr/local/lib/python3.6/dist-packages/hydra\n",
            "classy_vision        0.5.0 @/usr/local/lib/python3.6/dist-packages/classy_vision\n",
            "tensorboard          1.15.0\n",
            "apex                 0.1 @/usr/local/lib/python3.6/dist-packages/apex\n",
            "cv2                  4.1.2\n",
            "PyTorch              1.5.1+cu101 @/usr/local/lib/python3.6/dist-packages/torch\n",
            "PyTorch debug build  False\n",
            "-------------------  ---------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 10.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "CPU info:\n",
            "-------------------  ------------------------------\n",
            "Architecture         x86_64\n",
            "CPU op-mode(s)       32-bit, 64-bit\n",
            "Byte Order           Little Endian\n",
            "CPU(s)               2\n",
            "On-line CPU(s) list  0,1\n",
            "Thread(s) per core   2\n",
            "Core(s) per socket   1\n",
            "Socket(s)            1\n",
            "NUMA node(s)         1\n",
            "Vendor ID            GenuineIntel\n",
            "CPU family           6\n",
            "Model                79\n",
            "Model name           Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping             0\n",
            "CPU MHz              2199.998\n",
            "BogoMIPS             4399.99\n",
            "Hypervisor vendor    KVM\n",
            "Virtualization type  full\n",
            "L1d cache            32K\n",
            "L1i cache            32K\n",
            "L2 cache             256K\n",
            "L3 cache             56320K\n",
            "NUMA node0 CPU(s)    0,1\n",
            "-------------------  ------------------------------\n",
            "INFO 2021-01-13 21:58:47,289 train_task.py: 121: Setting amp args: None\n",
            "INFO 2021-01-13 21:58:47,289 trainer_main.py:  61: Using Distributed init method: tcp://localhost:56753, world_size: 1, rank: 0\n",
            "INFO 2021-01-13 21:58:47,290 trainer_main.py:  82: | initialized host 1e768c2ad305 as rank 0 (0)\n",
            "INFO 2021-01-13 21:58:47,291 ssl_dataset.py:  68: Rank: 0 Data files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-01-13 21:58:47,291 ssl_dataset.py:  69: Rank: 0 Label files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-01-13 21:58:47,291 disk_dataset.py:  77: Loaded 10 samples from folder /content/dummy_data/val\n",
            "INFO 2021-01-13 21:58:47,292 ssl_dataset.py:  68: Rank: 0 Data files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-01-13 21:58:47,292 ssl_dataset.py:  69: Rank: 0 Label files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-01-13 21:58:47,292 disk_dataset.py:  77: Loaded 10 samples from folder /content/dummy_data/train\n",
            "INFO 2021-01-13 21:58:47,292 misc.py:  68: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-01-13 21:58:47,292 __init__.py:  64: Created the Distributed Sampler....\n",
            "INFO 2021-01-13 21:58:47,292 __init__.py:  52: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "INFO 2021-01-13 21:58:47,292 __init__.py: 106: Wrapping the dataloader to async device copies\n",
            "INFO 2021-01-13 21:58:50,946 misc.py:  68: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-01-13 21:58:50,946 __init__.py:  64: Created the Distributed Sampler....\n",
            "INFO 2021-01-13 21:58:50,946 __init__.py:  52: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "INFO 2021-01-13 21:58:50,946 __init__.py: 106: Wrapping the dataloader to async device copies\n",
            "INFO 2021-01-13 21:58:50,947 train_task.py: 280: Building model....\n",
            "INFO 2021-01-13 21:58:50,947 resnext.py:  58: ResNeXT trunk, supports activation checkpointing. Deactivated\n",
            "INFO 2021-01-13 21:58:50,947 resnext.py:  72: Building model: ResNeXt50-1x64d-w1-BatchNorm2d\n",
            "INFO 2021-01-13 21:58:51,530 model_helpers.py:  85: Using SyncBN group size: None\n",
            "INFO 2021-01-13 21:58:51,530 model_helpers.py: 100: Converting BN layers to PyTorch SyncBN\n",
            "INFO 2021-01-13 21:58:51,530 model_helpers.py: 103: Not creating process_group for PyTorch SyncBN...\n",
            "INFO 2021-01-13 21:58:51,536 train_task.py: 298: config.MODEL.FEATURE_EVAL_SETTINGS.FREEZE_TRUNK_ONLY=True, will freeze trunk...\n",
            "INFO 2021-01-13 21:58:51,536 base_ssl_model.py: 151: Freezing model trunk...\n",
            "INFO 2021-01-13 21:58:51,536 train_task.py: 253: Initializing model from: /content/resnet50-19c8e357.pth\n",
            "INFO 2021-01-13 21:58:51,703 checkpoint.py: 405: Loaded: trunk._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,703 checkpoint.py: 405: Loaded: trunk._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,703 checkpoint.py: 405: Loaded: trunk._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,703 checkpoint.py: 405: Loaded: trunk._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,703 checkpoint.py: 405: Loaded: trunk._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,704 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,704 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,704 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,704 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,704 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,704 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,704 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer1.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,704 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,704 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,704 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,704 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,704 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,705 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer1.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,705 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,705 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,705 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,705 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,705 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,705 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer1.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,705 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,705 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,705 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,705 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,706 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,706 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer1.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,706 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,706 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,706 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,706 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,706 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,706 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer1.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,706 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,706 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,706 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,706 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,707 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,707 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer1.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,707 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,707 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,707 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,707 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,707 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,707 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer1.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,707 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,707 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,707 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,707 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,708 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,708 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer1.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,708 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,708 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,708 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,708 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,708 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,708 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer1.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,708 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,708 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,708 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,709 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,709 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,709 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer1.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,709 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,709 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,709 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,709 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,709 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,709 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer2.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,709 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,710 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,710 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,710 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,710 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,710 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer2.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,710 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,710 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,710 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,710 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,710 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,711 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer2.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,711 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,711 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,711 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,711 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,711 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,711 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer2.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,711 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,711 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,711 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,712 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,712 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,712 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer2.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,712 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,712 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,712 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,712 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,712 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,712 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer2.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,712 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,713 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,713 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,713 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,713 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,713 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer2.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,713 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,713 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,713 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,713 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,713 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,713 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer2.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,714 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,714 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,714 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,714 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,714 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,714 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer2.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,719 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,719 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,719 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,719 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,719 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,719 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer2.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,720 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,720 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,720 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,720 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,720 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,720 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer2.3.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,720 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,721 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,721 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,721 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,721 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,721 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer2.3.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,721 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,721 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,722 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,722 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,722 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,722 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer2.3.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,722 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,722 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,722 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,723 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,723 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,723 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,723 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,724 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,724 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,724 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,724 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,724 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,724 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,724 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,724 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,724 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,725 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,725 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,725 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,725 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,725 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,725 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,725 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,726 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,726 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,726 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,726 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,726 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,726 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,726 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,727 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,727 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,727 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,727 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,727 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,727 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,727 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,728 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,728 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,728 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,728 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,728 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,728 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,728 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,728 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,728 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,728 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,729 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,729 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,729 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,729 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,729 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,729 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,729 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,730 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,730 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,730 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,730 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,730 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,730 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,730 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,731 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,731 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,731 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,731 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,731 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.3.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,731 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,732 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,732 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,732 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,732 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,732 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.3.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,732 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,732 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,732 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,732 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,732 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,733 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.3.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,733 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,733 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,733 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,733 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,733 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,733 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.4.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,734 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,734 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,734 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,734 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,734 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,734 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.4.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,734 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,734 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,735 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,735 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,735 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,735 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.4.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,735 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,735 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,735 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,735 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,735 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,736 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.5.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,736 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,736 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,736 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,736 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,736 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,736 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.5.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,737 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,737 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,737 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,737 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,737 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,737 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer3.5.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,738 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,738 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,738 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,738 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,738 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,738 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer4.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,740 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,740 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,740 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,740 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,740 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,740 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer4.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,825 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,826 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,826 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,826 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,826 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,826 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer4.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,828 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,828 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,829 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,829 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,829 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,829 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer4.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,830 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,830 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,830 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,830 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,830 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,830 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer4.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,832 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,833 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,833 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,833 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,833 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,833 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer4.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,834 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,834 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,834 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,834 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,834 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,834 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer4.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,835 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,835 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,835 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,835 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,835 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,835 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer4.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,837 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,837 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,837 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,837 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,837 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,838 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer4.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,838 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,839 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,839 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,839 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,839 checkpoint.py: 405: Loaded: trunk._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 21:58:51,839 checkpoint.py: 377: Ignored layer:\ttrunk._feature_blocks.layer4.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,839 checkpoint.py: 413: Not found:\t\theads.0.channel_bn.weight, not initialized\n",
            "INFO 2021-01-13 21:58:51,839 checkpoint.py: 413: Not found:\t\theads.0.channel_bn.bias, not initialized\n",
            "INFO 2021-01-13 21:58:51,839 checkpoint.py: 413: Not found:\t\theads.0.channel_bn.running_mean, not initialized\n",
            "INFO 2021-01-13 21:58:51,839 checkpoint.py: 413: Not found:\t\theads.0.channel_bn.running_var, not initialized\n",
            "INFO 2021-01-13 21:58:51,839 checkpoint.py: 377: Ignored layer:\theads.0.channel_bn.num_batches_tracked\n",
            "INFO 2021-01-13 21:58:51,839 checkpoint.py: 413: Not found:\t\theads.0.clf.clf.0.weight, not initialized\n",
            "INFO 2021-01-13 21:58:51,840 checkpoint.py: 413: Not found:\t\theads.0.clf.clf.0.bias, not initialized\n",
            "INFO 2021-01-13 21:58:51,840 checkpoint.py: 420: Extra layers not loaded from checkpoint: ['trunk._feature_blocks.fc.weight', 'trunk._feature_blocks.fc.bias']\n",
            "INFO 2021-01-13 21:58:51,841 train_task.py: 437: Broadcast model BN buffers from master on every forward pass\n",
            "INFO 2021-01-13 21:58:51,841 classification_task.py: 341: Synchronized Batch Normalization is disabled\n",
            "INFO 2021-01-13 21:58:51,841 train_task.py: 222: Building loss...\n",
            "INFO 2021-01-13 21:58:51,887 optimizer_helper.py:  86: Traininable params: 4, Non-Traininable params: 0, Regularized Parameters: 2, Unregularized Parameters 2\n",
            "INFO 2021-01-13 21:58:51,887 trainer_main.py: 168: Training 2 epochs. One epoch = 5 iterations\n",
            "INFO 2021-01-13 21:58:51,887 trainer_main.py: 170: Total 10 iterations for training\n",
            "INFO 2021-01-13 21:58:51,888 trainer_main.py: 171: Total 10 samples in one epoch\n",
            "INFO 2021-01-13 21:58:52,007 logger.py:  66: Wed Jan 13 21:58:51 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    26W /  70W |    915MiB / 15079MiB |      4%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "INFO 2021-01-13 21:58:52,009 trainer_main.py: 103: Model is:\n",
            " Classy <class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'>:\n",
            "BaseSSLMultiInputOutputModel(\n",
            "  (_heads): ModuleDict()\n",
            "  (trunk): ResNeXt(\n",
            "    (_feature_blocks): ModuleDict(\n",
            "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1_relu): ReLU(inplace=True)\n",
            "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (layer1): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer2): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer3): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (4): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (5): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer4): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), bias=False)\n",
            "            (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "      (flatten): Flatten()\n",
            "    )\n",
            "  )\n",
            "  (heads): ModuleList(\n",
            "    (0): LinearEvalMLP(\n",
            "      (channel_bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (clf): MLP(\n",
            "        (clf): Sequential(\n",
            "          (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "INFO 2021-01-13 21:58:52,029 trainer_main.py: 104: Loss is: CrossEntropyMultipleOutputSingleTargetLoss(\n",
            "  (_losses): ModuleList()\n",
            ")\n",
            "INFO 2021-01-13 21:58:52,029 trainer_main.py: 105: Starting training....\n",
            "INFO 2021-01-13 21:58:52,029 __init__.py:  52: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-13 21:58:54,619 trainer_main.py: 205: Phase advanced. Rank: 0\n",
            "INFO 2021-01-13 21:58:54,620 state_update_hooks.py:  90: Starting phase 0 [train]\n",
            "INFO 2021-01-13 21:58:54,980 log_hooks.py: 119: Rank: 0; [ep: 0] iter: 1; lr: 0.01; loss: 7.05151; btime(ms): 3092; eta: 0:00:27; peak_mem: 2420M\n",
            "INFO 2021-01-13 21:58:55,047 log_hooks.py: 119: Rank: 0; [ep: 0] iter: 5; lr: 0.01; loss: 10.52996; btime(ms): 631; eta: 0:00:03; peak_mem: 2420M\n",
            "INFO 2021-01-13 21:58:55,047 trainer_main.py: 123: Meters synced\n",
            "INFO 2021-01-13 21:58:55,072 log_hooks.py: 298: Average train batch time (ms) for 5 batches: 90\n",
            "INFO 2021-01-13 21:58:55,072 log_hooks.py: 307: Train step time breakdown (rank 0):\n",
            "               Timer     Host    CudaEvent\n",
            "         read_sample:    2.64 ms    2.66 ms\n",
            "             forward:   79.49 ms   79.75 ms\n",
            "        loss_compute:    0.53 ms    0.36 ms\n",
            "     loss_all_reduce:    0.08 ms    0.08 ms\n",
            "       meters_update:    0.37 ms    0.39 ms\n",
            "            backward:    0.82 ms    0.85 ms\n",
            "      optimizer_step:    0.40 ms    0.62 ms\n",
            "    train_step_total:   85.35 ms   85.36 ms\n",
            "INFO 2021-01-13 21:58:55,073 log_hooks.py: 228: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {0: 20.0}, 'top_5': {0: 20.0}}\n",
            "INFO 2021-01-13 21:58:55,073 io.py:  16: Saving data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-13 21:58:55,073 io.py:  30: Saved data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-13 21:58:55,073 log_hooks.py: 182: [phase: 0] Saving checkpoint to ./checkpoints\n",
            "INFO 2021-01-13 21:58:55,258 log_hooks.py: 212: Saved checkpoint: ./checkpoints/model_phase0.torch\n",
            "INFO 2021-01-13 21:58:55,258 __init__.py:  52: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 1, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-13 21:58:57,657 trainer_main.py: 205: Phase advanced. Rank: 0\n",
            "INFO 2021-01-13 21:58:57,657 state_update_hooks.py:  90: Starting phase 1 [test]\n",
            "INFO 2021-01-13 21:58:57,809 trainer_main.py: 123: Meters synced\n",
            "INFO 2021-01-13 21:58:57,809 log_hooks.py: 298: Average test batch time (ms) for 5 batches: 30\n",
            "INFO 2021-01-13 21:58:57,810 log_hooks.py: 228: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {0: 50.0}, 'top_5': {0: 50.0}}\n",
            "INFO 2021-01-13 21:58:57,810 io.py:  16: Saving data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-13 21:58:57,810 io.py:  30: Saved data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-13 21:58:57,810 __init__.py:  52: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 2, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-13 21:59:00,226 trainer_main.py: 205: Phase advanced. Rank: 0\n",
            "INFO 2021-01-13 21:59:00,226 state_update_hooks.py:  90: Starting phase 2 [train]\n",
            "INFO 2021-01-13 21:59:00,360 log_hooks.py: 119: Rank: 0; [ep: 1] iter: 10; lr: 0.001; loss: 6.95633; btime(ms): 564; eta: 0:00:00; peak_mem: 2420M\n",
            "INFO 2021-01-13 21:59:00,360 trainer_main.py: 123: Meters synced\n",
            "INFO 2021-01-13 21:59:00,360 log_hooks.py: 298: Average train batch time (ms) for 5 batches: 26\n",
            "INFO 2021-01-13 21:59:00,360 log_hooks.py: 307: Train step time breakdown (rank 0):\n",
            "               Timer     Host    CudaEvent\n",
            "         read_sample:    6.07 ms    6.07 ms\n",
            "             forward:   13.07 ms   17.92 ms\n",
            "        loss_compute:    5.06 ms    0.29 ms\n",
            "     loss_all_reduce:    0.07 ms    0.07 ms\n",
            "       meters_update:    0.31 ms    0.33 ms\n",
            "            backward:    0.54 ms    0.69 ms\n",
            "      optimizer_step:    0.35 ms    0.56 ms\n",
            "    train_step_total:   26.55 ms   26.56 ms\n",
            "INFO 2021-01-13 21:59:00,361 log_hooks.py: 228: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {0: 40.0}, 'top_5': {0: 40.0}}\n",
            "INFO 2021-01-13 21:59:00,361 io.py:  16: Saving data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-13 21:59:00,361 io.py:  30: Saved data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-13 21:59:00,361 log_hooks.py: 182: [phase: 2] Saving checkpoint to ./checkpoints\n",
            "INFO 2021-01-13 21:59:00,497 log_hooks.py: 212: Saved checkpoint: ./checkpoints/model_final_checkpoint_phase2.torch\n",
            "INFO 2021-01-13 21:59:00,498 __init__.py:  52: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 3, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-13 21:59:02,997 trainer_main.py: 205: Phase advanced. Rank: 0\n",
            "INFO 2021-01-13 21:59:02,998 state_update_hooks.py:  90: Starting phase 3 [test]\n",
            "INFO 2021-01-13 21:59:03,110 trainer_main.py: 123: Meters synced\n",
            "INFO 2021-01-13 21:59:03,110 log_hooks.py: 298: Average test batch time (ms) for 5 batches: 22\n",
            "INFO 2021-01-13 21:59:03,111 log_hooks.py: 228: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {0: 50.0}, 'top_5': {0: 50.0}}\n",
            "INFO 2021-01-13 21:59:03,111 io.py:  16: Saving data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-13 21:59:03,111 io.py:  30: Saved data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-13 21:59:03,189 train.py:  86: All Done!\n",
            "INFO 2021-01-13 21:59:03,190 logger.py:  59: Shutting down loggers...\n",
            "INFO 2021-01-13 21:59:03,190 run_distributed_engines.py:  95: All Done!\n",
            "INFO 2021-01-13 21:59:03,190 logger.py:  59: Shutting down loggers...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8fILq7VzyOu"
      },
      "source": [
        "And we are done!! We have the linear classifier trained on the trunk output and the `metrics.json` containing `top-1` and `top-5` accuracy on validation set is available in `checkpoints/metrics.json`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otUmgl4ms96M",
        "outputId": "1c5c7ae3-4e86-48c6-bbd0-479fbeb0bc8b"
      },
      "source": [
        "ls checkpoints/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log.txt  metrics.json  model_final_checkpoint_phase2.torch  model_phase0.torch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDMLjudpya2I",
        "outputId": "a17ad0b6-85c7-44b2-b63c-85d9b7d084fa"
      },
      "source": [
        "cat checkpoints/metrics.json"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"iteration\": 5, \"phase_idx\": 0, \"train_accuracy_list_meter\": {\"top_1\": {\"0\": 20.0}, \"top_5\": {\"0\": 20.0}}, \"train_phase_idx\": 0}\n",
            "{\"iteration\": 5, \"phase_idx\": 1, \"test_accuracy_list_meter\": {\"top_1\": {\"0\": 50.0}, \"top_5\": {\"0\": 50.0}}, \"train_phase_idx\": 0}\n",
            "{\"iteration\": 10, \"phase_idx\": 2, \"train_accuracy_list_meter\": {\"top_1\": {\"0\": 40.0}, \"top_5\": {\"0\": 40.0}}, \"train_phase_idx\": 1}\n",
            "{\"iteration\": 10, \"phase_idx\": 3, \"test_accuracy_list_meter\": {\"top_1\": {\"0\": 50.0}, \"top_5\": {\"0\": 50.0}}, \"train_phase_idx\": 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJKSyC0txO4x"
      },
      "source": [
        "## Training linear classifiers on several trunk features\n",
        "\n",
        "VISSL also supports training linear classifiers on several features of the trunk. For the purpose of tutorial, we will use [this](https://github.com/facebookresearch/vissl/blob/master/configs/config/test/integration_test/quick_eval_in1k_linear_imagefolder.yaml) config file. Let's go ahead and download it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FEqQ8ByxjZG"
      },
      "source": [
        "!wget -q -O configs/config/eval_in1k_linear_imagefolder.yaml https://dl.fbaipublicfiles.com/vissl/tutorials/configs/eval_in1k_linear_imagefolder.yaml"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8hMOAgBxptv"
      },
      "source": [
        "Now, let's re-run the previous command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwEg7GLoxvr5",
        "outputId": "ef98af9d-1e64-4011-e27a-125b7105b4c4"
      },
      "source": [
        "!python3 run_distributed_engines.py \\\n",
        "    hydra.verbose=true \\\n",
        "    config=eval_in1k_linear_imagefolder \\\n",
        "    config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DATA.TEST.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TEST.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DISTRIBUTED.NUM_NODES=1 \\\n",
        "    config.DISTRIBUTED.NUM_PROC_PER_NODE=1 \\\n",
        "    config.CHECKPOINT.DIR=\"./checkpoints_trunk_eval\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.PARAMS_FILE=\"/content/resnet50-19c8e357.pth\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=\"trunk.base_model._feature_blocks.\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=\"\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "####### overrides: ['hydra.verbose=true', 'config=eval_in1k_linear_imagefolder', 'config.DATA.TRAIN.DATA_SOURCES=[disk_folder]', 'config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]', 'config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2', 'config.DATA.TEST.DATA_SOURCES=[disk_folder]', 'config.DATA.TEST.LABEL_SOURCES=[disk_folder]', 'config.DATA.TEST.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TEST.BATCHSIZE_PER_REPLICA=2', 'config.DISTRIBUTED.NUM_NODES=1', 'config.DISTRIBUTED.NUM_PROC_PER_NODE=1', 'config.CHECKPOINT.DIR=./checkpoints_trunk_eval', 'config.MODEL.WEIGHTS_INIT.PARAMS_FILE=/content/resnet50-19c8e357.pth', 'config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=trunk.base_model._feature_blocks.', 'config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=', 'hydra.verbose=true']\n",
            "INFO 2021-01-13 22:05:08,283 __init__.py:  32: Provided Config has latest version: 1\n",
            "INFO 2021-01-13 22:05:08,283 run_distributed_engines.py: 121: Spawning process for node_id: 0, local_rank: 0, dist_rank: 0, dist_run_id: localhost:39005\n",
            "INFO 2021-01-13 22:05:08,284 train.py:  42: Env set for rank: 0, dist_rank: 0\n",
            "INFO 2021-01-13 22:05:08,284 env.py:  24: CLICOLOR:\t1\n",
            "INFO 2021-01-13 22:05:08,284 env.py:  24: CLOUDSDK_CONFIG:\t/content/.config\n",
            "INFO 2021-01-13 22:05:08,284 env.py:  24: CLOUDSDK_PYTHON:\tpython3\n",
            "INFO 2021-01-13 22:05:08,284 env.py:  24: COLAB_GPU:\t1\n",
            "INFO 2021-01-13 22:05:08,284 env.py:  24: CUDA_PKG_VERSION:\t10-1=10.1.243-1\n",
            "INFO 2021-01-13 22:05:08,284 env.py:  24: CUDA_VERSION:\t10.1.243\n",
            "INFO 2021-01-13 22:05:08,284 env.py:  24: CUDNN_VERSION:\t7.6.5.32\n",
            "INFO 2021-01-13 22:05:08,285 env.py:  24: DATALAB_SETTINGS_OVERRIDES:\t{\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=\\\"172.28.0.2\\\"\"],\"debugAdapterMultiplexerPath\":\"/usr/local/bin/dap_multiplexer\"}\n",
            "INFO 2021-01-13 22:05:08,285 env.py:  24: DEBIAN_FRONTEND:\tnoninteractive\n",
            "INFO 2021-01-13 22:05:08,285 env.py:  24: ENV:\t/root/.bashrc\n",
            "INFO 2021-01-13 22:05:08,285 env.py:  24: GCE_METADATA_TIMEOUT:\t0\n",
            "INFO 2021-01-13 22:05:08,285 env.py:  24: GCS_READ_CACHE_BLOCK_SIZE_MB:\t16\n",
            "INFO 2021-01-13 22:05:08,285 env.py:  24: GIT_PAGER:\tcat\n",
            "INFO 2021-01-13 22:05:08,285 env.py:  24: GLIBCPP_FORCE_NEW:\t1\n",
            "INFO 2021-01-13 22:05:08,285 env.py:  24: GLIBCXX_FORCE_NEW:\t1\n",
            "INFO 2021-01-13 22:05:08,285 env.py:  24: HOME:\t/root\n",
            "INFO 2021-01-13 22:05:08,285 env.py:  24: HOSTNAME:\t1e768c2ad305\n",
            "INFO 2021-01-13 22:05:08,285 env.py:  24: JPY_PARENT_PID:\t49\n",
            "INFO 2021-01-13 22:05:08,285 env.py:  24: LANG:\ten_US.UTF-8\n",
            "INFO 2021-01-13 22:05:08,285 env.py:  24: LAST_FORCED_REBUILD:\t20210105\n",
            "INFO 2021-01-13 22:05:08,285 env.py:  24: LD_LIBRARY_PATH:\t/usr/lib64-nvidia\n",
            "INFO 2021-01-13 22:05:08,285 env.py:  24: LD_PRELOAD:\t/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4\n",
            "INFO 2021-01-13 22:05:08,285 env.py:  24: LIBRARY_PATH:\t/usr/local/cuda/lib64/stubs\n",
            "INFO 2021-01-13 22:05:08,285 env.py:  24: LOCAL_RANK:\t0\n",
            "INFO 2021-01-13 22:05:08,285 env.py:  24: MPLBACKEND:\tmodule://ipykernel.pylab.backend_inline\n",
            "INFO 2021-01-13 22:05:08,286 env.py:  24: NCCL_VERSION:\t2.7.8\n",
            "INFO 2021-01-13 22:05:08,286 env.py:  24: NO_GCE_CHECK:\tTrue\n",
            "INFO 2021-01-13 22:05:08,286 env.py:  24: NVIDIA_DRIVER_CAPABILITIES:\tcompute,utility\n",
            "INFO 2021-01-13 22:05:08,286 env.py:  24: NVIDIA_REQUIRE_CUDA:\tcuda>=10.1 brand=tesla,driver>=396,driver<397 brand=tesla,driver>=410,driver<411 brand=tesla,driver>=418,driver<419\n",
            "INFO 2021-01-13 22:05:08,286 env.py:  24: NVIDIA_VISIBLE_DEVICES:\tall\n",
            "INFO 2021-01-13 22:05:08,286 env.py:  24: OLDPWD:\t/\n",
            "INFO 2021-01-13 22:05:08,286 env.py:  24: PAGER:\tcat\n",
            "INFO 2021-01-13 22:05:08,286 env.py:  24: PATH:\t/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n",
            "INFO 2021-01-13 22:05:08,286 env.py:  24: PWD:\t/content\n",
            "INFO 2021-01-13 22:05:08,286 env.py:  24: PYTHONPATH:\t/env/python\n",
            "INFO 2021-01-13 22:05:08,286 env.py:  24: PYTHONWARNINGS:\tignore:::pip._internal.cli.base_command\n",
            "INFO 2021-01-13 22:05:08,286 env.py:  24: RANK:\t0\n",
            "INFO 2021-01-13 22:05:08,286 env.py:  24: SHELL:\t/bin/bash\n",
            "INFO 2021-01-13 22:05:08,286 env.py:  24: SHLVL:\t1\n",
            "INFO 2021-01-13 22:05:08,286 env.py:  24: TBE_CREDS_ADDR:\t172.28.0.1:8008\n",
            "INFO 2021-01-13 22:05:08,286 env.py:  24: TERM:\txterm-color\n",
            "INFO 2021-01-13 22:05:08,286 env.py:  24: TF_FORCE_GPU_ALLOW_GROWTH:\ttrue\n",
            "INFO 2021-01-13 22:05:08,286 env.py:  24: WORLD_SIZE:\t1\n",
            "INFO 2021-01-13 22:05:08,287 env.py:  24: _:\t/usr/bin/python3\n",
            "INFO 2021-01-13 22:05:08,287 env.py:  24: __EGL_VENDOR_LIBRARY_DIRS:\t/usr/lib64-nvidia:/usr/share/glvnd/egl_vendor.d/\n",
            "INFO 2021-01-13 22:05:08,287 misc.py:  68: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-01-13 22:05:08,287 train.py:  53: Setting seed....\n",
            "INFO 2021-01-13 22:05:08,287 misc.py:  77: MACHINE SEED: 1\n",
            "INFO 2021-01-13 22:05:08,323 hydra_config.py: 122: Training with config:\n",
            "INFO 2021-01-13 22:05:08,328 hydra_config.py: 126: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,\n",
            "                'AUTO_RESUME': True,\n",
            "                'BACKEND': 'disk',\n",
            "                'CHECKPOINT_FREQUENCY': 2,\n",
            "                'CHECKPOINT_ITER_FREQUENCY': -1,\n",
            "                'DIR': './checkpoints_trunk_eval',\n",
            "                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,\n",
            "                'OVERWRITE_EXISTING': True},\n",
            " 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',\n",
            "                'FEATURES': {'DATASET_NAME': '',\n",
            "                             'DATA_PARTITION': 'TRAIN',\n",
            "                             'LAYER_NAME': ''},\n",
            "                'NUM_CLUSTERS': 16000,\n",
            "                'N_ITER': 50},\n",
            " 'DATA': {'ENABLE_ASYNC_GPU_COPY': True,\n",
            "          'NUM_DATALOADER_WORKERS': 2,\n",
            "          'PIN_MEMORY': True,\n",
            "          'TEST': {'BATCHSIZE_PER_REPLICA': 2,\n",
            "                   'COLLATE_FUNCTION': 'default_collate',\n",
            "                   'COPY_DESTINATION_DIR': '',\n",
            "                   'COPY_TO_LOCAL_DISK': False,\n",
            "                   'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                   'DATA_LIMIT': 50,\n",
            "                   'DATA_PATHS': [],\n",
            "                   'DATA_SOURCES': ['disk_folder'],\n",
            "                   'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                   'DROP_LAST': False,\n",
            "                   'ENABLE_QUEUE_DATASET': False,\n",
            "                   'INPUT_KEY_NAMES': ['data'],\n",
            "                   'LABEL_PATHS': [],\n",
            "                   'LABEL_SOURCES': ['disk_folder'],\n",
            "                   'LABEL_TYPE': 'standard',\n",
            "                   'MMAP_MODE': True,\n",
            "                   'TARGET_KEY_NAMES': ['label'],\n",
            "                   'TRANSFORMS': [{'name': 'Resize', 'size': 256},\n",
            "                                  {'name': 'CenterCrop', 'size': 224},\n",
            "                                  {'name': 'ToTensor'},\n",
            "                                  {'mean': [0.485, 0.456, 0.406],\n",
            "                                   'name': 'Normalize',\n",
            "                                   'std': [0.229, 0.224, 0.225]}],\n",
            "                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},\n",
            "          'TRAIN': {'BATCHSIZE_PER_REPLICA': 2,\n",
            "                    'COLLATE_FUNCTION': 'default_collate',\n",
            "                    'COPY_DESTINATION_DIR': '',\n",
            "                    'COPY_TO_LOCAL_DISK': False,\n",
            "                    'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                    'DATA_LIMIT': 50,\n",
            "                    'DATA_PATHS': [],\n",
            "                    'DATA_SOURCES': ['disk_folder'],\n",
            "                    'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                    'DROP_LAST': False,\n",
            "                    'ENABLE_QUEUE_DATASET': False,\n",
            "                    'INPUT_KEY_NAMES': ['data'],\n",
            "                    'LABEL_PATHS': [],\n",
            "                    'LABEL_SOURCES': ['disk_folder'],\n",
            "                    'LABEL_TYPE': 'standard',\n",
            "                    'MMAP_MODE': True,\n",
            "                    'TARGET_KEY_NAMES': ['label'],\n",
            "                    'TRANSFORMS': [{'name': 'RandomResizedCrop', 'size': 224},\n",
            "                                   {'name': 'RandomHorizontalFlip'},\n",
            "                                   {'name': 'ToTensor'},\n",
            "                                   {'mean': [0.485, 0.456, 0.406],\n",
            "                                    'name': 'Normalize',\n",
            "                                    'std': [0.229, 0.224, 0.225]}],\n",
            "                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},\n",
            " 'DISTRIBUTED': {'BACKEND': 'nccl',\n",
            "                 'BROADCAST_BUFFERS': True,\n",
            "                 'INIT_METHOD': 'tcp',\n",
            "                 'MANUAL_GRADIENT_REDUCTION': False,\n",
            "                 'NCCL_DEBUG': False,\n",
            "                 'NUM_NODES': 1,\n",
            "                 'NUM_PROC_PER_NODE': 1,\n",
            "                 'RUN_ID': 'auto'},\n",
            " 'IMG_RETRIEVAL': {'DATASET_PATH': '',\n",
            "                   'EVAL_BINARY_PATH': '',\n",
            "                   'EVAL_DATASET_NAME': 'Paris',\n",
            "                   'FEATS_PROCESSING_TYPE': '',\n",
            "                   'GEM_POOL_POWER': 4.0,\n",
            "                   'N_PCA': 512,\n",
            "                   'RESIZE_IMG': 1024,\n",
            "                   'SHOULD_TRAIN_PCA_OR_WHITENING': True,\n",
            "                   'SPATIAL_LEVELS': 3,\n",
            "                   'TEMP_DIR': '/tmp/instance_retrieval/',\n",
            "                   'TRAIN_DATASET_NAME': 'Oxford',\n",
            "                   'WHITEN_IMG_LIST': ''},\n",
            " 'LOG_FREQUENCY': 10,\n",
            " 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},\n",
            "          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,\n",
            "                                                          'normalize_output': False,\n",
            "                                                          'reduction': 'mean',\n",
            "                                                          'weight': None},\n",
            "          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,\n",
            "                                 'DROP_LAST': True,\n",
            "                                 'kmeans_iters': 10,\n",
            "                                 'memory_params': {'crops_for_mb': [0],\n",
            "                                                   'embedding_dim': 128},\n",
            "                                 'num_clusters': [3000, 3000, 3000],\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_train_samples': -1,\n",
            "                                 'temperature': 0.1},\n",
            "          'moco_loss': {'embedding_dim': 128,\n",
            "                        'momentum': 0.999,\n",
            "                        'queue_size': 65536,\n",
            "                        'temperature': 0.2},\n",
            "          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                               'embedding_dim': 128,\n",
            "                                                               'world_size': 64},\n",
            "                                             'num_crops': 2,\n",
            "                                             'temperature': 0.1},\n",
            "          'name': 'cross_entropy_multiple_output_single_target',\n",
            "          'nce_loss_with_memory': {'loss_type': 'nce',\n",
            "                                   'loss_weights': [1.0],\n",
            "                                   'memory_params': {'embedding_dim': 128,\n",
            "                                                     'memory_size': -1,\n",
            "                                                     'momentum': 0.5,\n",
            "                                                     'norm_init': True,\n",
            "                                                     'update_mem_on_forward': True},\n",
            "                                   'negative_sampling_params': {'num_negatives': 16000,\n",
            "                                                                'type': 'random'},\n",
            "                                   'norm_constant': -1,\n",
            "                                   'norm_embedding': True,\n",
            "                                   'num_train_samples': -1,\n",
            "                                   'temperature': 0.07,\n",
            "                                   'update_mem_with_emb_index': -100},\n",
            "          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                     'embedding_dim': 128,\n",
            "                                                     'world_size': 64},\n",
            "                                   'temperature': 0.1},\n",
            "          'swav_loss': {'crops_for_assign': [0, 1],\n",
            "                        'embedding_dim': 128,\n",
            "                        'epsilon': 0.05,\n",
            "                        'normalize_last_layer': True,\n",
            "                        'num_crops': 2,\n",
            "                        'num_iters': 3,\n",
            "                        'num_prototypes': [3000],\n",
            "                        'queue': {'local_queue_length': 0,\n",
            "                                  'queue_length': 0,\n",
            "                                  'start_iter': 0},\n",
            "                        'temperature': 0.1,\n",
            "                        'use_double_precision': False}},\n",
            " 'MACHINE': {'DEVICE': 'gpu'},\n",
            " 'METERS': {'accuracy_list_meter': {'meter_names': ['res5', 'res5avg'],\n",
            "                                    'num_meters': 2,\n",
            "                                    'topk_values': [1, 5]}},\n",
            " 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,\n",
            "                                        'USE_ACTIVATION_CHECKPOINTING': False},\n",
            "           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'}, 'USE_AMP': False},\n",
            "           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': True,\n",
            "                                     'EVAL_TRUNK_AND_HEAD': False,\n",
            "                                     'EXTRACT_TRUNK_FEATURES_ONLY': False,\n",
            "                                     'FREEZE_TRUNK_AND_HEAD': False,\n",
            "                                     'FREEZE_TRUNK_ONLY': True,\n",
            "                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [['res5',\n",
            "                                                                        ['AvgPool2d',\n",
            "                                                                         [[6,\n",
            "                                                                           6],\n",
            "                                                                          1,\n",
            "                                                                          0]]],\n",
            "                                                                       ['res5avg',\n",
            "                                                                        ['Identity',\n",
            "                                                                         []]]],\n",
            "                                     'SHOULD_FLATTEN_FEATS': False},\n",
            "           'HEAD': {'BATCHNORM_EPS': 1e-05,\n",
            "                    'BATCHNORM_MOMENTUM': 0.1,\n",
            "                    'PARAMS': [['eval_mlp',\n",
            "                                {'dims': [8192, 1000], 'in_channels': 2048}],\n",
            "                               ['eval_mlp',\n",
            "                                {'dims': [2048, 1000], 'in_channels': 2048}]],\n",
            "                    'PARAMS_MULTIPLIER': 100.0},\n",
            "           'INPUT_TYPE': 'rgb',\n",
            "           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,\n",
            "                                'INPUT_SHAPE': [3, 224, 224]},\n",
            "           'MULTI_INPUT_HEAD_MAPPING': [],\n",
            "           'NON_TRAINABLE_PARAMS': [],\n",
            "           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': True,\n",
            "                              'GROUP_SIZE': 0,\n",
            "                              'SYNC_BN_TYPE': 'pytorch'},\n",
            "           'TEMP_FROZEN_PARAMS_ITER_MAP': [],\n",
            "           'TRUNK': {'NAME': 'resnet',\n",
            "                     'TRUNK_PARAMS': {'EFFICIENT_NETS': {},\n",
            "                                      'REGNETS': {},\n",
            "                                      'RESNETS': {'DEPTH': 50,\n",
            "                                                  'GROUPS': 1,\n",
            "                                                  'LAYER4_STRIDE': 2,\n",
            "                                                  'NORM': 'BatchNorm',\n",
            "                                                  'WIDTH_MULTIPLIER': 1,\n",
            "                                                  'WIDTH_PER_GROUP': 64,\n",
            "                                                  'ZERO_INIT_RESIDUAL': False}}},\n",
            "           'WEIGHTS_INIT': {'APPEND_PREFIX': 'trunk.base_model._feature_blocks.',\n",
            "                            'PARAMS_FILE': '/content/resnet50-19c8e357.pth',\n",
            "                            'REMOVE_PREFIX': '',\n",
            "                            'SKIP_LAYERS': ['num_batches_tracked'],\n",
            "                            'STATE_DICT_KEY_NAME': ''}},\n",
            " 'MONITOR_PERF_STATS': True,\n",
            " 'MULTI_PROCESSING_METHOD': 'forkserver',\n",
            " 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},\n",
            " 'OPTIMIZER': {'head_optimizer_params': {'use_different_lr': True,\n",
            "                                         'use_different_wd': True,\n",
            "                                         'weight_decay': 0.0001},\n",
            "               'larc_config': {'clip': False,\n",
            "                               'eps': 1e-08,\n",
            "                               'trust_coefficient': 0.001},\n",
            "               'momentum': 0.9,\n",
            "               'name': 'sgd',\n",
            "               'nesterov': True,\n",
            "               'num_epochs': 2,\n",
            "               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': False,\n",
            "                                                               'base_lr_batch_size': 256,\n",
            "                                                               'base_value': 0.1},\n",
            "                                           'end_value': 0.0,\n",
            "                                           'interval_scaling': [],\n",
            "                                           'lengths': [],\n",
            "                                           'milestones': [1],\n",
            "                                           'name': 'multistep',\n",
            "                                           'schedulers': [],\n",
            "                                           'start_value': 0.1,\n",
            "                                           'update_interval': 'epoch',\n",
            "                                           'value': 0.1,\n",
            "                                           'values': [0.01, 0.001]},\n",
            "                                    'lr_head': {'milestones': [1],\n",
            "                                                'name': 'multistep',\n",
            "                                                'update_interval': 'epoch',\n",
            "                                                'values': [0.2, 0.02]}},\n",
            "               'regularize_bias': True,\n",
            "               'regularize_bn': False,\n",
            "               'use_larc': False,\n",
            "               'weight_decay': 0.0005},\n",
            " 'PERF_STAT_FREQUENCY': -1,\n",
            " 'ROLLING_BTIME_FREQ': -1,\n",
            " 'SEED_VALUE': 1,\n",
            " 'SVM': {'cls_list': [],\n",
            "         'costs': {'base': -1.0,\n",
            "                   'costs_list': [0.1, 0.01],\n",
            "                   'power_range': [4, 20]},\n",
            "         'cross_val_folds': 3,\n",
            "         'dual': True,\n",
            "         'force_retrain': False,\n",
            "         'loss': 'squared_hinge',\n",
            "         'low_shot': {'dataset_name': 'voc',\n",
            "                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],\n",
            "                      'sample_inds': [1, 2, 3, 4, 5]},\n",
            "         'max_iter': 2000,\n",
            "         'normalize': True,\n",
            "         'penalty': 'l2'},\n",
            " 'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': '',\n",
            "                       'FLUSH_EVERY_N_MIN': 5,\n",
            "                       'LOG_ACTIVATIONS': True,\n",
            "                       'LOG_DIR': '.',\n",
            "                       'USE_TENSORBOARD': False},\n",
            " 'TEST_EVERY_NUM_EPOCH': 2,\n",
            " 'TEST_MODEL': True,\n",
            " 'TEST_ONLY': False,\n",
            " 'TRAINER': {'TRAIN_STEP_NAME': 'standard_train_step'},\n",
            " 'VERBOSE': True}\n",
            "INFO 2021-01-13 22:05:08,590 train.py:  65: System config:\n",
            "-------------------  ---------------------------------------------------------------\n",
            "sys.platform         linux\n",
            "Python               3.6.9 (default, Oct  8 2020, 12:12:24) [GCC 8.4.0]\n",
            "numpy                1.19.5\n",
            "Pillow               7.0.0\n",
            "vissl                0.1.3 @/usr/local/lib/python3.6/dist-packages/vissl\n",
            "GPU available        True\n",
            "GPU 0                Tesla T4\n",
            "CUDA_HOME            /usr/local/cuda\n",
            "torchvision          0.6.1+cu101 @/usr/local/lib/python3.6/dist-packages/torchvision\n",
            "hydra                1.0.5 @/usr/local/lib/python3.6/dist-packages/hydra\n",
            "classy_vision        0.5.0 @/usr/local/lib/python3.6/dist-packages/classy_vision\n",
            "tensorboard          1.15.0\n",
            "apex                 0.1 @/usr/local/lib/python3.6/dist-packages/apex\n",
            "cv2                  4.1.2\n",
            "PyTorch              1.5.1+cu101 @/usr/local/lib/python3.6/dist-packages/torch\n",
            "PyTorch debug build  False\n",
            "-------------------  ---------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 10.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "CPU info:\n",
            "-------------------  ------------------------------\n",
            "Architecture         x86_64\n",
            "CPU op-mode(s)       32-bit, 64-bit\n",
            "Byte Order           Little Endian\n",
            "CPU(s)               2\n",
            "On-line CPU(s) list  0,1\n",
            "Thread(s) per core   2\n",
            "Core(s) per socket   1\n",
            "Socket(s)            1\n",
            "NUMA node(s)         1\n",
            "Vendor ID            GenuineIntel\n",
            "CPU family           6\n",
            "Model                79\n",
            "Model name           Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping             0\n",
            "CPU MHz              2199.998\n",
            "BogoMIPS             4399.99\n",
            "Hypervisor vendor    KVM\n",
            "Virtualization type  full\n",
            "L1d cache            32K\n",
            "L1i cache            32K\n",
            "L2 cache             256K\n",
            "L3 cache             56320K\n",
            "NUMA node0 CPU(s)    0,1\n",
            "-------------------  ------------------------------\n",
            "INFO 2021-01-13 22:05:08,591 train_task.py: 121: Setting amp args: None\n",
            "INFO 2021-01-13 22:05:08,591 trainer_main.py:  61: Using Distributed init method: tcp://localhost:39005, world_size: 1, rank: 0\n",
            "INFO 2021-01-13 22:05:08,592 trainer_main.py:  82: | initialized host 1e768c2ad305 as rank 0 (0)\n",
            "INFO 2021-01-13 22:05:08,593 ssl_dataset.py:  68: Rank: 0 Data files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-01-13 22:05:08,593 ssl_dataset.py:  69: Rank: 0 Label files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-01-13 22:05:08,593 disk_dataset.py:  77: Loaded 10 samples from folder /content/dummy_data/val\n",
            "INFO 2021-01-13 22:05:08,593 ssl_dataset.py:  68: Rank: 0 Data files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-01-13 22:05:08,594 ssl_dataset.py:  69: Rank: 0 Label files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-01-13 22:05:08,594 disk_dataset.py:  77: Loaded 10 samples from folder /content/dummy_data/train\n",
            "INFO 2021-01-13 22:05:08,594 misc.py:  68: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-01-13 22:05:08,594 __init__.py:  64: Created the Distributed Sampler....\n",
            "INFO 2021-01-13 22:05:08,594 __init__.py:  52: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "INFO 2021-01-13 22:05:08,594 __init__.py: 106: Wrapping the dataloader to async device copies\n",
            "INFO 2021-01-13 22:05:12,270 misc.py:  68: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-01-13 22:05:12,271 __init__.py:  64: Created the Distributed Sampler....\n",
            "INFO 2021-01-13 22:05:12,271 __init__.py:  52: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "INFO 2021-01-13 22:05:12,271 __init__.py: 106: Wrapping the dataloader to async device copies\n",
            "INFO 2021-01-13 22:05:12,271 train_task.py: 280: Building model....\n",
            "INFO 2021-01-13 22:05:12,271 feature_extractor.py:  23: Creating Feature extractor trunk...\n",
            "INFO 2021-01-13 22:05:12,272 resnext.py:  58: ResNeXT trunk, supports activation checkpointing. Deactivated\n",
            "INFO 2021-01-13 22:05:12,272 resnext.py:  72: Building model: ResNeXt50-1x64d-w1-BatchNorm2d\n",
            "INFO 2021-01-13 22:05:12,845 feature_extractor.py:  46: Freezing model trunk...\n",
            "INFO 2021-01-13 22:05:12,911 model_helpers.py:  85: Using SyncBN group size: None\n",
            "INFO 2021-01-13 22:05:12,911 model_helpers.py: 100: Converting BN layers to PyTorch SyncBN\n",
            "INFO 2021-01-13 22:05:12,911 model_helpers.py: 103: Not creating process_group for PyTorch SyncBN...\n",
            "INFO 2021-01-13 22:05:12,917 train_task.py: 298: config.MODEL.FEATURE_EVAL_SETTINGS.FREEZE_TRUNK_ONLY=True, will freeze trunk...\n",
            "INFO 2021-01-13 22:05:12,917 base_ssl_model.py: 151: Freezing model trunk...\n",
            "INFO 2021-01-13 22:05:12,917 train_task.py: 253: Initializing model from: /content/resnet50-19c8e357.pth\n",
            "INFO 2021-01-13 22:05:13,101 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,101 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,101 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,101 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,101 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,101 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,101 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,102 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,102 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,102 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,102 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,102 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,102 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,102 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,102 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,102 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,102 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,102 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,103 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,103 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,103 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,103 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,103 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,103 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,103 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,103 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,103 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,103 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,103 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,104 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,104 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,104 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,104 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,104 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,104 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,104 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,104 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,104 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,104 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,105 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,105 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,105 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,105 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,105 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,105 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,105 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,105 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,105 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,105 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,105 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,105 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,106 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,106 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,106 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,106 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,106 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,106 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,106 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,106 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,106 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,106 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,106 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,107 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,107 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,107 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,107 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,107 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,107 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,107 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,107 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,107 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,107 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,108 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,108 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,108 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,108 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,108 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,108 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,108 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,108 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,108 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,108 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,108 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,109 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,109 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,109 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,109 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,109 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,109 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,109 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,109 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,109 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,109 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,110 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,110 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,110 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,110 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,110 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,110 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,110 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,194 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,194 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,194 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,195 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,195 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,195 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,195 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,195 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,195 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,195 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,195 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,195 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,196 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,196 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,196 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,196 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,196 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,196 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,197 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,197 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,197 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,197 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,197 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,197 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,197 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,197 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,198 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,198 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,198 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,198 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,198 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,198 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.3.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,199 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,199 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,199 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,199 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,199 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,199 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.3.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,199 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,200 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,200 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,200 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,200 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,200 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.3.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,200 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,200 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,200 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,201 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,201 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,201 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,201 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,202 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,202 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,202 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,202 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,202 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,202 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,203 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,203 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,203 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,203 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,203 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,204 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,204 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,204 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,204 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,204 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,204 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,204 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,205 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,205 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,205 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,205 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,205 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,205 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,206 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,206 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,206 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,206 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,206 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,206 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,206 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,207 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,207 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,207 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,207 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,207 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,207 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,207 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,207 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,208 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,208 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,208 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,208 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,208 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,209 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,209 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,209 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,209 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,209 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,209 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,209 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,209 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,210 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,210 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,210 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,210 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,210 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,210 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,210 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.3.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,211 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,211 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,211 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,211 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,211 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,211 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.3.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,212 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,212 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,212 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,212 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,212 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,212 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.3.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,212 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,213 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,213 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,213 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,213 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,213 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.4.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,214 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,214 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,214 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,214 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,214 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,214 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.4.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,214 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,214 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,215 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,215 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,215 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,215 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.4.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,215 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,215 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,215 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,215 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,216 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,216 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.5.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,216 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,216 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,217 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,302 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,302 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,302 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.5.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,303 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,303 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,303 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,303 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,303 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,303 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.5.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,304 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,304 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,304 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,304 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,304 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,304 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,306 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,306 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,306 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,307 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,307 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,307 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,308 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,308 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,308 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,308 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,308 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,308 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,310 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,310 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,310 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,310 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,310 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,310 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,311 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,311 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,311 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,311 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,311 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,312 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,313 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,313 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,313 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,314 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,314 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,314 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,315 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,315 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,315 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,315 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,315 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,315 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,316 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,316 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,316 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,316 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,316 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,317 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,318 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,318 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,319 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,319 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,319 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,319 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,320 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,320 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,320 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,320 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,320 checkpoint.py: 405: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-13 22:05:13,320 checkpoint.py: 377: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,320 checkpoint.py: 413: Not found:\t\theads.0.channel_bn.weight, not initialized\n",
            "INFO 2021-01-13 22:05:13,320 checkpoint.py: 413: Not found:\t\theads.0.channel_bn.bias, not initialized\n",
            "INFO 2021-01-13 22:05:13,320 checkpoint.py: 413: Not found:\t\theads.0.channel_bn.running_mean, not initialized\n",
            "INFO 2021-01-13 22:05:13,321 checkpoint.py: 413: Not found:\t\theads.0.channel_bn.running_var, not initialized\n",
            "INFO 2021-01-13 22:05:13,321 checkpoint.py: 377: Ignored layer:\theads.0.channel_bn.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,321 checkpoint.py: 413: Not found:\t\theads.0.clf.clf.0.weight, not initialized\n",
            "INFO 2021-01-13 22:05:13,321 checkpoint.py: 413: Not found:\t\theads.0.clf.clf.0.bias, not initialized\n",
            "INFO 2021-01-13 22:05:13,321 checkpoint.py: 413: Not found:\t\theads.1.channel_bn.weight, not initialized\n",
            "INFO 2021-01-13 22:05:13,321 checkpoint.py: 413: Not found:\t\theads.1.channel_bn.bias, not initialized\n",
            "INFO 2021-01-13 22:05:13,321 checkpoint.py: 413: Not found:\t\theads.1.channel_bn.running_mean, not initialized\n",
            "INFO 2021-01-13 22:05:13,321 checkpoint.py: 413: Not found:\t\theads.1.channel_bn.running_var, not initialized\n",
            "INFO 2021-01-13 22:05:13,321 checkpoint.py: 377: Ignored layer:\theads.1.channel_bn.num_batches_tracked\n",
            "INFO 2021-01-13 22:05:13,321 checkpoint.py: 413: Not found:\t\theads.1.clf.clf.0.weight, not initialized\n",
            "INFO 2021-01-13 22:05:13,321 checkpoint.py: 413: Not found:\t\theads.1.clf.clf.0.bias, not initialized\n",
            "INFO 2021-01-13 22:05:13,321 checkpoint.py: 420: Extra layers not loaded from checkpoint: ['trunk.base_model._feature_blocks.fc.weight', 'trunk.base_model._feature_blocks.fc.bias']\n",
            "INFO 2021-01-13 22:05:13,323 train_task.py: 437: Broadcast model BN buffers from master on every forward pass\n",
            "INFO 2021-01-13 22:05:13,323 classification_task.py: 341: Synchronized Batch Normalization is disabled\n",
            "INFO 2021-01-13 22:05:13,323 train_task.py: 222: Building loss...\n",
            "INFO 2021-01-13 22:05:13,378 optimizer_helper.py:  86: Traininable params: 8, Non-Traininable params: 0, Regularized Parameters: 4, Unregularized Parameters 4\n",
            "INFO 2021-01-13 22:05:13,379 trainer_main.py: 168: Training 2 epochs. One epoch = 5 iterations\n",
            "INFO 2021-01-13 22:05:13,379 trainer_main.py: 170: Total 10 iterations for training\n",
            "INFO 2021-01-13 22:05:13,379 trainer_main.py: 171: Total 10 samples in one epoch\n",
            "INFO 2021-01-13 22:05:13,527 logger.py:  66: Wed Jan 13 22:05:13 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W /  70W |    947MiB / 15079MiB |      9%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "INFO 2021-01-13 22:05:13,530 trainer_main.py: 103: Model is:\n",
            " Classy <class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'>:\n",
            "BaseSSLMultiInputOutputModel(\n",
            "  (_heads): ModuleDict()\n",
            "  (trunk): FeatureExtractorModel(\n",
            "    (base_model): ResNeXt(\n",
            "      (_feature_blocks): ModuleDict(\n",
            "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv1_relu): ReLU(inplace=True)\n",
            "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "        (layer1): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (layer2): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (layer3): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (4): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (5): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (layer4): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), bias=False)\n",
            "              (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "        (flatten): Flatten()\n",
            "      )\n",
            "    )\n",
            "    (feature_pool_ops): ModuleList(\n",
            "      (0): AvgPool2d(kernel_size=[6, 6], stride=1, padding=0)\n",
            "      (1): Identity()\n",
            "    )\n",
            "  )\n",
            "  (heads): ModuleList(\n",
            "    (0): LinearEvalMLP(\n",
            "      (channel_bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (clf): MLP(\n",
            "        (clf): Sequential(\n",
            "          (0): Linear(in_features=8192, out_features=1000, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): LinearEvalMLP(\n",
            "      (channel_bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (clf): MLP(\n",
            "        (clf): Sequential(\n",
            "          (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "INFO 2021-01-13 22:05:13,607 trainer_main.py: 104: Loss is: CrossEntropyMultipleOutputSingleTargetLoss(\n",
            "  (_losses): ModuleList()\n",
            ")\n",
            "INFO 2021-01-13 22:05:13,607 trainer_main.py: 105: Starting training....\n",
            "INFO 2021-01-13 22:05:13,609 __init__.py:  52: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-13 22:05:16,057 trainer_main.py: 205: Phase advanced. Rank: 0\n",
            "INFO 2021-01-13 22:05:16,058 state_update_hooks.py:  90: Starting phase 0 [train]\n",
            "INFO 2021-01-13 22:05:16,483 log_hooks.py: 119: Rank: 0; [ep: 0] iter: 1; lr: 0.01; loss: 14.02678; btime(ms): 3102; eta: 0:00:27; peak_mem: 2452M\n",
            "INFO 2021-01-13 22:05:16,544 log_hooks.py: 119: Rank: 0; [ep: 0] iter: 5; lr: 0.01; loss: 81.22306; btime(ms): 632; eta: 0:00:03; peak_mem: 2452M\n",
            "INFO 2021-01-13 22:05:16,544 trainer_main.py: 123: Meters synced\n",
            "INFO 2021-01-13 22:05:16,554 log_hooks.py: 298: Average train batch time (ms) for 5 batches: 99\n",
            "INFO 2021-01-13 22:05:16,554 log_hooks.py: 307: Train step time breakdown (rank 0):\n",
            "               Timer     Host    CudaEvent\n",
            "         read_sample:   15.63 ms   15.02 ms\n",
            "             forward:   75.92 ms   76.24 ms\n",
            "        loss_compute:    1.55 ms    0.52 ms\n",
            "     loss_all_reduce:    0.06 ms    0.07 ms\n",
            "       meters_update:    0.53 ms    0.55 ms\n",
            "            backward:    1.03 ms    1.65 ms\n",
            "      optimizer_step:    0.51 ms    2.55 ms\n",
            "    train_step_total:   97.09 ms   97.15 ms\n",
            "INFO 2021-01-13 22:05:16,555 log_hooks.py: 228: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 0.0, 'res5avg': 0.0}, 'top_5': {'res5': 40.0, 'res5avg': 0.0}}\n",
            "INFO 2021-01-13 22:05:16,555 io.py:  16: Saving data to file: ./checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-01-13 22:05:16,555 io.py:  30: Saved data to file: ./checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-01-13 22:05:16,555 log_hooks.py: 182: [phase: 0] Saving checkpoint to ./checkpoints_trunk_eval\n",
            "INFO 2021-01-13 22:05:16,831 log_hooks.py: 212: Saved checkpoint: ./checkpoints_trunk_eval/model_phase0.torch\n",
            "INFO 2021-01-13 22:05:16,831 __init__.py:  52: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 1, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-13 22:05:19,199 trainer_main.py: 205: Phase advanced. Rank: 0\n",
            "INFO 2021-01-13 22:05:19,199 state_update_hooks.py:  90: Starting phase 1 [test]\n",
            "INFO 2021-01-13 22:05:19,334 trainer_main.py: 123: Meters synced\n",
            "INFO 2021-01-13 22:05:19,334 log_hooks.py: 298: Average test batch time (ms) for 5 batches: 26\n",
            "INFO 2021-01-13 22:05:19,334 log_hooks.py: 228: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 50.0, 'res5avg': 50.0}, 'top_5': {'res5': 50.0, 'res5avg': 50.0}}\n",
            "INFO 2021-01-13 22:05:19,334 io.py:  16: Saving data to file: ./checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-01-13 22:05:19,335 io.py:  30: Saved data to file: ./checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-01-13 22:05:19,335 __init__.py:  52: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 2, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-13 22:05:21,782 trainer_main.py: 205: Phase advanced. Rank: 0\n",
            "INFO 2021-01-13 22:05:21,782 state_update_hooks.py:  90: Starting phase 2 [train]\n",
            "INFO 2021-01-13 22:05:21,912 log_hooks.py: 119: Rank: 0; [ep: 1] iter: 10; lr: 0.001; loss: 18.53993; btime(ms): 568; eta: 0:00:00; peak_mem: 2452M\n",
            "INFO 2021-01-13 22:05:21,913 trainer_main.py: 123: Meters synced\n",
            "INFO 2021-01-13 22:05:21,913 log_hooks.py: 298: Average train batch time (ms) for 5 batches: 26\n",
            "INFO 2021-01-13 22:05:21,913 log_hooks.py: 307: Train step time breakdown (rank 0):\n",
            "               Timer     Host    CudaEvent\n",
            "         read_sample:    5.69 ms    4.44 ms\n",
            "             forward:    9.47 ms   15.96 ms\n",
            "        loss_compute:    7.10 ms    0.46 ms\n",
            "     loss_all_reduce:    0.06 ms    0.06 ms\n",
            "       meters_update:    0.51 ms    0.52 ms\n",
            "            backward:    0.89 ms    1.69 ms\n",
            "      optimizer_step:    0.53 ms    2.43 ms\n",
            "    train_step_total:   25.78 ms   26.01 ms\n",
            "INFO 2021-01-13 22:05:21,913 log_hooks.py: 228: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 60.0, 'res5avg': 10.0}, 'top_5': {'res5': 80.0, 'res5avg': 30.0}}\n",
            "INFO 2021-01-13 22:05:21,913 io.py:  16: Saving data to file: ./checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-01-13 22:05:21,914 io.py:  30: Saved data to file: ./checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-01-13 22:05:21,914 log_hooks.py: 182: [phase: 2] Saving checkpoint to ./checkpoints_trunk_eval\n",
            "INFO 2021-01-13 22:05:22,181 log_hooks.py: 212: Saved checkpoint: ./checkpoints_trunk_eval/model_final_checkpoint_phase2.torch\n",
            "INFO 2021-01-13 22:05:22,181 __init__.py:  52: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 3, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-13 22:05:24,533 trainer_main.py: 205: Phase advanced. Rank: 0\n",
            "INFO 2021-01-13 22:05:24,534 state_update_hooks.py:  90: Starting phase 3 [test]\n",
            "INFO 2021-01-13 22:05:24,667 trainer_main.py: 123: Meters synced\n",
            "INFO 2021-01-13 22:05:24,667 log_hooks.py: 298: Average test batch time (ms) for 5 batches: 26\n",
            "INFO 2021-01-13 22:05:24,668 log_hooks.py: 228: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 50.0, 'res5avg': 0.0}, 'top_5': {'res5': 100.0, 'res5avg': 50.0}}\n",
            "INFO 2021-01-13 22:05:24,668 io.py:  16: Saving data to file: ./checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-01-13 22:05:24,668 io.py:  30: Saved data to file: ./checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-01-13 22:05:24,746 train.py:  86: All Done!\n",
            "INFO 2021-01-13 22:05:24,746 logger.py:  59: Shutting down loggers...\n",
            "INFO 2021-01-13 22:05:24,747 run_distributed_engines.py:  95: All Done!\n",
            "INFO 2021-01-13 22:05:24,747 logger.py:  59: Shutting down loggers...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvUJcklKyI5F"
      },
      "source": [
        "And we are done!! We have the linear classifier trained on the trunk features `res5` and `res5avg` and the `metrics.json` containing `top-1` and `top-5` accuracy on validation set is available in `checkpoints_trunk_eval/metrics.json`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpQ1__UqyQgj",
        "outputId": "eb071806-0df0-41a2-cdd6-d42ba567f789"
      },
      "source": [
        "ls checkpoints_trunk_eval/"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log.txt  metrics.json  model_final_checkpoint_phase2.torch  model_phase0.torch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsvStuaWySlY",
        "outputId": "79f655db-3bff-4413-c408-357fe4c242cb"
      },
      "source": [
        "cat checkpoints_trunk_eval/metrics.json"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"iteration\": 5, \"phase_idx\": 0, \"train_accuracy_list_meter\": {\"top_1\": {\"res5\": 0.0, \"res5avg\": 0.0}, \"top_5\": {\"res5\": 40.0, \"res5avg\": 0.0}}, \"train_phase_idx\": 0}\n",
            "{\"iteration\": 5, \"phase_idx\": 1, \"test_accuracy_list_meter\": {\"top_1\": {\"res5\": 50.0, \"res5avg\": 50.0}, \"top_5\": {\"res5\": 50.0, \"res5avg\": 50.0}}, \"train_phase_idx\": 0}\n",
            "{\"iteration\": 10, \"phase_idx\": 2, \"train_accuracy_list_meter\": {\"top_1\": {\"res5\": 60.0, \"res5avg\": 10.0}, \"top_5\": {\"res5\": 80.0, \"res5avg\": 30.0}}, \"train_phase_idx\": 1}\n",
            "{\"iteration\": 10, \"phase_idx\": 3, \"test_accuracy_list_meter\": {\"top_1\": {\"res5\": 50.0, \"res5avg\": 0.0}, \"top_5\": {\"res5\": 100.0, \"res5avg\": 50.0}}, \"train_phase_idx\": 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xFUcTj00B_a"
      },
      "source": [
        "# Loading Pre-trained models in VISSL\n",
        "\n",
        "VISSL supports Torchvision models out of the box. Generally, for loading any non-VISSL model, one needs to correctly set the following configuration options:\n",
        "\n",
        "```yaml\n",
        "WEIGHTS_INIT:\n",
        "  # path to the .torch weights files\n",
        "  PARAMS_FILE: \"\"\n",
        "  # name of the state dict. checkpoint = {\"classy_state_dict\": {layername:value}}. Options:\n",
        "  #   1. classy_state_dict - if model is trained and checkpointed with VISSL.\n",
        "  #      checkpoint = {\"classy_state_dict\": {layername:value}}\n",
        "  #   2. \"\" - if the model_file is not a nested dictionary for model weights i.e.\n",
        "  #      checkpoint = {layername:value}\n",
        "  #   3. key name that your model checkpoint uses for state_dict key name.\n",
        "  #      checkpoint = {\"your_key_name\": {layername:value}}\n",
        "  STATE_DICT_KEY_NAME: \"classy_state_dict\"\n",
        "  # specify what layer should not be loaded. Layer names with this key are not copied\n",
        "  # By default, set to BatchNorm stats \"num_batches_tracked\" to be skipped.\n",
        "  SKIP_LAYERS: [\"num_batches_tracked\"]\n",
        "  ####### If loading a non-VISSL trained model, set the following two args carefully #########\n",
        "  # to make the checkpoint compatible with VISSL, if you need to remove some names\n",
        "  # from the checkpoint keys, specify the name\n",
        "  REMOVE_PREFIX: \"\"\n",
        "  # In order to load the model (if not trained with VISSL) with VISSL, there are 2 scenarios:\n",
        "  #    1. If you are interested in evaluating the model features and freeze the trunk.\n",
        "  #       Set APPEND_PREFIX=\"trunk.base_model.\" This assumes that your model is compatible\n",
        "  #       with the VISSL trunks. The VISSL trunks start with \"_feature_blocks.\" prefix. If\n",
        "  #       your model doesn't have these prefix you can append them. For example:\n",
        "  #       For TorchVision ResNet trunk, set APPEND_PREFIX=\"trunk.base_model._feature_blocks.\"\n",
        "  #    2. where you want to load the model simply and finetune the full model.\n",
        "  #       Set APPEND_PREFIX=\"trunk.\"\n",
        "  #       This assumes that your model is compatible with the VISSL trunks. The VISSL\n",
        "  #       trunks start with \"_feature_blocks.\" prefix. If your model doesn't have these\n",
        "  #       prefix you can append them.\n",
        "  #       For TorchVision ResNet trunk, set APPEND_PREFIX=\"trunk._feature_blocks.\"\n",
        "  # NOTE: the prefix is appended to all the layers in the model\n",
        "  APPEND_PREFIX: \"\"\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc9YxGbNtFg6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}