{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Benchmark Linear Image Classification on ImageNet-1K.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL8iG7SJ7Hrk"
      },
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates. All rights reserved."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XzxTZfKwFNo"
      },
      "source": [
        "# Benchmark Linear Image Classification on ImageNet-1K\n",
        "\n",
        "In this tutorial, we look at a simple example of how to use VISSL to run linear image classification benchmark for [ResNet-50 Torchvision pre-trained model](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L16). This benchmark freezes the model trunk and attaches a linear MLP on top of the trunk features.\n",
        "\n",
        "You can make a copy of this tutorial by `File -> Open in playground mode` and make changes there. DO NOT request access to this tutorial.\n",
        "\n",
        "**NOTE:** Please ensure your Collab Notebook has GPU available. To ensure/select this, simple follow: `Edit -> Notebook Settings -> select GPU`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VohdWhBSw69e"
      },
      "source": [
        "## Install VISSL\n",
        "\n",
        "Installing VISSL is pretty straightfoward. We will use pip binaries of VISSL and follow instructions from [here](https://github.com/facebookresearch/vissl/blob/master/INSTALL.md#install-vissl-pip-package)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5ISg59KTOqU"
      },
      "source": [
        "# Install: PyTorch (we assume 1.5.1 but VISSL works with all PyTorch versions >=1.4)\n",
        "!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install opencv\n",
        "!pip install opencv-python\n",
        "\n",
        "# install apex by checking system settings: cuda version, pytorch version, python version\n",
        "import sys\n",
        "import torch\n",
        "version_str=\"\".join([\n",
        "    f\"py3{sys.version_info.minor}_cu\",\n",
        "    torch.version.cuda.replace(\".\",\"\"),\n",
        "    f\"_pyt{torch.__version__[0:5:2]}\"\n",
        "])\n",
        "print(version_str)\n",
        "\n",
        "# install apex (pre-compiled with optimizer C++ extensions and CUDA kernels)\n",
        "!pip install -f https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/{version_str}/download.html apex\n",
        "\n",
        "# install VISSL\n",
        "!pip install vissl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Fxe3MWxqsI"
      },
      "source": [
        "VISSL should be successfuly installed by now and all the dependencies should be available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np6atgoOTPrA"
      },
      "source": [
        "import vissl\n",
        "import tensorboard\n",
        "import apex\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFEHZ4KdxzWq"
      },
      "source": [
        "## YAML config file for Linear benchmark\n",
        "\n",
        "VISSL provides yaml configuration files for all benchmark tasks including linear image classification on ImageNet [here](https://github.com/facebookresearch/vissl/tree/master/configs/config/benchmark). \n",
        "\n",
        "For the purpose of this tutorial, we will use [this config file](https://github.com/facebookresearch/vissl/blob/master/configs/config/test/integration_test/quick_eval_in1k_linear_imagefolder_head.yaml) for training a linear classifier on the trunk output of ResNet-50 supervised model on 1-gpu. Let's go ahead and download the [example config file](https://github.com/facebookresearch/vissl/blob/master/configs/config/test/integration_test/quick_eval_in1k_linear_imagefolder_head.yaml).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ufyNAeUaDSs"
      },
      "source": [
        "!mkdir -p configs/config\n",
        "!wget -q -O configs/__init__.py https://dl.fbaipublicfiles.com/vissl/tutorials/configs/__init__.py \n",
        "!wget -q -O configs/config/eval_in1k_linear_imagefolder_head.yaml https://dl.fbaipublicfiles.com/vissl/tutorials/configs/eval_in1k_linear_imagefolder_head.yaml"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxMXLYLpsJXj"
      },
      "source": [
        "## Download the ResNet-50 weights from Torchvision\n",
        "\n",
        "We download the weights from the [torchvision ResNet50 model](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L16):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv0quZwFsWxs"
      },
      "source": [
        "!wget https://download.pytorch.org/models/resnet50-19c8e357.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndNMJGSRyffl"
      },
      "source": [
        "## Builtin training tool in VISSL\n",
        "\n",
        "VISSL also provides a [helper python tool](https://github.com/facebookresearch/vissl/blob/master/tools/run_distributed_engines.py) that allows to use VISSL for training purposes. This tool offers:\n",
        "- allows training and feature extraction both using VISSL. \n",
        "- also allows training on 1-gpu or multi-gpu. \n",
        "- can be used to launch multi-machine distributed training.\n",
        "\n",
        "Let's go ahead and download this tool directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6io7qQWzCbw"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/vissl/tutorials/run_distributed_engines.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0hng2EPY7pr"
      },
      "source": [
        "## Creating a custom data\n",
        "\n",
        "For the purpose of this tutorial, since we don't have ImageNet on the disk, we will create a dummy dataset by copying an image from COCO dataset in ImageNet dataset folder style as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-sy6nD-RfwB"
      },
      "source": [
        "!mkdir -p dummy_data/train/class1\n",
        "!mkdir -p dummy_data/train/class2\n",
        "!mkdir -p dummy_data/val/class1\n",
        "!mkdir -p dummy_data/val/class2\n",
        "\n",
        "# create 2 classes in train and add 5 images per class\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img5.jpg\n",
        "\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img5.jpg\n",
        "\n",
        "# create 2 classes in val and add 5 images per class\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img5.jpg\n",
        "\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img5.jpg\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPGCiTsXZeW3"
      },
      "source": [
        "## Using the custom data in VISSL\n",
        "\n",
        "Next step for us is to register the dummy data we created above with VISSL. Registering the dataset involves telling VISSL about the dataset name and the paths for the dataset. For this, we create a simple json file with the metadata and save it to `configs/config/dataset_catalog.py` file.\n",
        "\n",
        "**NOTE**: VISSL uses the specific `dataset_catalog.json` under the path `configs/config/dataset_catalog.json`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8Q6LCqaWjl1"
      },
      "source": [
        "json_data = {\n",
        "    \"dummy_data_folder\": {\n",
        "      \"train\": [\n",
        "        \"/content/dummy_data/train\", \"/content/dummy_data/train\"\n",
        "      ],\n",
        "      \"val\": [\n",
        "        \"/content/dummy_data/val\", \"/content/dummy_data/val\"\n",
        "      ]\n",
        "    }\n",
        "}\n",
        "\n",
        "# use VISSL's api to save or you can use your custom code.\n",
        "from vissl.utils.io import save_file\n",
        "save_file(json_data, \"/content/configs/config/dataset_catalog.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otN1pB32cBHK"
      },
      "source": [
        "Next, we verify that the dataset is registered with VISSL. For that we query VISSL's dataset catalog as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZBhH-s5bcHd",
        "outputId": "ba43329c-3b1e-4c2d-d1e8-8c9356c3073a"
      },
      "source": [
        "from vissl.data.dataset_catalog import VisslDatasetCatalog\n",
        "\n",
        "# list all the datasets that exist in catalog\n",
        "print(VisslDatasetCatalog.list())\n",
        "\n",
        "# get the metadata of dummy_data_folder dataset\n",
        "print(VisslDatasetCatalog.get(\"dummy_data_folder\"))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dummy_data_folder']\n",
            "{'train': ['/content/dummy_data/train', '/content/dummy_data/train'], 'val': ['/content/dummy_data/val', '/content/dummy_data/val']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaUMDwMdzYHN"
      },
      "source": [
        "## Training linear classifier on trunk output\n",
        "\n",
        "We are ready to train the linear classifier now. For the purpose of this tutorial, we will use synthetic dataset and train on dummy images. VISSL supports training on wide range of datasets and allows adding custom datasets. Please see VISSL documentation on how to use the datasets. To train on ImageNet instead: assuming your ImageNet dataset folder path is `/path/to/my/imagenet/folder/`, you can add the following command line \n",
        "input to your training command: \n",
        "```\n",
        "config.DATA.TRAIN.DATASET_NAMES=[imagenet1k_folder] \\\n",
        "config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "config.DATA.TRAIN.DATA_PATHS=[\"/path/to/my/imagenet/folder/train\"] \\\n",
        "config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM7IigSpONW0"
      },
      "source": [
        "The training command looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v0HvauIj9S2",
        "outputId": "27d8055f-a6a5-41f2-d6d4-80b0556220d2"
      },
      "source": [
        "!python3 run_distributed_engines.py \\\n",
        "    hydra.verbose=true \\\n",
        "    config=eval_in1k_linear_imagefolder_head \\\n",
        "    config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DATA.TEST.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TEST.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DISTRIBUTED.NUM_NODES=1 \\\n",
        "    config.DISTRIBUTED.NUM_PROC_PER_NODE=1 \\\n",
        "    config.CHECKPOINT.DIR=\"./checkpoints\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.PARAMS_FILE=\"/content/resnet50-19c8e357.pth\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=\"trunk._feature_blocks.\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=\"\"\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "####### overrides: ['hydra.verbose=true', 'config=eval_in1k_linear_imagefolder_head', 'config.DATA.TRAIN.DATA_SOURCES=[disk_folder]', 'config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]', 'config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2', 'config.DATA.TEST.DATA_SOURCES=[disk_folder]', 'config.DATA.TEST.LABEL_SOURCES=[disk_folder]', 'config.DATA.TEST.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TEST.BATCHSIZE_PER_REPLICA=2', 'config.DISTRIBUTED.NUM_NODES=1', 'config.DISTRIBUTED.NUM_PROC_PER_NODE=1', 'config.CHECKPOINT.DIR=./checkpoints', 'config.MODEL.WEIGHTS_INIT.PARAMS_FILE=/content/resnet50-19c8e357.pth', 'config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=trunk._feature_blocks.', 'config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=', 'hydra.verbose=true']\n",
            "INFO 2021-01-25 20:26:50,640 __init__.py:  32: Provided Config has latest version: 1\n",
            "[PathManager] Attempting to register prefix 'http://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 194, in <module>\n",
            "    hydra_main(overrides=overrides)\n",
            "  File \"run_distributed_engines.py\", line 179, in hydra_main\n",
            "    hook_generator=default_hook_generator,\n",
            "  File \"run_distributed_engines.py\", line 77, in launch_distributed\n",
            "    set_env_vars(local_rank=0, node_id=node_id, cfg=cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'http://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "[PathManager] Attempting to register prefix 'https://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 194, in <module>\n",
            "    hydra_main(overrides=overrides)\n",
            "  File \"run_distributed_engines.py\", line 179, in hydra_main\n",
            "    hook_generator=default_hook_generator,\n",
            "  File \"run_distributed_engines.py\", line 77, in launch_distributed\n",
            "    set_env_vars(local_rank=0, node_id=node_id, cfg=cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'https://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "[PathManager] Attempting to register prefix 'ftp://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 194, in <module>\n",
            "    hydra_main(overrides=overrides)\n",
            "  File \"run_distributed_engines.py\", line 179, in hydra_main\n",
            "    hook_generator=default_hook_generator,\n",
            "  File \"run_distributed_engines.py\", line 77, in launch_distributed\n",
            "    set_env_vars(local_rank=0, node_id=node_id, cfg=cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'ftp://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "INFO 2021-01-25 20:26:50,641 run_distributed_engines.py: 163: Spawning process for node_id: 0, local_rank: 0, dist_rank: 0, dist_run_id: localhost:47225\n",
            "[PathManager] Attempting to register prefix 'http://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 166, in _distributed_worker\n",
            "    process_main(cfg, dist_run_id, local_rank=local_rank, node_id=node_id)\n",
            "  File \"run_distributed_engines.py\", line 159, in process_main\n",
            "    hook_generator=hook_generator,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/engines/train.py\", line 60, in train_main\n",
            "    set_env_vars(local_rank, node_id, cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'http://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "[PathManager] Attempting to register prefix 'https://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 166, in _distributed_worker\n",
            "    process_main(cfg, dist_run_id, local_rank=local_rank, node_id=node_id)\n",
            "  File \"run_distributed_engines.py\", line 159, in process_main\n",
            "    hook_generator=hook_generator,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/engines/train.py\", line 60, in train_main\n",
            "    set_env_vars(local_rank, node_id, cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'https://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "[PathManager] Attempting to register prefix 'ftp://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 166, in _distributed_worker\n",
            "    process_main(cfg, dist_run_id, local_rank=local_rank, node_id=node_id)\n",
            "  File \"run_distributed_engines.py\", line 159, in process_main\n",
            "    hook_generator=hook_generator,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/engines/train.py\", line 60, in train_main\n",
            "    set_env_vars(local_rank, node_id, cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'ftp://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "INFO 2021-01-25 20:26:50,642 train.py:  66: Env set for rank: 0, dist_rank: 0\n",
            "INFO 2021-01-25 20:26:50,642 env.py:  41: CLICOLOR:\t1\n",
            "INFO 2021-01-25 20:26:50,642 env.py:  41: CLOUDSDK_CONFIG:\t/content/.config\n",
            "INFO 2021-01-25 20:26:50,642 env.py:  41: CLOUDSDK_PYTHON:\tpython3\n",
            "INFO 2021-01-25 20:26:50,643 env.py:  41: COLAB_GPU:\t1\n",
            "INFO 2021-01-25 20:26:50,643 env.py:  41: CUDA_PKG_VERSION:\t10-1=10.1.243-1\n",
            "INFO 2021-01-25 20:26:50,643 env.py:  41: CUDA_VERSION:\t10.1.243\n",
            "INFO 2021-01-25 20:26:50,643 env.py:  41: CUDNN_VERSION:\t7.6.5.32\n",
            "INFO 2021-01-25 20:26:50,643 env.py:  41: DATALAB_SETTINGS_OVERRIDES:\t{\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=\\\"172.28.0.2\\\"\"],\"debugAdapterMultiplexerPath\":\"/usr/local/bin/dap_multiplexer\"}\n",
            "INFO 2021-01-25 20:26:50,643 env.py:  41: DEBIAN_FRONTEND:\tnoninteractive\n",
            "INFO 2021-01-25 20:26:50,643 env.py:  41: ENV:\t/root/.bashrc\n",
            "INFO 2021-01-25 20:26:50,643 env.py:  41: GCE_METADATA_TIMEOUT:\t0\n",
            "INFO 2021-01-25 20:26:50,643 env.py:  41: GCS_READ_CACHE_BLOCK_SIZE_MB:\t16\n",
            "INFO 2021-01-25 20:26:50,643 env.py:  41: GIT_PAGER:\tcat\n",
            "INFO 2021-01-25 20:26:50,643 env.py:  41: GLIBCPP_FORCE_NEW:\t1\n",
            "INFO 2021-01-25 20:26:50,643 env.py:  41: GLIBCXX_FORCE_NEW:\t1\n",
            "INFO 2021-01-25 20:26:50,643 env.py:  41: HOME:\t/root\n",
            "INFO 2021-01-25 20:26:50,643 env.py:  41: HOSTNAME:\tec590053bcdc\n",
            "INFO 2021-01-25 20:26:50,643 env.py:  41: JPY_PARENT_PID:\t50\n",
            "INFO 2021-01-25 20:26:50,643 env.py:  41: LANG:\ten_US.UTF-8\n",
            "INFO 2021-01-25 20:26:50,643 env.py:  41: LAST_FORCED_REBUILD:\t20210119\n",
            "INFO 2021-01-25 20:26:50,643 env.py:  41: LD_LIBRARY_PATH:\t/usr/lib64-nvidia\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: LD_PRELOAD:\t/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: LIBRARY_PATH:\t/usr/local/cuda/lib64/stubs\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: LOCAL_RANK:\t0\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: MPLBACKEND:\tmodule://ipykernel.pylab.backend_inline\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: NCCL_VERSION:\t2.8.3\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: NO_GCE_CHECK:\tTrue\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: NVIDIA_DRIVER_CAPABILITIES:\tcompute,utility\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: NVIDIA_REQUIRE_CUDA:\tcuda>=10.1 brand=tesla,driver>=396,driver<397 brand=tesla,driver>=410,driver<411 brand=tesla,driver>=418,driver<419\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: NVIDIA_VISIBLE_DEVICES:\tall\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: OLDPWD:\t/\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: PAGER:\tcat\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: PATH:\t/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: PWD:\t/content\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: PYTHONPATH:\t/env/python\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: PYTHONWARNINGS:\tignore:::pip._internal.cli.base_command\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: RANK:\t0\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: SHELL:\t/bin/bash\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: SHLVL:\t1\n",
            "INFO 2021-01-25 20:26:50,644 env.py:  41: TBE_CREDS_ADDR:\t172.28.0.1:8008\n",
            "INFO 2021-01-25 20:26:50,645 env.py:  41: TERM:\txterm-color\n",
            "INFO 2021-01-25 20:26:50,645 env.py:  41: TF_FORCE_GPU_ALLOW_GROWTH:\ttrue\n",
            "INFO 2021-01-25 20:26:50,645 env.py:  41: WORLD_SIZE:\t1\n",
            "INFO 2021-01-25 20:26:50,645 env.py:  41: _:\t/usr/bin/python3\n",
            "INFO 2021-01-25 20:26:50,645 env.py:  41: __EGL_VENDOR_LIBRARY_DIRS:\t/usr/lib64-nvidia:/usr/share/glvnd/egl_vendor.d/\n",
            "INFO 2021-01-25 20:26:50,645 misc.py:  86: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-01-25 20:26:50,645 train.py:  77: Setting seed....\n",
            "INFO 2021-01-25 20:26:50,645 misc.py:  99: MACHINE SEED: 1\n",
            "INFO 2021-01-25 20:26:50,681 hydra_config.py: 140: Training with config:\n",
            "INFO 2021-01-25 20:26:50,686 hydra_config.py: 144: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,\n",
            "                'AUTO_RESUME': True,\n",
            "                'BACKEND': 'disk',\n",
            "                'CHECKPOINT_FREQUENCY': 2,\n",
            "                'CHECKPOINT_ITER_FREQUENCY': -1,\n",
            "                'DIR': './checkpoints',\n",
            "                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,\n",
            "                'OVERWRITE_EXISTING': True,\n",
            "                'USE_SYMLINK_CHECKPOINT_FOR_RESUME': False},\n",
            " 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',\n",
            "                'FEATURES': {'DATASET_NAME': '',\n",
            "                             'DATA_PARTITION': 'TRAIN',\n",
            "                             'LAYER_NAME': ''},\n",
            "                'NUM_CLUSTERS': 16000,\n",
            "                'N_ITER': 50},\n",
            " 'DATA': {'DDP_BUCKET_CAP_MB': 25,\n",
            "          'ENABLE_ASYNC_GPU_COPY': True,\n",
            "          'NUM_DATALOADER_WORKERS': 2,\n",
            "          'PIN_MEMORY': True,\n",
            "          'TEST': {'BATCHSIZE_PER_REPLICA': 2,\n",
            "                   'COLLATE_FUNCTION': 'default_collate',\n",
            "                   'COLLATE_FUNCTION_PARAMS': {},\n",
            "                   'COPY_DESTINATION_DIR': '',\n",
            "                   'COPY_TO_LOCAL_DISK': False,\n",
            "                   'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                   'DATA_LIMIT': 50,\n",
            "                   'DATA_PATHS': [],\n",
            "                   'DATA_SOURCES': ['disk_folder'],\n",
            "                   'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                   'DROP_LAST': False,\n",
            "                   'ENABLE_QUEUE_DATASET': False,\n",
            "                   'INPUT_KEY_NAMES': ['data'],\n",
            "                   'LABEL_PATHS': [],\n",
            "                   'LABEL_SOURCES': ['disk_folder'],\n",
            "                   'LABEL_TYPE': 'standard',\n",
            "                   'MMAP_MODE': True,\n",
            "                   'TARGET_KEY_NAMES': ['label'],\n",
            "                   'TRANSFORMS': [{'name': 'Resize', 'size': 256},\n",
            "                                  {'name': 'CenterCrop', 'size': 224},\n",
            "                                  {'name': 'ToTensor'},\n",
            "                                  {'mean': [0.485, 0.456, 0.406],\n",
            "                                   'name': 'Normalize',\n",
            "                                   'std': [0.229, 0.224, 0.225]}],\n",
            "                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},\n",
            "          'TRAIN': {'BATCHSIZE_PER_REPLICA': 2,\n",
            "                    'COLLATE_FUNCTION': 'default_collate',\n",
            "                    'COLLATE_FUNCTION_PARAMS': {},\n",
            "                    'COPY_DESTINATION_DIR': '',\n",
            "                    'COPY_TO_LOCAL_DISK': False,\n",
            "                    'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                    'DATA_LIMIT': 50,\n",
            "                    'DATA_PATHS': [],\n",
            "                    'DATA_SOURCES': ['disk_folder'],\n",
            "                    'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                    'DROP_LAST': False,\n",
            "                    'ENABLE_QUEUE_DATASET': False,\n",
            "                    'INPUT_KEY_NAMES': ['data'],\n",
            "                    'LABEL_PATHS': [],\n",
            "                    'LABEL_SOURCES': ['disk_folder'],\n",
            "                    'LABEL_TYPE': 'standard',\n",
            "                    'MMAP_MODE': True,\n",
            "                    'TARGET_KEY_NAMES': ['label'],\n",
            "                    'TRANSFORMS': [{'name': 'RandomResizedCrop', 'size': 224},\n",
            "                                   {'name': 'RandomHorizontalFlip'},\n",
            "                                   {'name': 'ToTensor'},\n",
            "                                   {'mean': [0.485, 0.456, 0.406],\n",
            "                                    'name': 'Normalize',\n",
            "                                    'std': [0.229, 0.224, 0.225]}],\n",
            "                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},\n",
            " 'DISTRIBUTED': {'BACKEND': 'nccl',\n",
            "                 'BROADCAST_BUFFERS': True,\n",
            "                 'INIT_METHOD': 'tcp',\n",
            "                 'MANUAL_GRADIENT_REDUCTION': False,\n",
            "                 'NCCL_DEBUG': False,\n",
            "                 'NCCL_SOCKET_NTHREADS': '',\n",
            "                 'NUM_NODES': 1,\n",
            "                 'NUM_PROC_PER_NODE': 1,\n",
            "                 'RUN_ID': 'auto'},\n",
            " 'IMG_RETRIEVAL': {'DATASET_PATH': '',\n",
            "                   'EVAL_BINARY_PATH': '',\n",
            "                   'EVAL_DATASET_NAME': 'Paris',\n",
            "                   'FEATS_PROCESSING_TYPE': '',\n",
            "                   'GEM_POOL_POWER': 4.0,\n",
            "                   'N_PCA': 512,\n",
            "                   'RESIZE_IMG': 1024,\n",
            "                   'SHOULD_TRAIN_PCA_OR_WHITENING': True,\n",
            "                   'SPATIAL_LEVELS': 3,\n",
            "                   'TEMP_DIR': '/tmp/instance_retrieval/',\n",
            "                   'TRAIN_DATASET_NAME': 'Oxford',\n",
            "                   'WHITEN_IMG_LIST': ''},\n",
            " 'LOG_FREQUENCY': 10,\n",
            " 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},\n",
            "          'bce_logits_multiple_output_single_target': {'normalize_output': False,\n",
            "                                                       'reduction': 'none',\n",
            "                                                       'world_size': 1},\n",
            "          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,\n",
            "                                                          'normalize_output': False,\n",
            "                                                          'reduction': 'mean',\n",
            "                                                          'temperature': 1.0,\n",
            "                                                          'weight': None},\n",
            "          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,\n",
            "                                 'DROP_LAST': True,\n",
            "                                 'kmeans_iters': 10,\n",
            "                                 'memory_params': {'crops_for_mb': [0],\n",
            "                                                   'embedding_dim': 128},\n",
            "                                 'num_clusters': [3000, 3000, 3000],\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_train_samples': -1,\n",
            "                                 'temperature': 0.1},\n",
            "          'moco_loss': {'embedding_dim': 128,\n",
            "                        'momentum': 0.999,\n",
            "                        'queue_size': 65536,\n",
            "                        'temperature': 0.2},\n",
            "          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                               'embedding_dim': 128,\n",
            "                                                               'world_size': 64},\n",
            "                                             'num_crops': 2,\n",
            "                                             'temperature': 0.1},\n",
            "          'name': 'cross_entropy_multiple_output_single_target',\n",
            "          'nce_loss_with_memory': {'loss_type': 'nce',\n",
            "                                   'loss_weights': [1.0],\n",
            "                                   'memory_params': {'embedding_dim': 128,\n",
            "                                                     'memory_size': -1,\n",
            "                                                     'momentum': 0.5,\n",
            "                                                     'norm_init': True,\n",
            "                                                     'update_mem_on_forward': True},\n",
            "                                   'negative_sampling_params': {'num_negatives': 16000,\n",
            "                                                                'type': 'random'},\n",
            "                                   'norm_constant': -1,\n",
            "                                   'norm_embedding': True,\n",
            "                                   'num_train_samples': -1,\n",
            "                                   'temperature': 0.07,\n",
            "                                   'update_mem_with_emb_index': -100},\n",
            "          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                     'embedding_dim': 128,\n",
            "                                                     'world_size': 64},\n",
            "                                   'temperature': 0.1},\n",
            "          'swav_loss': {'crops_for_assign': [0, 1],\n",
            "                        'embedding_dim': 128,\n",
            "                        'epsilon': 0.05,\n",
            "                        'normalize_last_layer': True,\n",
            "                        'num_crops': 2,\n",
            "                        'num_iters': 3,\n",
            "                        'num_prototypes': [3000],\n",
            "                        'output_dir': '',\n",
            "                        'queue': {'local_queue_length': 0,\n",
            "                                  'queue_length': 0,\n",
            "                                  'start_iter': 0},\n",
            "                        'temp_hard_assignment_iters': 0,\n",
            "                        'temperature': 0.1,\n",
            "                        'use_double_precision': False},\n",
            "          'swav_momentum_loss': {'crops_for_assign': [0, 1],\n",
            "                                 'embedding_dim': 128,\n",
            "                                 'epsilon': 0.05,\n",
            "                                 'momentum': 0.99,\n",
            "                                 'momentum_eval_mode_iter_start': 0,\n",
            "                                 'normalize_last_layer': True,\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_iters': 3,\n",
            "                                 'num_prototypes': [3000],\n",
            "                                 'queue': {'local_queue_length': 0,\n",
            "                                           'queue_length': 0,\n",
            "                                           'start_iter': 0},\n",
            "                                 'temperature': 0.1,\n",
            "                                 'use_double_precision': False}},\n",
            " 'MACHINE': {'DEVICE': 'gpu'},\n",
            " 'METERS': {'accuracy_list_meter': {'meter_names': [],\n",
            "                                    'num_meters': 1,\n",
            "                                    'topk_values': [1, 5]},\n",
            "            'enable_training_meter': True,\n",
            "            'mean_ap_list_meter': {'max_cpu_capacity': -1,\n",
            "                                   'meter_names': [],\n",
            "                                   'num_classes': 9605,\n",
            "                                   'num_meters': 1},\n",
            "            'name': 'accuracy_list_meter'},\n",
            " 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,\n",
            "                                        'USE_ACTIVATION_CHECKPOINTING': False},\n",
            "           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'},\n",
            "                          'AMP_TYPE': 'apex',\n",
            "                          'USE_AMP': False},\n",
            "           'CUDA_CACHE': {'CLEAR_CUDA_CACHE': False, 'CLEAR_FREQ': 100},\n",
            "           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': True,\n",
            "                                     'EVAL_TRUNK_AND_HEAD': False,\n",
            "                                     'EXTRACT_TRUNK_FEATURES_ONLY': False,\n",
            "                                     'FREEZE_TRUNK_AND_HEAD': False,\n",
            "                                     'FREEZE_TRUNK_ONLY': True,\n",
            "                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [],\n",
            "                                     'SHOULD_FLATTEN_FEATS': False},\n",
            "           'HEAD': {'BATCHNORM_EPS': 1e-05,\n",
            "                    'BATCHNORM_MOMENTUM': 0.1,\n",
            "                    'PARAMS': [['eval_mlp',\n",
            "                                {'dims': [2048, 1000], 'in_channels': 2048}]],\n",
            "                    'PARAMS_MULTIPLIER': 1.0},\n",
            "           'INPUT_TYPE': 'rgb',\n",
            "           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,\n",
            "                                'INPUT_SHAPE': [3, 224, 224]},\n",
            "           'MULTI_INPUT_HEAD_MAPPING': [],\n",
            "           'NON_TRAINABLE_PARAMS': [],\n",
            "           'SINGLE_PASS_EVERY_CROP': False,\n",
            "           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': True,\n",
            "                              'GROUP_SIZE': 0,\n",
            "                              'SYNC_BN_TYPE': 'pytorch'},\n",
            "           'TEMP_FROZEN_PARAMS_ITER_MAP': [],\n",
            "           'TRUNK': {'NAME': 'resnet',\n",
            "                     'TRUNK_PARAMS': {'EFFICIENT_NETS': {},\n",
            "                                      'REGNET': {},\n",
            "                                      'RESNETS': {'DEPTH': 50,\n",
            "                                                  'GROUPS': 1,\n",
            "                                                  'LAYER4_STRIDE': 2,\n",
            "                                                  'NORM': 'BatchNorm',\n",
            "                                                  'WIDTH_MULTIPLIER': 1,\n",
            "                                                  'WIDTH_PER_GROUP': 64,\n",
            "                                                  'ZERO_INIT_RESIDUAL': False}}},\n",
            "           'WEIGHTS_INIT': {'APPEND_PREFIX': 'trunk._feature_blocks.',\n",
            "                            'PARAMS_FILE': '/content/resnet50-19c8e357.pth',\n",
            "                            'REMOVE_PREFIX': '',\n",
            "                            'SKIP_LAYERS': ['num_batches_tracked'],\n",
            "                            'STATE_DICT_KEY_NAME': ''}},\n",
            " 'MONITOR_PERF_STATS': True,\n",
            " 'MULTI_PROCESSING_METHOD': 'forkserver',\n",
            " 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},\n",
            " 'OPTIMIZER': {'head_optimizer_params': {'use_different_lr': False,\n",
            "                                         'use_different_wd': False,\n",
            "                                         'weight_decay': 0.0005},\n",
            "               'larc_config': {'clip': False,\n",
            "                               'eps': 1e-08,\n",
            "                               'trust_coefficient': 0.001},\n",
            "               'momentum': 0.9,\n",
            "               'name': 'sgd',\n",
            "               'nesterov': True,\n",
            "               'num_epochs': 2,\n",
            "               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': False,\n",
            "                                                               'base_lr_batch_size': 256,\n",
            "                                                               'base_value': 0.1},\n",
            "                                           'end_value': 0.0,\n",
            "                                           'interval_scaling': [],\n",
            "                                           'lengths': [],\n",
            "                                           'milestones': [1],\n",
            "                                           'name': 'multistep',\n",
            "                                           'schedulers': [],\n",
            "                                           'start_value': 0.1,\n",
            "                                           'update_interval': 'epoch',\n",
            "                                           'value': 0.1,\n",
            "                                           'values': [0.01, 0.001]},\n",
            "                                    'lr_head': {'auto_lr_scaling': {'auto_scale': False,\n",
            "                                                                    'base_lr_batch_size': 256,\n",
            "                                                                    'base_value': 0.1},\n",
            "                                                'end_value': 0.0,\n",
            "                                                'interval_scaling': [],\n",
            "                                                'lengths': [],\n",
            "                                                'milestones': [1],\n",
            "                                                'name': 'multistep',\n",
            "                                                'schedulers': [],\n",
            "                                                'start_value': 0.1,\n",
            "                                                'update_interval': 'epoch',\n",
            "                                                'value': 0.1,\n",
            "                                                'values': [0.01, 0.001]}},\n",
            "               'regularize_bias': True,\n",
            "               'regularize_bn': False,\n",
            "               'use_larc': False,\n",
            "               'weight_decay': 0.0005},\n",
            " 'PERF_STAT_FREQUENCY': -1,\n",
            " 'ROLLING_BTIME_FREQ': -1,\n",
            " 'SEED_VALUE': 1,\n",
            " 'SVM': {'cls_list': [],\n",
            "         'costs': {'base': -1.0,\n",
            "                   'costs_list': [0.1, 0.01],\n",
            "                   'power_range': [4, 20]},\n",
            "         'cross_val_folds': 3,\n",
            "         'dual': True,\n",
            "         'force_retrain': False,\n",
            "         'loss': 'squared_hinge',\n",
            "         'low_shot': {'dataset_name': 'voc',\n",
            "                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],\n",
            "                      'sample_inds': [1, 2, 3, 4, 5]},\n",
            "         'max_iter': 2000,\n",
            "         'normalize': True,\n",
            "         'penalty': 'l2'},\n",
            " 'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': 'tensorboard',\n",
            "                       'FLUSH_EVERY_N_MIN': 5,\n",
            "                       'LOG_DIR': '.',\n",
            "                       'LOG_PARAMS': True,\n",
            "                       'LOG_PARAMS_EVERY_N_ITERS': 310,\n",
            "                       'LOG_PARAMS_GRADIENTS': True,\n",
            "                       'USE_TENSORBOARD': False},\n",
            " 'TEST_EVERY_NUM_EPOCH': 2,\n",
            " 'TEST_MODEL': True,\n",
            " 'TEST_ONLY': False,\n",
            " 'TRAINER': {'TASK_NAME': 'self_supervision_task',\n",
            "             'TRAIN_STEP_NAME': 'standard_train_step'},\n",
            " 'VERBOSE': True}\n",
            "INFO 2021-01-25 20:26:50,948 train.py:  89: System config:\n",
            "-------------------  ---------------------------------------------------------------\n",
            "sys.platform         linux\n",
            "Python               3.6.9 (default, Oct  8 2020, 12:12:24) [GCC 8.4.0]\n",
            "numpy                1.19.5\n",
            "Pillow               7.0.0\n",
            "vissl                0.1.5 @/usr/local/lib/python3.6/dist-packages/vissl\n",
            "GPU available        True\n",
            "GPU 0                Tesla T4\n",
            "CUDA_HOME            /usr/local/cuda\n",
            "torchvision          0.6.1+cu101 @/usr/local/lib/python3.6/dist-packages/torchvision\n",
            "hydra                1.0.5 @/usr/local/lib/python3.6/dist-packages/hydra\n",
            "classy_vision        0.6.0.dev @/usr/local/lib/python3.6/dist-packages/classy_vision\n",
            "tensorboard          1.15.0\n",
            "apex                 0.1 @/usr/local/lib/python3.6/dist-packages/apex\n",
            "cv2                  4.1.2\n",
            "PyTorch              1.5.1+cu101 @/usr/local/lib/python3.6/dist-packages/torch\n",
            "PyTorch debug build  False\n",
            "-------------------  ---------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 10.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "CPU info:\n",
            "-------------------  ------------------------------\n",
            "Architecture         x86_64\n",
            "CPU op-mode(s)       32-bit, 64-bit\n",
            "Byte Order           Little Endian\n",
            "CPU(s)               2\n",
            "On-line CPU(s) list  0,1\n",
            "Thread(s) per core   2\n",
            "Core(s) per socket   1\n",
            "Socket(s)            1\n",
            "NUMA node(s)         1\n",
            "Vendor ID            GenuineIntel\n",
            "CPU family           6\n",
            "Model                79\n",
            "Model name           Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping             0\n",
            "CPU MHz              2199.998\n",
            "BogoMIPS             4399.99\n",
            "Hypervisor vendor    KVM\n",
            "Virtualization type  full\n",
            "L1d cache            32K\n",
            "L1i cache            32K\n",
            "L2 cache             256K\n",
            "L3 cache             56320K\n",
            "NUMA node0 CPU(s)    0,1\n",
            "-------------------  ------------------------------\n",
            "INFO 2021-01-25 20:26:50,949 train_task.py: 192: Not using Automatic Mixed Precision\n",
            "INFO 2021-01-25 20:26:50,949 trainer_main.py: 109: Using Distributed init method: tcp://localhost:47225, world_size: 1, rank: 0\n",
            "INFO 2021-01-25 20:26:50,950 trainer_main.py: 130: | initialized host ec590053bcdc as rank 0 (0)\n",
            "INFO 2021-01-25 20:26:50,951 ssl_dataset.py: 130: Rank: 0 split: TEST Data files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-01-25 20:26:50,951 ssl_dataset.py: 133: Rank: 0 split: TEST Label files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-01-25 20:26:50,952 disk_dataset.py:  81: Loaded 10 samples from folder /content/dummy_data/val\n",
            "INFO 2021-01-25 20:26:50,952 ssl_dataset.py: 130: Rank: 0 split: TRAIN Data files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-01-25 20:26:50,952 ssl_dataset.py: 133: Rank: 0 split: TRAIN Label files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-01-25 20:26:50,952 disk_dataset.py:  81: Loaded 10 samples from folder /content/dummy_data/train\n",
            "INFO 2021-01-25 20:26:50,952 misc.py:  86: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-01-25 20:26:50,952 __init__.py:  91: Created the Distributed Sampler....\n",
            "INFO 2021-01-25 20:26:50,952 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "INFO 2021-01-25 20:26:50,953 __init__.py: 155: Wrapping the dataloader to async device copies\n",
            "INFO 2021-01-25 20:26:54,714 misc.py:  86: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-01-25 20:26:54,714 __init__.py:  91: Created the Distributed Sampler....\n",
            "INFO 2021-01-25 20:26:54,714 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "INFO 2021-01-25 20:26:54,714 __init__.py: 155: Wrapping the dataloader to async device copies\n",
            "INFO 2021-01-25 20:26:54,715 train_task.py: 419: Building model....\n",
            "INFO 2021-01-25 20:26:54,715 resnext.py:  63: ResNeXT trunk, supports activation checkpointing. Deactivated\n",
            "INFO 2021-01-25 20:26:54,715 resnext.py:  83: Building model: ResNeXt50-1x64d-w1-BatchNorm2d\n",
            "INFO 2021-01-25 20:26:55,307 model_helpers.py: 138: Using SyncBN group size: None\n",
            "INFO 2021-01-25 20:26:55,308 model_helpers.py: 153: Converting BN layers to PyTorch SyncBN\n",
            "INFO 2021-01-25 20:26:55,308 model_helpers.py: 156: Not creating process_group for PyTorch SyncBN...\n",
            "INFO 2021-01-25 20:26:55,313 train_task.py: 437: config.MODEL.FEATURE_EVAL_SETTINGS.FREEZE_TRUNK_ONLY=True, will freeze trunk...\n",
            "INFO 2021-01-25 20:26:55,313 base_ssl_model.py: 181: Freezing model trunk...\n",
            "INFO 2021-01-25 20:26:55,314 train_task.py: 378: Initializing model from: /content/resnet50-19c8e357.pth\n",
            "INFO 2021-01-25 20:26:55,314 util.py: 277: Attempting to load checkpoint from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-01-25 20:26:55,510 util.py: 282: Loaded checkpoint from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-01-25 20:26:55,510 util.py: 241: Broadcasting checkpoint loaded from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-01-25 20:26:58,428 checkpoint.py: 455: Loaded: trunk._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,429 checkpoint.py: 455: Loaded: trunk._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,429 checkpoint.py: 455: Loaded: trunk._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,429 checkpoint.py: 455: Loaded: trunk._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,429 checkpoint.py: 455: Loaded: trunk._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,429 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,429 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,429 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,429 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,430 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,430 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,430 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,430 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,430 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,430 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,430 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,430 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,430 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,430 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,430 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,431 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,431 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,431 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,431 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,431 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,431 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,431 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,431 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,431 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,431 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,431 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,431 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,432 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,432 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,432 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,432 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,432 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,432 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,432 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,432 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,432 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,432 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,432 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,432 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,433 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,433 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,433 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,433 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,433 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,433 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,433 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,433 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,433 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,433 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,433 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,433 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,434 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,434 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,434 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,434 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,434 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,434 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,434 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,434 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,434 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,434 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer1.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,434 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,434 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,435 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,435 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,435 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,435 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,435 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,435 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,435 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,435 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,435 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,435 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,436 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,436 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,436 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,436 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,436 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,436 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,436 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,436 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,436 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,436 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,437 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,437 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,437 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,437 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,437 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,437 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,437 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,437 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,437 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,437 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,438 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,438 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,438 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,438 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,438 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,438 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,438 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,438 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,438 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,438 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,438 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,439 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,439 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,439 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,439 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,439 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,439 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,439 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,439 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,439 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,439 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,440 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,472 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,472 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,473 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,473 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,473 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,473 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,473 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,473 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,473 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,474 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,474 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,474 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.3.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,474 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,474 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,474 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,474 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,475 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,475 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.3.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,475 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,475 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,475 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,475 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,475 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,475 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer2.3.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,476 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,476 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,476 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,476 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,476 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,476 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,477 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,477 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,477 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,477 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,477 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,477 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,477 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,477 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,477 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,478 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,478 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,478 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,478 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,478 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,478 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,478 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,479 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,479 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,479 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,479 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,479 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,479 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,479 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,479 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,480 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,480 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,480 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,480 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,480 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,480 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,480 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,481 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,481 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,481 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,481 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,481 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,481 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,481 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,481 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,481 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,482 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,482 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,482 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,482 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,482 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,482 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,482 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,483 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,483 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,483 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,483 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,483 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,483 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,483 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,484 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,484 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,484 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,484 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,484 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,484 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.3.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,484 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,485 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,485 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,485 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,485 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,485 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.3.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,485 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,485 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,485 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,485 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,486 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,486 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.3.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,486 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,486 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,486 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,486 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,486 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,486 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.4.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,487 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,487 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,487 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,487 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,487 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,487 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.4.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,488 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,488 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,488 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,488 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,488 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,488 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.4.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,488 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,488 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,488 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,489 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,489 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,489 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.5.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,489 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,489 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,489 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,490 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,490 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,490 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.5.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,490 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,490 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,490 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,490 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,490 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,490 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer3.5.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,576 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,576 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,576 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,577 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,577 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,577 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,579 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,579 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,579 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,579 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,579 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,579 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,580 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,580 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,580 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,580 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,580 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,580 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,582 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,582 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,582 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,582 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,582 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,582 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,583 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,583 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,583 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,584 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,584 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,584 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,585 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,586 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,586 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,586 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,586 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,586 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,587 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,587 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,587 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,587 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,587 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,587 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,588 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,588 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,588 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,588 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,588 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,588 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,590 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,590 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,590 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,591 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,591 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,591 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,592 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,592 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,592 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,592 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,592 checkpoint.py: 455: Loaded: trunk._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:26:58,592 checkpoint.py: 427: Ignored layer:\ttrunk._feature_blocks.layer4.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,592 checkpoint.py: 463: Not found:\t\theads.0.channel_bn.weight, not initialized\n",
            "INFO 2021-01-25 20:26:58,592 checkpoint.py: 463: Not found:\t\theads.0.channel_bn.bias, not initialized\n",
            "INFO 2021-01-25 20:26:58,592 checkpoint.py: 463: Not found:\t\theads.0.channel_bn.running_mean, not initialized\n",
            "INFO 2021-01-25 20:26:58,592 checkpoint.py: 463: Not found:\t\theads.0.channel_bn.running_var, not initialized\n",
            "INFO 2021-01-25 20:26:58,592 checkpoint.py: 427: Ignored layer:\theads.0.channel_bn.num_batches_tracked\n",
            "INFO 2021-01-25 20:26:58,592 checkpoint.py: 463: Not found:\t\theads.0.clf.clf.0.weight, not initialized\n",
            "INFO 2021-01-25 20:26:58,592 checkpoint.py: 463: Not found:\t\theads.0.clf.clf.0.bias, not initialized\n",
            "INFO 2021-01-25 20:26:58,593 checkpoint.py: 470: Extra layers not loaded from checkpoint: ['trunk._feature_blocks.fc.weight', 'trunk._feature_blocks.fc.bias']\n",
            "INFO 2021-01-25 20:26:58,600 train_task.py: 591: Broadcast model BN buffers from master on every forward pass\n",
            "INFO 2021-01-25 20:26:58,600 classification_task.py: 359: Synchronized Batch Normalization is disabled\n",
            "INFO 2021-01-25 20:26:58,601 train_task.py: 340: Building loss...\n",
            "INFO 2021-01-25 20:26:58,645 optimizer_helper.py: 157: \n",
            "Trainable params: 4, \n",
            "Non-Trainable params: 0, \n",
            "Trunk Regularized Parameters: 0, \n",
            "Trunk Unregularized Parameters 0, \n",
            "Head Regularized Parameters: 2, \n",
            "Head Unregularized Parameters: 2 \n",
            "Remaining Regularized Parameters: 0 \n",
            "INFO 2021-01-25 20:26:58,645 trainer_main.py: 241: Training 2 epochs. One epoch = 5 iterations\n",
            "INFO 2021-01-25 20:26:58,645 trainer_main.py: 243: Total 10 iterations for training\n",
            "INFO 2021-01-25 20:26:58,645 trainer_main.py: 244: Total 10 samples in one epoch\n",
            "INFO 2021-01-25 20:26:58,802 logger.py:  76: Mon Jan 25 20:26:58 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    27W /  70W |    915MiB / 15079MiB |      9%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "INFO 2021-01-25 20:26:58,804 trainer_main.py: 166: Model is:\n",
            " Classy <class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'>:\n",
            "BaseSSLMultiInputOutputModel(\n",
            "  (_heads): ModuleDict()\n",
            "  (trunk): ResNeXt(\n",
            "    (_feature_blocks): ModuleDict(\n",
            "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1_relu): ReLU(inplace=True)\n",
            "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (layer1): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer2): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer3): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (4): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (5): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer4): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), bias=False)\n",
            "            (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "      (flatten): Flatten()\n",
            "    )\n",
            "  )\n",
            "  (heads): ModuleList(\n",
            "    (0): LinearEvalMLP(\n",
            "      (channel_bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (clf): MLP(\n",
            "        (clf): Sequential(\n",
            "          (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "INFO 2021-01-25 20:26:58,888 trainer_main.py: 167: Loss is: CrossEntropyMultipleOutputSingleTargetLoss(\n",
            "  (_losses): ModuleList()\n",
            ")\n",
            "INFO 2021-01-25 20:26:58,889 trainer_main.py: 168: Starting training....\n",
            "INFO 2021-01-25 20:26:58,889 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "\n",
            "INFO 2021-01-25 20:27:01,580 trainer_main.py: 296: Phase advanced. Rank: 0\n",
            "INFO 2021-01-25 20:27:01,581 state_update_hooks.py:  98: Starting phase 0 [train]\n",
            "INFO 2021-01-25 20:27:01,932 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 1; lr: 0.01; loss: 7.05151; btime(ms): 3286; eta: 0:00:29; peak_mem: 2420M\n",
            "INFO 2021-01-25 20:27:01,985 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 5; lr: 0.01; loss: 10.52996; btime(ms): 667; eta: 0:00:03; peak_mem: 2420M\n",
            "INFO 2021-01-25 20:27:01,985 trainer_main.py: 194: Meters synced\n",
            "INFO 2021-01-25 20:27:01,997 log_hooks.py: 416: Average train batch time (ms) for 5 batches: 83\n",
            "INFO 2021-01-25 20:27:01,997 log_hooks.py: 425: Train step time breakdown (rank 0):\n",
            "               Timer     Host    CudaEvent\n",
            "         read_sample:    0.51 ms    0.51 ms\n",
            "             forward:   76.24 ms   76.92 ms\n",
            "        loss_compute:    0.40 ms    0.40 ms\n",
            "     loss_all_reduce:    0.06 ms    0.07 ms\n",
            "       meters_update:    0.35 ms    0.37 ms\n",
            "            backward:    0.87 ms    0.92 ms\n",
            "      optimizer_step:    0.34 ms    0.65 ms\n",
            "    train_step_total:   80.58 ms   80.61 ms\n",
            "INFO 2021-01-25 20:27:01,997 log_hooks.py: 346: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {0: 20.0}, 'top_5': {0: 20.0}}\n",
            "INFO 2021-01-25 20:27:01,997 io.py:  56: Saving data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-25 20:27:01,997 io.py:  70: Saved data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-25 20:27:01,998 log_hooks.py: 283: [phase: 0] Saving checkpoint to ./checkpoints\n",
            "INFO 2021-01-25 20:27:02,131 log_hooks.py: 312: Saved checkpoint: ./checkpoints/model_phase0.torch\n",
            "INFO 2021-01-25 20:27:02,132 log_hooks.py: 316: Creating symlink...\n",
            "INFO 2021-01-25 20:27:02,132 log_hooks.py: 320: Created symlink: ./checkpoints/checkpoint.torch\n",
            "INFO 2021-01-25 20:27:02,133 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 1, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-25 20:27:04,556 trainer_main.py: 296: Phase advanced. Rank: 0\n",
            "INFO 2021-01-25 20:27:04,556 state_update_hooks.py:  98: Starting phase 1 [test]\n",
            "INFO 2021-01-25 20:27:04,708 trainer_main.py: 194: Meters synced\n",
            "INFO 2021-01-25 20:27:04,708 log_hooks.py: 416: Average test batch time (ms) for 5 batches: 30\n",
            "INFO 2021-01-25 20:27:04,708 log_hooks.py: 346: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {0: 50.0}, 'top_5': {0: 50.0}}\n",
            "INFO 2021-01-25 20:27:04,709 io.py:  56: Saving data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-25 20:27:04,709 io.py:  70: Saved data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-25 20:27:04,709 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 2, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-25 20:27:07,162 trainer_main.py: 296: Phase advanced. Rank: 0\n",
            "INFO 2021-01-25 20:27:07,162 state_update_hooks.py:  98: Starting phase 2 [train]\n",
            "INFO 2021-01-25 20:27:07,293 log_hooks.py: 155: Rank: 0; [ep: 1] iter: 10; lr: 0.001; loss: 6.95633; btime(ms): 576; eta: 0:00:00; peak_mem: 2420M\n",
            "INFO 2021-01-25 20:27:07,293 trainer_main.py: 194: Meters synced\n",
            "INFO 2021-01-25 20:27:07,294 log_hooks.py: 416: Average train batch time (ms) for 5 batches: 26\n",
            "INFO 2021-01-25 20:27:07,294 log_hooks.py: 425: Train step time breakdown (rank 0):\n",
            "               Timer     Host    CudaEvent\n",
            "         read_sample:    3.89 ms    3.90 ms\n",
            "             forward:   12.33 ms   17.01 ms\n",
            "        loss_compute:    0.37 ms    0.36 ms\n",
            "     loss_all_reduce:    0.07 ms    0.08 ms\n",
            "       meters_update:    0.37 ms    0.38 ms\n",
            "            backward:    1.97 ms    2.10 ms\n",
            "      optimizer_step:    0.37 ms    0.58 ms\n",
            "    train_step_total:   26.06 ms   26.08 ms\n",
            "INFO 2021-01-25 20:27:07,294 log_hooks.py: 346: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {0: 40.0}, 'top_5': {0: 40.0}}\n",
            "INFO 2021-01-25 20:27:07,294 io.py:  56: Saving data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-25 20:27:07,294 io.py:  70: Saved data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-25 20:27:07,294 log_hooks.py: 283: [phase: 2] Saving checkpoint to ./checkpoints\n",
            "INFO 2021-01-25 20:27:07,419 log_hooks.py: 312: Saved checkpoint: ./checkpoints/model_final_checkpoint_phase2.torch\n",
            "INFO 2021-01-25 20:27:07,419 log_hooks.py: 316: Creating symlink...\n",
            "Error in symlink - [Errno 17] File exists: './checkpoints/model_final_checkpoint_phase2.torch' -> './checkpoints/checkpoint.torch'\n",
            "INFO 2021-01-25 20:27:07,419 log_hooks.py: 320: Created symlink: ./checkpoints/checkpoint.torch\n",
            "INFO 2021-01-25 20:27:07,420 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 3, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-25 20:27:09,916 trainer_main.py: 296: Phase advanced. Rank: 0\n",
            "INFO 2021-01-25 20:27:09,919 state_update_hooks.py:  98: Starting phase 3 [test]\n",
            "INFO 2021-01-25 20:27:10,041 trainer_main.py: 194: Meters synced\n",
            "INFO 2021-01-25 20:27:10,042 log_hooks.py: 416: Average test batch time (ms) for 5 batches: 25\n",
            "INFO 2021-01-25 20:27:10,042 log_hooks.py: 346: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {0: 50.0}, 'top_5': {0: 50.0}}\n",
            "INFO 2021-01-25 20:27:10,042 io.py:  56: Saving data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-25 20:27:10,043 io.py:  70: Saved data to file: ./checkpoints/metrics.json\n",
            "INFO 2021-01-25 20:27:10,132 train.py: 103: All Done!\n",
            "INFO 2021-01-25 20:27:10,132 logger.py:  66: Shutting down loggers...\n",
            "INFO 2021-01-25 20:27:10,133 run_distributed_engines.py: 133: All Done!\n",
            "INFO 2021-01-25 20:27:10,133 logger.py:  66: Shutting down loggers...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8fILq7VzyOu"
      },
      "source": [
        "And we are done!! We have the linear classifier trained on the trunk output and the `metrics.json` containing `top-1` and `top-5` accuracy on validation set is available in `checkpoints/metrics.json`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otUmgl4ms96M",
        "outputId": "51fe73cf-da7e-4943-85c2-1b4e15b9ab36"
      },
      "source": [
        "ls checkpoints/"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;36mcheckpoint.torch\u001b[0m@  metrics.json                         model_phase0.torch\n",
            "log.txt            model_final_checkpoint_phase2.torch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDMLjudpya2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c8b86a1-96a3-4a6a-ed33-62d25bd65e79"
      },
      "source": [
        "cat checkpoints/metrics.json"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"iteration\": 5, \"phase_idx\": 0, \"train_accuracy_list_meter\": {\"top_1\": {\"0\": 20.0}, \"top_5\": {\"0\": 20.0}}, \"train_phase_idx\": 0}\n",
            "{\"iteration\": 5, \"phase_idx\": 1, \"test_accuracy_list_meter\": {\"top_1\": {\"0\": 50.0}, \"top_5\": {\"0\": 50.0}}, \"train_phase_idx\": 0}\n",
            "{\"iteration\": 10, \"phase_idx\": 2, \"train_accuracy_list_meter\": {\"top_1\": {\"0\": 40.0}, \"top_5\": {\"0\": 40.0}}, \"train_phase_idx\": 1}\n",
            "{\"iteration\": 10, \"phase_idx\": 3, \"test_accuracy_list_meter\": {\"top_1\": {\"0\": 50.0}, \"top_5\": {\"0\": 50.0}}, \"train_phase_idx\": 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJKSyC0txO4x"
      },
      "source": [
        "## Training linear classifiers on several trunk features\n",
        "\n",
        "VISSL also supports training linear classifiers on several features of the trunk. For the purpose of tutorial, we will use [this](https://github.com/facebookresearch/vissl/blob/master/configs/config/test/integration_test/quick_eval_in1k_linear_imagefolder.yaml) config file. Let's go ahead and download it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FEqQ8ByxjZG"
      },
      "source": [
        "!wget -q -O configs/config/eval_in1k_linear_imagefolder.yaml https://dl.fbaipublicfiles.com/vissl/tutorials/configs/eval_in1k_linear_imagefolder.yaml"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8hMOAgBxptv"
      },
      "source": [
        "Now, let's re-run the previous command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwEg7GLoxvr5",
        "outputId": "b170a63b-bfa2-4ba8-f046-b1754c2807ac"
      },
      "source": [
        "!python3 run_distributed_engines.py \\\n",
        "    hydra.verbose=true \\\n",
        "    config=eval_in1k_linear_imagefolder \\\n",
        "    config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DATA.TEST.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TEST.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DISTRIBUTED.NUM_NODES=1 \\\n",
        "    config.DISTRIBUTED.NUM_PROC_PER_NODE=1 \\\n",
        "    config.CHECKPOINT.DIR=\"./checkpoints_trunk_eval\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.PARAMS_FILE=\"/content/resnet50-19c8e357.pth\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=\"trunk.base_model._feature_blocks.\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=\"\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "####### overrides: ['hydra.verbose=true', 'config=eval_in1k_linear_imagefolder', 'config.DATA.TRAIN.DATA_SOURCES=[disk_folder]', 'config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]', 'config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2', 'config.DATA.TEST.DATA_SOURCES=[disk_folder]', 'config.DATA.TEST.LABEL_SOURCES=[disk_folder]', 'config.DATA.TEST.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TEST.BATCHSIZE_PER_REPLICA=2', 'config.DISTRIBUTED.NUM_NODES=1', 'config.DISTRIBUTED.NUM_PROC_PER_NODE=1', 'config.CHECKPOINT.DIR=./checkpoints_trunk_eval', 'config.MODEL.WEIGHTS_INIT.PARAMS_FILE=/content/resnet50-19c8e357.pth', 'config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=trunk.base_model._feature_blocks.', 'config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=', 'hydra.verbose=true']\n",
            "INFO 2021-01-25 20:29:44,966 __init__.py:  32: Provided Config has latest version: 1\n",
            "[PathManager] Attempting to register prefix 'http://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 194, in <module>\n",
            "    hydra_main(overrides=overrides)\n",
            "  File \"run_distributed_engines.py\", line 179, in hydra_main\n",
            "    hook_generator=default_hook_generator,\n",
            "  File \"run_distributed_engines.py\", line 77, in launch_distributed\n",
            "    set_env_vars(local_rank=0, node_id=node_id, cfg=cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'http://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "[PathManager] Attempting to register prefix 'https://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 194, in <module>\n",
            "    hydra_main(overrides=overrides)\n",
            "  File \"run_distributed_engines.py\", line 179, in hydra_main\n",
            "    hook_generator=default_hook_generator,\n",
            "  File \"run_distributed_engines.py\", line 77, in launch_distributed\n",
            "    set_env_vars(local_rank=0, node_id=node_id, cfg=cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'https://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "[PathManager] Attempting to register prefix 'ftp://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 194, in <module>\n",
            "    hydra_main(overrides=overrides)\n",
            "  File \"run_distributed_engines.py\", line 179, in hydra_main\n",
            "    hook_generator=default_hook_generator,\n",
            "  File \"run_distributed_engines.py\", line 77, in launch_distributed\n",
            "    set_env_vars(local_rank=0, node_id=node_id, cfg=cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'ftp://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "INFO 2021-01-25 20:29:44,967 run_distributed_engines.py: 163: Spawning process for node_id: 0, local_rank: 0, dist_rank: 0, dist_run_id: localhost:56523\n",
            "[PathManager] Attempting to register prefix 'http://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 166, in _distributed_worker\n",
            "    process_main(cfg, dist_run_id, local_rank=local_rank, node_id=node_id)\n",
            "  File \"run_distributed_engines.py\", line 159, in process_main\n",
            "    hook_generator=hook_generator,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/engines/train.py\", line 60, in train_main\n",
            "    set_env_vars(local_rank, node_id, cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'http://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "[PathManager] Attempting to register prefix 'https://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 166, in _distributed_worker\n",
            "    process_main(cfg, dist_run_id, local_rank=local_rank, node_id=node_id)\n",
            "  File \"run_distributed_engines.py\", line 159, in process_main\n",
            "    hook_generator=hook_generator,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/engines/train.py\", line 60, in train_main\n",
            "    set_env_vars(local_rank, node_id, cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'https://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "[PathManager] Attempting to register prefix 'ftp://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 166, in _distributed_worker\n",
            "    process_main(cfg, dist_run_id, local_rank=local_rank, node_id=node_id)\n",
            "  File \"run_distributed_engines.py\", line 159, in process_main\n",
            "    hook_generator=hook_generator,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/engines/train.py\", line 60, in train_main\n",
            "    set_env_vars(local_rank, node_id, cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'ftp://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "INFO 2021-01-25 20:29:44,968 train.py:  66: Env set for rank: 0, dist_rank: 0\n",
            "INFO 2021-01-25 20:29:44,968 env.py:  41: CLICOLOR:\t1\n",
            "INFO 2021-01-25 20:29:44,968 env.py:  41: CLOUDSDK_CONFIG:\t/content/.config\n",
            "INFO 2021-01-25 20:29:44,968 env.py:  41: CLOUDSDK_PYTHON:\tpython3\n",
            "INFO 2021-01-25 20:29:44,968 env.py:  41: COLAB_GPU:\t1\n",
            "INFO 2021-01-25 20:29:44,968 env.py:  41: CUDA_PKG_VERSION:\t10-1=10.1.243-1\n",
            "INFO 2021-01-25 20:29:44,968 env.py:  41: CUDA_VERSION:\t10.1.243\n",
            "INFO 2021-01-25 20:29:44,968 env.py:  41: CUDNN_VERSION:\t7.6.5.32\n",
            "INFO 2021-01-25 20:29:44,968 env.py:  41: DATALAB_SETTINGS_OVERRIDES:\t{\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=\\\"172.28.0.2\\\"\"],\"debugAdapterMultiplexerPath\":\"/usr/local/bin/dap_multiplexer\"}\n",
            "INFO 2021-01-25 20:29:44,968 env.py:  41: DEBIAN_FRONTEND:\tnoninteractive\n",
            "INFO 2021-01-25 20:29:44,969 env.py:  41: ENV:\t/root/.bashrc\n",
            "INFO 2021-01-25 20:29:44,969 env.py:  41: GCE_METADATA_TIMEOUT:\t0\n",
            "INFO 2021-01-25 20:29:44,969 env.py:  41: GCS_READ_CACHE_BLOCK_SIZE_MB:\t16\n",
            "INFO 2021-01-25 20:29:44,969 env.py:  41: GIT_PAGER:\tcat\n",
            "INFO 2021-01-25 20:29:44,969 env.py:  41: GLIBCPP_FORCE_NEW:\t1\n",
            "INFO 2021-01-25 20:29:44,969 env.py:  41: GLIBCXX_FORCE_NEW:\t1\n",
            "INFO 2021-01-25 20:29:44,969 env.py:  41: HOME:\t/root\n",
            "INFO 2021-01-25 20:29:44,969 env.py:  41: HOSTNAME:\tec590053bcdc\n",
            "INFO 2021-01-25 20:29:44,969 env.py:  41: JPY_PARENT_PID:\t50\n",
            "INFO 2021-01-25 20:29:44,969 env.py:  41: LANG:\ten_US.UTF-8\n",
            "INFO 2021-01-25 20:29:44,969 env.py:  41: LAST_FORCED_REBUILD:\t20210119\n",
            "INFO 2021-01-25 20:29:44,969 env.py:  41: LD_LIBRARY_PATH:\t/usr/lib64-nvidia\n",
            "INFO 2021-01-25 20:29:44,969 env.py:  41: LD_PRELOAD:\t/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4\n",
            "INFO 2021-01-25 20:29:44,969 env.py:  41: LIBRARY_PATH:\t/usr/local/cuda/lib64/stubs\n",
            "INFO 2021-01-25 20:29:44,969 env.py:  41: LOCAL_RANK:\t0\n",
            "INFO 2021-01-25 20:29:44,969 env.py:  41: MPLBACKEND:\tmodule://ipykernel.pylab.backend_inline\n",
            "INFO 2021-01-25 20:29:44,969 env.py:  41: NCCL_VERSION:\t2.8.3\n",
            "INFO 2021-01-25 20:29:44,969 env.py:  41: NO_GCE_CHECK:\tTrue\n",
            "INFO 2021-01-25 20:29:44,970 env.py:  41: NVIDIA_DRIVER_CAPABILITIES:\tcompute,utility\n",
            "INFO 2021-01-25 20:29:44,970 env.py:  41: NVIDIA_REQUIRE_CUDA:\tcuda>=10.1 brand=tesla,driver>=396,driver<397 brand=tesla,driver>=410,driver<411 brand=tesla,driver>=418,driver<419\n",
            "INFO 2021-01-25 20:29:44,970 env.py:  41: NVIDIA_VISIBLE_DEVICES:\tall\n",
            "INFO 2021-01-25 20:29:44,970 env.py:  41: OLDPWD:\t/\n",
            "INFO 2021-01-25 20:29:44,970 env.py:  41: PAGER:\tcat\n",
            "INFO 2021-01-25 20:29:44,970 env.py:  41: PATH:\t/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n",
            "INFO 2021-01-25 20:29:44,970 env.py:  41: PWD:\t/content\n",
            "INFO 2021-01-25 20:29:44,970 env.py:  41: PYTHONPATH:\t/env/python\n",
            "INFO 2021-01-25 20:29:44,970 env.py:  41: PYTHONWARNINGS:\tignore:::pip._internal.cli.base_command\n",
            "INFO 2021-01-25 20:29:44,970 env.py:  41: RANK:\t0\n",
            "INFO 2021-01-25 20:29:44,970 env.py:  41: SHELL:\t/bin/bash\n",
            "INFO 2021-01-25 20:29:44,970 env.py:  41: SHLVL:\t1\n",
            "INFO 2021-01-25 20:29:44,970 env.py:  41: TBE_CREDS_ADDR:\t172.28.0.1:8008\n",
            "INFO 2021-01-25 20:29:44,970 env.py:  41: TERM:\txterm-color\n",
            "INFO 2021-01-25 20:29:44,970 env.py:  41: TF_FORCE_GPU_ALLOW_GROWTH:\ttrue\n",
            "INFO 2021-01-25 20:29:44,970 env.py:  41: WORLD_SIZE:\t1\n",
            "INFO 2021-01-25 20:29:44,970 env.py:  41: _:\t/usr/bin/python3\n",
            "INFO 2021-01-25 20:29:44,970 env.py:  41: __EGL_VENDOR_LIBRARY_DIRS:\t/usr/lib64-nvidia:/usr/share/glvnd/egl_vendor.d/\n",
            "INFO 2021-01-25 20:29:44,971 misc.py:  86: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-01-25 20:29:44,971 train.py:  77: Setting seed....\n",
            "INFO 2021-01-25 20:29:44,971 misc.py:  99: MACHINE SEED: 1\n",
            "INFO 2021-01-25 20:29:45,007 hydra_config.py: 140: Training with config:\n",
            "INFO 2021-01-25 20:29:45,011 hydra_config.py: 144: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,\n",
            "                'AUTO_RESUME': True,\n",
            "                'BACKEND': 'disk',\n",
            "                'CHECKPOINT_FREQUENCY': 2,\n",
            "                'CHECKPOINT_ITER_FREQUENCY': -1,\n",
            "                'DIR': './checkpoints_trunk_eval',\n",
            "                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,\n",
            "                'OVERWRITE_EXISTING': True,\n",
            "                'USE_SYMLINK_CHECKPOINT_FOR_RESUME': False},\n",
            " 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',\n",
            "                'FEATURES': {'DATASET_NAME': '',\n",
            "                             'DATA_PARTITION': 'TRAIN',\n",
            "                             'LAYER_NAME': ''},\n",
            "                'NUM_CLUSTERS': 16000,\n",
            "                'N_ITER': 50},\n",
            " 'DATA': {'DDP_BUCKET_CAP_MB': 25,\n",
            "          'ENABLE_ASYNC_GPU_COPY': True,\n",
            "          'NUM_DATALOADER_WORKERS': 2,\n",
            "          'PIN_MEMORY': True,\n",
            "          'TEST': {'BATCHSIZE_PER_REPLICA': 2,\n",
            "                   'COLLATE_FUNCTION': 'default_collate',\n",
            "                   'COLLATE_FUNCTION_PARAMS': {},\n",
            "                   'COPY_DESTINATION_DIR': '',\n",
            "                   'COPY_TO_LOCAL_DISK': False,\n",
            "                   'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                   'DATA_LIMIT': 50,\n",
            "                   'DATA_PATHS': [],\n",
            "                   'DATA_SOURCES': ['disk_folder'],\n",
            "                   'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                   'DROP_LAST': False,\n",
            "                   'ENABLE_QUEUE_DATASET': False,\n",
            "                   'INPUT_KEY_NAMES': ['data'],\n",
            "                   'LABEL_PATHS': [],\n",
            "                   'LABEL_SOURCES': ['disk_folder'],\n",
            "                   'LABEL_TYPE': 'standard',\n",
            "                   'MMAP_MODE': True,\n",
            "                   'TARGET_KEY_NAMES': ['label'],\n",
            "                   'TRANSFORMS': [{'name': 'Resize', 'size': 256},\n",
            "                                  {'name': 'CenterCrop', 'size': 224},\n",
            "                                  {'name': 'ToTensor'},\n",
            "                                  {'mean': [0.485, 0.456, 0.406],\n",
            "                                   'name': 'Normalize',\n",
            "                                   'std': [0.229, 0.224, 0.225]}],\n",
            "                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},\n",
            "          'TRAIN': {'BATCHSIZE_PER_REPLICA': 2,\n",
            "                    'COLLATE_FUNCTION': 'default_collate',\n",
            "                    'COLLATE_FUNCTION_PARAMS': {},\n",
            "                    'COPY_DESTINATION_DIR': '',\n",
            "                    'COPY_TO_LOCAL_DISK': False,\n",
            "                    'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                    'DATA_LIMIT': 50,\n",
            "                    'DATA_PATHS': [],\n",
            "                    'DATA_SOURCES': ['disk_folder'],\n",
            "                    'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                    'DROP_LAST': False,\n",
            "                    'ENABLE_QUEUE_DATASET': False,\n",
            "                    'INPUT_KEY_NAMES': ['data'],\n",
            "                    'LABEL_PATHS': [],\n",
            "                    'LABEL_SOURCES': ['disk_folder'],\n",
            "                    'LABEL_TYPE': 'standard',\n",
            "                    'MMAP_MODE': True,\n",
            "                    'TARGET_KEY_NAMES': ['label'],\n",
            "                    'TRANSFORMS': [{'name': 'RandomResizedCrop', 'size': 224},\n",
            "                                   {'name': 'RandomHorizontalFlip'},\n",
            "                                   {'name': 'ToTensor'},\n",
            "                                   {'mean': [0.485, 0.456, 0.406],\n",
            "                                    'name': 'Normalize',\n",
            "                                    'std': [0.229, 0.224, 0.225]}],\n",
            "                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},\n",
            " 'DISTRIBUTED': {'BACKEND': 'nccl',\n",
            "                 'BROADCAST_BUFFERS': True,\n",
            "                 'INIT_METHOD': 'tcp',\n",
            "                 'MANUAL_GRADIENT_REDUCTION': False,\n",
            "                 'NCCL_DEBUG': False,\n",
            "                 'NCCL_SOCKET_NTHREADS': '',\n",
            "                 'NUM_NODES': 1,\n",
            "                 'NUM_PROC_PER_NODE': 1,\n",
            "                 'RUN_ID': 'auto'},\n",
            " 'IMG_RETRIEVAL': {'DATASET_PATH': '',\n",
            "                   'EVAL_BINARY_PATH': '',\n",
            "                   'EVAL_DATASET_NAME': 'Paris',\n",
            "                   'FEATS_PROCESSING_TYPE': '',\n",
            "                   'GEM_POOL_POWER': 4.0,\n",
            "                   'N_PCA': 512,\n",
            "                   'RESIZE_IMG': 1024,\n",
            "                   'SHOULD_TRAIN_PCA_OR_WHITENING': True,\n",
            "                   'SPATIAL_LEVELS': 3,\n",
            "                   'TEMP_DIR': '/tmp/instance_retrieval/',\n",
            "                   'TRAIN_DATASET_NAME': 'Oxford',\n",
            "                   'WHITEN_IMG_LIST': ''},\n",
            " 'LOG_FREQUENCY': 10,\n",
            " 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},\n",
            "          'bce_logits_multiple_output_single_target': {'normalize_output': False,\n",
            "                                                       'reduction': 'none',\n",
            "                                                       'world_size': 1},\n",
            "          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,\n",
            "                                                          'normalize_output': False,\n",
            "                                                          'reduction': 'mean',\n",
            "                                                          'temperature': 1.0,\n",
            "                                                          'weight': None},\n",
            "          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,\n",
            "                                 'DROP_LAST': True,\n",
            "                                 'kmeans_iters': 10,\n",
            "                                 'memory_params': {'crops_for_mb': [0],\n",
            "                                                   'embedding_dim': 128},\n",
            "                                 'num_clusters': [3000, 3000, 3000],\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_train_samples': -1,\n",
            "                                 'temperature': 0.1},\n",
            "          'moco_loss': {'embedding_dim': 128,\n",
            "                        'momentum': 0.999,\n",
            "                        'queue_size': 65536,\n",
            "                        'temperature': 0.2},\n",
            "          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                               'embedding_dim': 128,\n",
            "                                                               'world_size': 64},\n",
            "                                             'num_crops': 2,\n",
            "                                             'temperature': 0.1},\n",
            "          'name': 'cross_entropy_multiple_output_single_target',\n",
            "          'nce_loss_with_memory': {'loss_type': 'nce',\n",
            "                                   'loss_weights': [1.0],\n",
            "                                   'memory_params': {'embedding_dim': 128,\n",
            "                                                     'memory_size': -1,\n",
            "                                                     'momentum': 0.5,\n",
            "                                                     'norm_init': True,\n",
            "                                                     'update_mem_on_forward': True},\n",
            "                                   'negative_sampling_params': {'num_negatives': 16000,\n",
            "                                                                'type': 'random'},\n",
            "                                   'norm_constant': -1,\n",
            "                                   'norm_embedding': True,\n",
            "                                   'num_train_samples': -1,\n",
            "                                   'temperature': 0.07,\n",
            "                                   'update_mem_with_emb_index': -100},\n",
            "          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                     'embedding_dim': 128,\n",
            "                                                     'world_size': 64},\n",
            "                                   'temperature': 0.1},\n",
            "          'swav_loss': {'crops_for_assign': [0, 1],\n",
            "                        'embedding_dim': 128,\n",
            "                        'epsilon': 0.05,\n",
            "                        'normalize_last_layer': True,\n",
            "                        'num_crops': 2,\n",
            "                        'num_iters': 3,\n",
            "                        'num_prototypes': [3000],\n",
            "                        'output_dir': '',\n",
            "                        'queue': {'local_queue_length': 0,\n",
            "                                  'queue_length': 0,\n",
            "                                  'start_iter': 0},\n",
            "                        'temp_hard_assignment_iters': 0,\n",
            "                        'temperature': 0.1,\n",
            "                        'use_double_precision': False},\n",
            "          'swav_momentum_loss': {'crops_for_assign': [0, 1],\n",
            "                                 'embedding_dim': 128,\n",
            "                                 'epsilon': 0.05,\n",
            "                                 'momentum': 0.99,\n",
            "                                 'momentum_eval_mode_iter_start': 0,\n",
            "                                 'normalize_last_layer': True,\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_iters': 3,\n",
            "                                 'num_prototypes': [3000],\n",
            "                                 'queue': {'local_queue_length': 0,\n",
            "                                           'queue_length': 0,\n",
            "                                           'start_iter': 0},\n",
            "                                 'temperature': 0.1,\n",
            "                                 'use_double_precision': False}},\n",
            " 'MACHINE': {'DEVICE': 'gpu'},\n",
            " 'METERS': {'accuracy_list_meter': {'meter_names': ['res5', 'res5avg'],\n",
            "                                    'num_meters': 2,\n",
            "                                    'topk_values': [1, 5]},\n",
            "            'enable_training_meter': True,\n",
            "            'mean_ap_list_meter': {'max_cpu_capacity': -1,\n",
            "                                   'meter_names': [],\n",
            "                                   'num_classes': 9605,\n",
            "                                   'num_meters': 1},\n",
            "            'name': 'accuracy_list_meter'},\n",
            " 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,\n",
            "                                        'USE_ACTIVATION_CHECKPOINTING': False},\n",
            "           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'},\n",
            "                          'AMP_TYPE': 'apex',\n",
            "                          'USE_AMP': False},\n",
            "           'CUDA_CACHE': {'CLEAR_CUDA_CACHE': False, 'CLEAR_FREQ': 100},\n",
            "           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': True,\n",
            "                                     'EVAL_TRUNK_AND_HEAD': False,\n",
            "                                     'EXTRACT_TRUNK_FEATURES_ONLY': False,\n",
            "                                     'FREEZE_TRUNK_AND_HEAD': False,\n",
            "                                     'FREEZE_TRUNK_ONLY': True,\n",
            "                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [['res5',\n",
            "                                                                        ['AvgPool2d',\n",
            "                                                                         [[6,\n",
            "                                                                           6],\n",
            "                                                                          1,\n",
            "                                                                          0]]],\n",
            "                                                                       ['res5avg',\n",
            "                                                                        ['Identity',\n",
            "                                                                         []]]],\n",
            "                                     'SHOULD_FLATTEN_FEATS': False},\n",
            "           'HEAD': {'BATCHNORM_EPS': 1e-05,\n",
            "                    'BATCHNORM_MOMENTUM': 0.1,\n",
            "                    'PARAMS': [['eval_mlp',\n",
            "                                {'dims': [8192, 1000], 'in_channels': 2048}],\n",
            "                               ['eval_mlp',\n",
            "                                {'dims': [2048, 1000], 'in_channels': 2048}]],\n",
            "                    'PARAMS_MULTIPLIER': 100.0},\n",
            "           'INPUT_TYPE': 'rgb',\n",
            "           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,\n",
            "                                'INPUT_SHAPE': [3, 224, 224]},\n",
            "           'MULTI_INPUT_HEAD_MAPPING': [],\n",
            "           'NON_TRAINABLE_PARAMS': [],\n",
            "           'SINGLE_PASS_EVERY_CROP': False,\n",
            "           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': True,\n",
            "                              'GROUP_SIZE': 0,\n",
            "                              'SYNC_BN_TYPE': 'pytorch'},\n",
            "           'TEMP_FROZEN_PARAMS_ITER_MAP': [],\n",
            "           'TRUNK': {'NAME': 'resnet',\n",
            "                     'TRUNK_PARAMS': {'EFFICIENT_NETS': {},\n",
            "                                      'REGNET': {},\n",
            "                                      'RESNETS': {'DEPTH': 50,\n",
            "                                                  'GROUPS': 1,\n",
            "                                                  'LAYER4_STRIDE': 2,\n",
            "                                                  'NORM': 'BatchNorm',\n",
            "                                                  'WIDTH_MULTIPLIER': 1,\n",
            "                                                  'WIDTH_PER_GROUP': 64,\n",
            "                                                  'ZERO_INIT_RESIDUAL': False}}},\n",
            "           'WEIGHTS_INIT': {'APPEND_PREFIX': 'trunk.base_model._feature_blocks.',\n",
            "                            'PARAMS_FILE': '/content/resnet50-19c8e357.pth',\n",
            "                            'REMOVE_PREFIX': '',\n",
            "                            'SKIP_LAYERS': ['num_batches_tracked'],\n",
            "                            'STATE_DICT_KEY_NAME': ''}},\n",
            " 'MONITOR_PERF_STATS': True,\n",
            " 'MULTI_PROCESSING_METHOD': 'forkserver',\n",
            " 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},\n",
            " 'OPTIMIZER': {'head_optimizer_params': {'use_different_lr': True,\n",
            "                                         'use_different_wd': True,\n",
            "                                         'weight_decay': 0.0001},\n",
            "               'larc_config': {'clip': False,\n",
            "                               'eps': 1e-08,\n",
            "                               'trust_coefficient': 0.001},\n",
            "               'momentum': 0.9,\n",
            "               'name': 'sgd',\n",
            "               'nesterov': True,\n",
            "               'num_epochs': 2,\n",
            "               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': False,\n",
            "                                                               'base_lr_batch_size': 256,\n",
            "                                                               'base_value': 0.1},\n",
            "                                           'end_value': 0.0,\n",
            "                                           'interval_scaling': [],\n",
            "                                           'lengths': [],\n",
            "                                           'milestones': [1],\n",
            "                                           'name': 'multistep',\n",
            "                                           'schedulers': [],\n",
            "                                           'start_value': 0.1,\n",
            "                                           'update_interval': 'epoch',\n",
            "                                           'value': 0.1,\n",
            "                                           'values': [0.01, 0.001]},\n",
            "                                    'lr_head': {'auto_lr_scaling': {'auto_scale': False,\n",
            "                                                                    'base_lr_batch_size': 256,\n",
            "                                                                    'base_value': 0.1},\n",
            "                                                'end_value': 0.0,\n",
            "                                                'interval_scaling': [],\n",
            "                                                'lengths': [],\n",
            "                                                'milestones': [1],\n",
            "                                                'name': 'multistep',\n",
            "                                                'schedulers': [],\n",
            "                                                'start_value': 0.1,\n",
            "                                                'update_interval': 'epoch',\n",
            "                                                'value': 0.1,\n",
            "                                                'values': [0.2, 0.02]}},\n",
            "               'regularize_bias': True,\n",
            "               'regularize_bn': False,\n",
            "               'use_larc': False,\n",
            "               'weight_decay': 0.0005},\n",
            " 'PERF_STAT_FREQUENCY': -1,\n",
            " 'ROLLING_BTIME_FREQ': -1,\n",
            " 'SEED_VALUE': 1,\n",
            " 'SVM': {'cls_list': [],\n",
            "         'costs': {'base': -1.0,\n",
            "                   'costs_list': [0.1, 0.01],\n",
            "                   'power_range': [4, 20]},\n",
            "         'cross_val_folds': 3,\n",
            "         'dual': True,\n",
            "         'force_retrain': False,\n",
            "         'loss': 'squared_hinge',\n",
            "         'low_shot': {'dataset_name': 'voc',\n",
            "                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],\n",
            "                      'sample_inds': [1, 2, 3, 4, 5]},\n",
            "         'max_iter': 2000,\n",
            "         'normalize': True,\n",
            "         'penalty': 'l2'},\n",
            " 'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': 'tensorboard',\n",
            "                       'FLUSH_EVERY_N_MIN': 5,\n",
            "                       'LOG_DIR': '.',\n",
            "                       'LOG_PARAMS': True,\n",
            "                       'LOG_PARAMS_EVERY_N_ITERS': 310,\n",
            "                       'LOG_PARAMS_GRADIENTS': True,\n",
            "                       'USE_TENSORBOARD': False},\n",
            " 'TEST_EVERY_NUM_EPOCH': 2,\n",
            " 'TEST_MODEL': True,\n",
            " 'TEST_ONLY': False,\n",
            " 'TRAINER': {'TASK_NAME': 'self_supervision_task',\n",
            "             'TRAIN_STEP_NAME': 'standard_train_step'},\n",
            " 'VERBOSE': True}\n",
            "INFO 2021-01-25 20:29:45,321 train.py:  89: System config:\n",
            "-------------------  ---------------------------------------------------------------\n",
            "sys.platform         linux\n",
            "Python               3.6.9 (default, Oct  8 2020, 12:12:24) [GCC 8.4.0]\n",
            "numpy                1.19.5\n",
            "Pillow               7.0.0\n",
            "vissl                0.1.5 @/usr/local/lib/python3.6/dist-packages/vissl\n",
            "GPU available        True\n",
            "GPU 0                Tesla T4\n",
            "CUDA_HOME            /usr/local/cuda\n",
            "torchvision          0.6.1+cu101 @/usr/local/lib/python3.6/dist-packages/torchvision\n",
            "hydra                1.0.5 @/usr/local/lib/python3.6/dist-packages/hydra\n",
            "classy_vision        0.6.0.dev @/usr/local/lib/python3.6/dist-packages/classy_vision\n",
            "tensorboard          1.15.0\n",
            "apex                 0.1 @/usr/local/lib/python3.6/dist-packages/apex\n",
            "cv2                  4.1.2\n",
            "PyTorch              1.5.1+cu101 @/usr/local/lib/python3.6/dist-packages/torch\n",
            "PyTorch debug build  False\n",
            "-------------------  ---------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 10.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "CPU info:\n",
            "-------------------  ------------------------------\n",
            "Architecture         x86_64\n",
            "CPU op-mode(s)       32-bit, 64-bit\n",
            "Byte Order           Little Endian\n",
            "CPU(s)               2\n",
            "On-line CPU(s) list  0,1\n",
            "Thread(s) per core   2\n",
            "Core(s) per socket   1\n",
            "Socket(s)            1\n",
            "NUMA node(s)         1\n",
            "Vendor ID            GenuineIntel\n",
            "CPU family           6\n",
            "Model                79\n",
            "Model name           Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping             0\n",
            "CPU MHz              2199.998\n",
            "BogoMIPS             4399.99\n",
            "Hypervisor vendor    KVM\n",
            "Virtualization type  full\n",
            "L1d cache            32K\n",
            "L1i cache            32K\n",
            "L2 cache             256K\n",
            "L3 cache             56320K\n",
            "NUMA node0 CPU(s)    0,1\n",
            "-------------------  ------------------------------\n",
            "INFO 2021-01-25 20:29:45,322 train_task.py: 192: Not using Automatic Mixed Precision\n",
            "INFO 2021-01-25 20:29:45,322 trainer_main.py: 109: Using Distributed init method: tcp://localhost:56523, world_size: 1, rank: 0\n",
            "INFO 2021-01-25 20:29:45,323 trainer_main.py: 130: | initialized host ec590053bcdc as rank 0 (0)\n",
            "INFO 2021-01-25 20:29:45,324 ssl_dataset.py: 130: Rank: 0 split: TEST Data files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-01-25 20:29:45,324 ssl_dataset.py: 133: Rank: 0 split: TEST Label files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-01-25 20:29:45,325 disk_dataset.py:  81: Loaded 10 samples from folder /content/dummy_data/val\n",
            "INFO 2021-01-25 20:29:45,325 ssl_dataset.py: 130: Rank: 0 split: TRAIN Data files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-01-25 20:29:45,325 ssl_dataset.py: 133: Rank: 0 split: TRAIN Label files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-01-25 20:29:45,325 disk_dataset.py:  81: Loaded 10 samples from folder /content/dummy_data/train\n",
            "INFO 2021-01-25 20:29:45,325 misc.py:  86: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-01-25 20:29:45,325 __init__.py:  91: Created the Distributed Sampler....\n",
            "INFO 2021-01-25 20:29:45,325 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "INFO 2021-01-25 20:29:45,326 __init__.py: 155: Wrapping the dataloader to async device copies\n",
            "INFO 2021-01-25 20:29:49,020 misc.py:  86: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-01-25 20:29:49,020 __init__.py:  91: Created the Distributed Sampler....\n",
            "INFO 2021-01-25 20:29:49,020 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "INFO 2021-01-25 20:29:49,020 __init__.py: 155: Wrapping the dataloader to async device copies\n",
            "INFO 2021-01-25 20:29:49,020 train_task.py: 419: Building model....\n",
            "INFO 2021-01-25 20:29:49,021 feature_extractor.py:  23: Creating Feature extractor trunk...\n",
            "INFO 2021-01-25 20:29:49,021 resnext.py:  63: ResNeXT trunk, supports activation checkpointing. Deactivated\n",
            "INFO 2021-01-25 20:29:49,021 resnext.py:  83: Building model: ResNeXt50-1x64d-w1-BatchNorm2d\n",
            "INFO 2021-01-25 20:29:49,621 feature_extractor.py:  46: Freezing model trunk...\n",
            "INFO 2021-01-25 20:29:49,689 model_helpers.py: 138: Using SyncBN group size: None\n",
            "INFO 2021-01-25 20:29:49,689 model_helpers.py: 153: Converting BN layers to PyTorch SyncBN\n",
            "INFO 2021-01-25 20:29:49,689 model_helpers.py: 156: Not creating process_group for PyTorch SyncBN...\n",
            "INFO 2021-01-25 20:29:49,695 train_task.py: 437: config.MODEL.FEATURE_EVAL_SETTINGS.FREEZE_TRUNK_ONLY=True, will freeze trunk...\n",
            "INFO 2021-01-25 20:29:49,695 base_ssl_model.py: 181: Freezing model trunk...\n",
            "INFO 2021-01-25 20:29:49,695 train_task.py: 378: Initializing model from: /content/resnet50-19c8e357.pth\n",
            "INFO 2021-01-25 20:29:49,696 util.py: 277: Attempting to load checkpoint from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-01-25 20:29:49,865 util.py: 282: Loaded checkpoint from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-01-25 20:29:49,865 util.py: 241: Broadcasting checkpoint loaded from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-01-25 20:29:52,597 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,597 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,597 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,597 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,597 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,597 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,597 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,598 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,598 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,598 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,598 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,598 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,598 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,598 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,598 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,598 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,598 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,598 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,599 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,599 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,599 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,599 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,599 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,599 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,599 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,599 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,599 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,599 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,599 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,599 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,600 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,600 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,600 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,600 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,600 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,600 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,600 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,600 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,600 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,600 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,601 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,601 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,601 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,601 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,601 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,601 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,601 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,601 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,601 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,601 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,601 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,601 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,602 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,602 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,602 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,602 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,602 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,602 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,602 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,602 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,602 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,602 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,602 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,603 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,603 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,603 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,603 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,603 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,603 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,603 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,603 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,603 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,603 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,604 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,604 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,604 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,604 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,604 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,604 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,604 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,604 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,604 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,604 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,604 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,605 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,605 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,605 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,605 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,605 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,605 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,605 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,605 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,605 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,606 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,606 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,606 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,606 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,606 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,606 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,639 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,639 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,639 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,639 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,639 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,640 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,640 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,640 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,640 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,640 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,640 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,640 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,641 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,641 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,641 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,641 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,641 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,641 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,642 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,642 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,642 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,642 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,642 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,642 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,642 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,643 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,643 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,643 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,643 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,643 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,643 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,643 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,644 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.3.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,644 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,644 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,644 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,644 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,644 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,644 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.3.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,645 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,645 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,645 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,645 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,645 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,645 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.3.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,646 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,646 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,646 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,646 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,646 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,646 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,647 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,647 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,647 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,647 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,647 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,647 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,648 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,648 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,648 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,648 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,648 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,648 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,649 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,649 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,649 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,649 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,649 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,649 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,649 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,649 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,649 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,650 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,650 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,650 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,650 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,650 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,650 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,651 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,651 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,651 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,651 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,651 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,651 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,651 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,651 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,651 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,652 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,652 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,652 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,652 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,652 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,652 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,653 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,653 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,653 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,653 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,653 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,653 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,653 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,653 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,654 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,654 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,654 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,654 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,654 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,654 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,654 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,654 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,654 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,654 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.3.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,655 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,655 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,655 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,655 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,655 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,655 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.3.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,656 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,656 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,656 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,656 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,656 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,656 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.3.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,656 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,656 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,657 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,657 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,657 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,657 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.4.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,657 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,657 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,658 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,658 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,658 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,658 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.4.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,658 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,658 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,658 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,658 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,658 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,658 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.4.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,659 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,659 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,659 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,659 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,659 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,659 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.5.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,660 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,660 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,747 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,748 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,748 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,748 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.5.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,748 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,748 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,748 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,748 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,748 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,748 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.5.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,749 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,749 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,749 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,749 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,749 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,749 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,751 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,751 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,751 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,751 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,751 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,751 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,752 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,752 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,752 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,753 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,753 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,753 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,755 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,755 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,755 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,755 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,755 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,755 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,756 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,757 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,757 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,757 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,757 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,757 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,759 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,759 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,759 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,759 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,759 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,759 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,760 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,760 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,760 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,760 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,760 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,760 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,761 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,761 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,761 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,761 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,761 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,762 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,763 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,763 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,763 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,764 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,764 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,764 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,765 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,765 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,765 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,765 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,765 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:29:52,765 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,765 checkpoint.py: 463: Not found:\t\theads.0.channel_bn.weight, not initialized\n",
            "INFO 2021-01-25 20:29:52,765 checkpoint.py: 463: Not found:\t\theads.0.channel_bn.bias, not initialized\n",
            "INFO 2021-01-25 20:29:52,765 checkpoint.py: 463: Not found:\t\theads.0.channel_bn.running_mean, not initialized\n",
            "INFO 2021-01-25 20:29:52,765 checkpoint.py: 463: Not found:\t\theads.0.channel_bn.running_var, not initialized\n",
            "INFO 2021-01-25 20:29:52,765 checkpoint.py: 427: Ignored layer:\theads.0.channel_bn.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,765 checkpoint.py: 463: Not found:\t\theads.0.clf.clf.0.weight, not initialized\n",
            "INFO 2021-01-25 20:29:52,765 checkpoint.py: 463: Not found:\t\theads.0.clf.clf.0.bias, not initialized\n",
            "INFO 2021-01-25 20:29:52,766 checkpoint.py: 463: Not found:\t\theads.1.channel_bn.weight, not initialized\n",
            "INFO 2021-01-25 20:29:52,766 checkpoint.py: 463: Not found:\t\theads.1.channel_bn.bias, not initialized\n",
            "INFO 2021-01-25 20:29:52,766 checkpoint.py: 463: Not found:\t\theads.1.channel_bn.running_mean, not initialized\n",
            "INFO 2021-01-25 20:29:52,766 checkpoint.py: 463: Not found:\t\theads.1.channel_bn.running_var, not initialized\n",
            "INFO 2021-01-25 20:29:52,766 checkpoint.py: 427: Ignored layer:\theads.1.channel_bn.num_batches_tracked\n",
            "INFO 2021-01-25 20:29:52,766 checkpoint.py: 463: Not found:\t\theads.1.clf.clf.0.weight, not initialized\n",
            "INFO 2021-01-25 20:29:52,766 checkpoint.py: 463: Not found:\t\theads.1.clf.clf.0.bias, not initialized\n",
            "INFO 2021-01-25 20:29:52,766 checkpoint.py: 470: Extra layers not loaded from checkpoint: ['trunk.base_model._feature_blocks.fc.weight', 'trunk.base_model._feature_blocks.fc.bias']\n",
            "INFO 2021-01-25 20:29:52,773 train_task.py: 591: Broadcast model BN buffers from master on every forward pass\n",
            "INFO 2021-01-25 20:29:52,773 classification_task.py: 359: Synchronized Batch Normalization is disabled\n",
            "INFO 2021-01-25 20:29:52,773 train_task.py: 340: Building loss...\n",
            "INFO 2021-01-25 20:29:52,825 optimizer_helper.py: 157: \n",
            "Trainable params: 8, \n",
            "Non-Trainable params: 0, \n",
            "Trunk Regularized Parameters: 0, \n",
            "Trunk Unregularized Parameters 0, \n",
            "Head Regularized Parameters: 4, \n",
            "Head Unregularized Parameters: 4 \n",
            "Remaining Regularized Parameters: 0 \n",
            "INFO 2021-01-25 20:29:52,825 trainer_main.py: 241: Training 2 epochs. One epoch = 5 iterations\n",
            "INFO 2021-01-25 20:29:52,825 trainer_main.py: 243: Total 10 iterations for training\n",
            "INFO 2021-01-25 20:29:52,825 trainer_main.py: 244: Total 10 samples in one epoch\n",
            "INFO 2021-01-25 20:29:52,977 logger.py:  76: Mon Jan 25 20:29:52 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    27W /  70W |    947MiB / 15079MiB |      9%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "INFO 2021-01-25 20:29:52,978 trainer_main.py: 166: Model is:\n",
            " Classy <class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'>:\n",
            "BaseSSLMultiInputOutputModel(\n",
            "  (_heads): ModuleDict()\n",
            "  (trunk): FeatureExtractorModel(\n",
            "    (base_model): ResNeXt(\n",
            "      (_feature_blocks): ModuleDict(\n",
            "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv1_relu): ReLU(inplace=True)\n",
            "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "        (layer1): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (layer2): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (layer3): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (4): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (5): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (layer4): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), bias=False)\n",
            "              (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "        (flatten): Flatten()\n",
            "      )\n",
            "    )\n",
            "    (feature_pool_ops): ModuleList(\n",
            "      (0): AvgPool2d(kernel_size=[6, 6], stride=1, padding=0)\n",
            "      (1): Identity()\n",
            "    )\n",
            "  )\n",
            "  (heads): ModuleList(\n",
            "    (0): LinearEvalMLP(\n",
            "      (channel_bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (clf): MLP(\n",
            "        (clf): Sequential(\n",
            "          (0): Linear(in_features=8192, out_features=1000, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): LinearEvalMLP(\n",
            "      (channel_bn): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (clf): MLP(\n",
            "        (clf): Sequential(\n",
            "          (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "INFO 2021-01-25 20:29:53,063 trainer_main.py: 167: Loss is: CrossEntropyMultipleOutputSingleTargetLoss(\n",
            "  (_losses): ModuleList()\n",
            ")\n",
            "INFO 2021-01-25 20:29:53,063 trainer_main.py: 168: Starting training....\n",
            "INFO 2021-01-25 20:29:53,064 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-25 20:29:55,672 trainer_main.py: 296: Phase advanced. Rank: 0\n",
            "INFO 2021-01-25 20:29:55,672 state_update_hooks.py:  98: Starting phase 0 [train]\n",
            "INFO 2021-01-25 20:29:56,017 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 1; lr: [0.2, 0.01]; loss: 358.54126; btime(ms): 3190; eta: 0:00:28; peak_mem: 2452M\n",
            "INFO 2021-01-25 20:29:56,082 log_hooks.py: 155: Rank: 0; [ep: 0] iter: 5; lr: [0.2, 0.01]; loss: 1846.89526; btime(ms): 650; eta: 0:00:03; peak_mem: 2452M\n",
            "INFO 2021-01-25 20:29:56,082 trainer_main.py: 194: Meters synced\n",
            "INFO 2021-01-25 20:29:56,092 log_hooks.py: 416: Average train batch time (ms) for 5 batches: 83\n",
            "INFO 2021-01-25 20:29:56,092 log_hooks.py: 425: Train step time breakdown (rank 0):\n",
            "               Timer     Host    CudaEvent\n",
            "         read_sample:    1.24 ms    0.74 ms\n",
            "             forward:   73.86 ms   74.62 ms\n",
            "        loss_compute:    0.62 ms    0.63 ms\n",
            "     loss_all_reduce:    0.08 ms    0.08 ms\n",
            "       meters_update:    0.52 ms    0.54 ms\n",
            "            backward:    1.05 ms    1.69 ms\n",
            "      optimizer_step:    0.59 ms    2.54 ms\n",
            "    train_step_total:   81.80 ms   81.74 ms\n",
            "INFO 2021-01-25 20:29:56,092 log_hooks.py: 346: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 10.0, 'res5avg': 30.0}, 'top_5': {'res5': 50.0, 'res5avg': 60.0}}\n",
            "INFO 2021-01-25 20:29:56,092 io.py:  56: Saving data to file: ./checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-01-25 20:29:56,093 io.py:  70: Saved data to file: ./checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-01-25 20:29:56,093 log_hooks.py: 283: [phase: 0] Saving checkpoint to ./checkpoints_trunk_eval\n",
            "INFO 2021-01-25 20:29:56,368 log_hooks.py: 312: Saved checkpoint: ./checkpoints_trunk_eval/model_phase0.torch\n",
            "INFO 2021-01-25 20:29:56,369 log_hooks.py: 316: Creating symlink...\n",
            "INFO 2021-01-25 20:29:56,372 log_hooks.py: 320: Created symlink: ./checkpoints_trunk_eval/checkpoint.torch\n",
            "INFO 2021-01-25 20:29:56,373 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 1, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-25 20:29:58,802 trainer_main.py: 296: Phase advanced. Rank: 0\n",
            "INFO 2021-01-25 20:29:58,803 state_update_hooks.py:  98: Starting phase 1 [test]\n",
            "INFO 2021-01-25 20:29:58,973 trainer_main.py: 194: Meters synced\n",
            "INFO 2021-01-25 20:29:58,973 log_hooks.py: 416: Average test batch time (ms) for 5 batches: 34\n",
            "INFO 2021-01-25 20:29:58,973 log_hooks.py: 346: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 50.0, 'res5avg': 50.0}, 'top_5': {'res5': 100.0, 'res5avg': 100.0}}\n",
            "INFO 2021-01-25 20:29:58,973 io.py:  56: Saving data to file: ./checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-01-25 20:29:58,974 io.py:  70: Saved data to file: ./checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-01-25 20:29:58,974 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 2, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-25 20:30:01,353 trainer_main.py: 296: Phase advanced. Rank: 0\n",
            "INFO 2021-01-25 20:30:01,353 state_update_hooks.py:  98: Starting phase 2 [train]\n",
            "INFO 2021-01-25 20:30:01,494 log_hooks.py: 155: Rank: 0; [ep: 1] iter: 10; lr: [0.02, 0.001]; loss: 0.0; btime(ms): 577; eta: 0:00:00; peak_mem: 2452M\n",
            "INFO 2021-01-25 20:30:01,494 trainer_main.py: 194: Meters synced\n",
            "INFO 2021-01-25 20:30:01,495 log_hooks.py: 416: Average train batch time (ms) for 5 batches: 28\n",
            "INFO 2021-01-25 20:30:01,495 log_hooks.py: 425: Train step time breakdown (rank 0):\n",
            "               Timer     Host    CudaEvent\n",
            "         read_sample:    6.69 ms    5.34 ms\n",
            "             forward:    9.45 ms   15.33 ms\n",
            "        loss_compute:    0.53 ms    0.52 ms\n",
            "     loss_all_reduce:    0.07 ms    0.08 ms\n",
            "       meters_update:    1.94 ms    1.96 ms\n",
            "            backward:    0.88 ms    1.79 ms\n",
            "      optimizer_step:    0.58 ms    2.43 ms\n",
            "    train_step_total:   28.03 ms   28.13 ms\n",
            "INFO 2021-01-25 20:30:01,495 log_hooks.py: 346: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {'res5': 60.0, 'res5avg': 70.0}, 'top_5': {'res5': 90.0, 'res5avg': 100.0}}\n",
            "INFO 2021-01-25 20:30:01,495 io.py:  56: Saving data to file: ./checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-01-25 20:30:01,495 io.py:  70: Saved data to file: ./checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-01-25 20:30:01,495 log_hooks.py: 283: [phase: 2] Saving checkpoint to ./checkpoints_trunk_eval\n",
            "INFO 2021-01-25 20:30:01,779 log_hooks.py: 312: Saved checkpoint: ./checkpoints_trunk_eval/model_final_checkpoint_phase2.torch\n",
            "INFO 2021-01-25 20:30:01,779 log_hooks.py: 316: Creating symlink...\n",
            "Error in symlink - [Errno 17] File exists: './checkpoints_trunk_eval/model_final_checkpoint_phase2.torch' -> './checkpoints_trunk_eval/checkpoint.torch'\n",
            "INFO 2021-01-25 20:30:01,780 log_hooks.py: 320: Created symlink: ./checkpoints_trunk_eval/checkpoint.torch\n",
            "INFO 2021-01-25 20:30:01,780 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 3, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-25 20:30:04,283 trainer_main.py: 296: Phase advanced. Rank: 0\n",
            "INFO 2021-01-25 20:30:04,283 state_update_hooks.py:  98: Starting phase 3 [test]\n",
            "INFO 2021-01-25 20:30:04,405 trainer_main.py: 194: Meters synced\n",
            "INFO 2021-01-25 20:30:04,406 log_hooks.py: 416: Average test batch time (ms) for 5 batches: 24\n",
            "INFO 2021-01-25 20:30:04,406 log_hooks.py: 346: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {'res5': 50.0, 'res5avg': 50.0}, 'top_5': {'res5': 50.0, 'res5avg': 100.0}}\n",
            "INFO 2021-01-25 20:30:04,406 io.py:  56: Saving data to file: ./checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-01-25 20:30:04,406 io.py:  70: Saved data to file: ./checkpoints_trunk_eval/metrics.json\n",
            "INFO 2021-01-25 20:30:04,482 train.py: 103: All Done!\n",
            "INFO 2021-01-25 20:30:04,482 logger.py:  66: Shutting down loggers...\n",
            "INFO 2021-01-25 20:30:04,483 run_distributed_engines.py: 133: All Done!\n",
            "INFO 2021-01-25 20:30:04,483 logger.py:  66: Shutting down loggers...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvUJcklKyI5F"
      },
      "source": [
        "And we are done!! We have the linear classifier trained on the trunk features `res5` and `res5avg` and the `metrics.json` containing `top-1` and `top-5` accuracy on validation set is available in `checkpoints_trunk_eval/metrics.json`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpQ1__UqyQgj",
        "outputId": "1809b071-5962-4249-d845-c6766ac3b270"
      },
      "source": [
        "ls checkpoints_trunk_eval/"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;36mcheckpoint.torch\u001b[0m@  metrics.json                         model_phase0.torch\n",
            "log.txt            model_final_checkpoint_phase2.torch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsvStuaWySlY",
        "outputId": "09ef1a00-7c48-440e-a03f-50a4ed83791b"
      },
      "source": [
        "cat checkpoints_trunk_eval/metrics.json"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"iteration\": 5, \"phase_idx\": 0, \"train_accuracy_list_meter\": {\"top_1\": {\"res5\": 10.0, \"res5avg\": 30.0}, \"top_5\": {\"res5\": 50.0, \"res5avg\": 60.0}}, \"train_phase_idx\": 0}\n",
            "{\"iteration\": 5, \"phase_idx\": 1, \"test_accuracy_list_meter\": {\"top_1\": {\"res5\": 50.0, \"res5avg\": 50.0}, \"top_5\": {\"res5\": 100.0, \"res5avg\": 100.0}}, \"train_phase_idx\": 0}\n",
            "{\"iteration\": 10, \"phase_idx\": 2, \"train_accuracy_list_meter\": {\"top_1\": {\"res5\": 60.0, \"res5avg\": 70.0}, \"top_5\": {\"res5\": 90.0, \"res5avg\": 100.0}}, \"train_phase_idx\": 1}\n",
            "{\"iteration\": 10, \"phase_idx\": 3, \"test_accuracy_list_meter\": {\"top_1\": {\"res5\": 50.0, \"res5avg\": 50.0}, \"top_5\": {\"res5\": 50.0, \"res5avg\": 100.0}}, \"train_phase_idx\": 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xFUcTj00B_a"
      },
      "source": [
        "# Loading Pre-trained models in VISSL\n",
        "\n",
        "VISSL supports Torchvision models out of the box. Generally, for loading any non-VISSL model, one needs to correctly set the following configuration options:\n",
        "\n",
        "```yaml\n",
        "WEIGHTS_INIT:\n",
        "  # path to the .torch weights files\n",
        "  PARAMS_FILE: \"\"\n",
        "  # name of the state dict. checkpoint = {\"classy_state_dict\": {layername:value}}. Options:\n",
        "  #   1. classy_state_dict - if model is trained and checkpointed with VISSL.\n",
        "  #      checkpoint = {\"classy_state_dict\": {layername:value}}\n",
        "  #   2. \"\" - if the model_file is not a nested dictionary for model weights i.e.\n",
        "  #      checkpoint = {layername:value}\n",
        "  #   3. key name that your model checkpoint uses for state_dict key name.\n",
        "  #      checkpoint = {\"your_key_name\": {layername:value}}\n",
        "  STATE_DICT_KEY_NAME: \"classy_state_dict\"\n",
        "  # specify what layer should not be loaded. Layer names with this key are not copied\n",
        "  # By default, set to BatchNorm stats \"num_batches_tracked\" to be skipped.\n",
        "  SKIP_LAYERS: [\"num_batches_tracked\"]\n",
        "  ####### If loading a non-VISSL trained model, set the following two args carefully #########\n",
        "  # to make the checkpoint compatible with VISSL, if you need to remove some names\n",
        "  # from the checkpoint keys, specify the name\n",
        "  REMOVE_PREFIX: \"\"\n",
        "  # In order to load the model (if not trained with VISSL) with VISSL, there are 2 scenarios:\n",
        "  #    1. If you are interested in evaluating the model features and freeze the trunk.\n",
        "  #       Set APPEND_PREFIX=\"trunk.base_model.\" This assumes that your model is compatible\n",
        "  #       with the VISSL trunks. The VISSL trunks start with \"_feature_blocks.\" prefix. If\n",
        "  #       your model doesn't have these prefix you can append them. For example:\n",
        "  #       For TorchVision ResNet trunk, set APPEND_PREFIX=\"trunk.base_model._feature_blocks.\"\n",
        "  #    2. where you want to load the model simply and finetune the full model.\n",
        "  #       Set APPEND_PREFIX=\"trunk.\"\n",
        "  #       This assumes that your model is compatible with the VISSL trunks. The VISSL\n",
        "  #       trunks start with \"_feature_blocks.\" prefix. If your model doesn't have these\n",
        "  #       prefix you can append them.\n",
        "  #       For TorchVision ResNet trunk, set APPEND_PREFIX=\"trunk._feature_blocks.\"\n",
        "  # NOTE: the prefix is appended to all the layers in the model\n",
        "  APPEND_PREFIX: \"\"\n",
        "  ```"
      ]
    }
  ]
}
