# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved

######################### versioning ###################################
# this version is checked with the VISSL latest config version in
# vissl/config/__init__.py
# Users are recommended to keep a config version in their config file so vissl can
# take care of upgrades to config files as the version evolves.
VERSION: 1
################## some command line options to decide workflow ###############
node_id: 0
engine_name: train
config:
  # ----------------------------------------------------------------------------------- #
  # GLOBAL DEFAULTS
  # ----------------------------------------------------------------------------------- #
  VERBOSE: False
  LOG_FREQUENCY: 10
  TEST_ONLY: False
  TEST_EVERY_NUM_EPOCH: 1
  SEED_VALUE: 0
  TEST_MODEL: True
  # Use the forkserver or spawn
  # https://github.com/pytorch/pytorch/blob/master/torch/nn/parallel/distributed.py#L142
  MULTI_PROCESSING_METHOD: "forkserver"
  MONITOR_PERF_STATS: False
  # we print perf stats (if enabled) after every phase. If we want to print every few
  # batches, set the frequency here.
  PERF_STAT_FREQUENCY: -1
  # if we want to print the rolling avg. batch time, set the value below to number of
  # batches over which we want to print average
  ROLLING_BTIME_FREQ: -1

  # ----------------------------------------------------------------------------------- #
  # DATA
  # ----------------------------------------------------------------------------------- #
  DATA:
    # Common data options
    NUM_DATALOADER_WORKERS: 4 # Set this depending on the number of CPUs you have
    PIN_MEMORY: True # Makes CPU->GPU copy of the data faster
    ENABLE_ASYNC_GPU_COPY: True
    # Training Data Options
    TRAIN:
      # if we want to resume the data sampler as well from a previous iteration
      USE_STATEFUL_DISTRIBUTED_SAMPLER: False
      # whether to drop the last incomplete batch per process
      DROP_LAST: False
      # Sources for reading data.
      # Currently supports: disk_folder and disk_filelist
      # Parallel aligned with DATA_PATHS argument.
      DATA_SOURCES: []
      DATA_PATHS: []
      LABEL_SOURCES: []
      LABEL_PATHS: []
      MMAP_MODE: True
      DEFAULT_GRAY_IMG_SIZE: 224
      BATCHSIZE_PER_REPLICA: 256
      TRANSFORMS: []
      COLLATE_FUNCTION: "default_collate"
      DATA_LIMIT: -1
      DATASET_NAMES: ["imagenet1k_folder"]
      COPY_TO_LOCAL_DISK: False
      COPY_DESTINATION_DIR: ""
      # either standard | sample_index
      LABEL_TYPE: "standard"
      # keys that specify what `keys' in a sample dictionary
      # correspond to input and target
      INPUT_KEY_NAMES: ["data"]
      TARGET_KEY_NAMES: ["label"]
      # set this to True if you want to handle the invalid images using QueueDataset.
      # In case of an invalid image, by default a mean image is returned. But using
      # QueueDataset, you can instead return a valid and previously seen image.
      ENABLE_QUEUE_DATASET: False
    TEST:
      # if we want to resume the data sampler as well from a previous iteration
      USE_STATEFUL_DISTRIBUTED_SAMPLER: False
      DROP_LAST: False
      DATA_SOURCES: []
      DATA_PATHS: []
      LABEL_SOURCES: []
      LABEL_PATHS: []
      MMAP_MODE: True
      DEFAULT_GRAY_IMG_SIZE: 224
      BATCHSIZE_PER_REPLICA: 256
      TRANSFORMS: []
      COLLATE_FUNCTION: "default_collate"
      DATA_LIMIT: -1
      DATASET_NAMES: ["imagenet1k_folder"]
      COPY_TO_LOCAL_DISK: False
      COPY_DESTINATION_DIR: ""
      # either standard | sample_index
      LABEL_TYPE: "standard"
      # keys that specify what `keys' in a sample dictionary
      # correspond to input and target
      INPUT_KEY_NAMES: ["data"]
      TARGET_KEY_NAMES: ["label"]
      # set this to True if you want to handle the invalid images using QueueDataset.
      # In case of an invalid image, by default a mean image is returned. But using
      # QueueDataset, you can instead return a valid and previously seen image.
      ENABLE_QUEUE_DATASET: False

  # ----------------------------------------------------------------------------------- #
  # METERS
  # ----------------------------------------------------------------------------------- #
  # what meters to attach. All the mentioned meters will be calculated.
  METERS:
    accuracy_list_meter:
      # number of accuracy meters. In cases like linear evaluation of feature, we perform
      # evaluation of several layers and there's a separate meter for each layer.
      # num_meters basically specifices number of meters.
      num_meters: 1
      # what topk values to calculate. Example topk_values = [1, 5] means top1 and top5
      # both will be calculated
      topk_values: [1]
      # names of the meter. Useful in cases where we have several meters. For the linear
      # feature evaluation workflows, meter name is automatically inferred.
      meter_names: []

  # ----------------------------------------------------------------------------------- #
  # MACHINE (cpu, gpu)
  # ----------------------------------------------------------------------------------- #
  MACHINE:
    DEVICE: "gpu"

  # ----------------------------------------------------------------------------------- #
  # MODEL
  # ----------------------------------------------------------------------------------- #
  MODEL:
    # the model parameter names that should not be trained
    NON_TRAINABLE_PARAMS: []
    TEMP_FROZEN_PARAMS_ITER_MAP: []
    # Colorization models take lab input. Everything else takes rgb.
    INPUT_TYPE: "rgb"
    # Multi-input model: input keys in the sample dictionary and which head
    # uses them for example, input contains "images" and "patches" and there
    # is one separate head applied to images and another to patches
    MULTI_INPUT_HEAD_MAPPING: []
    # Use activation checkpointing in the training phase
    ACTIVATION_CHECKPOINTING:
      USE_ACTIVATION_CHECKPOINTING: false
      NUM_ACTIVATION_CHECKPOINTING_SPLITS: 2
    # ----------------------------------------------------------------------------------- #
    # Feature evaluation settings
    # ----------------------------------------------------------------------------------- #
    FEATURE_EVAL_SETTINGS:
      # for evaluating the features on any evaluation task/benchmark, set this to True
      EVAL_MODE_ON: False
      # if you want to evaluate several feature layers of the pre-trained model on
      # benchmark tasks like linear classification, set this to True. This freezes the model
      # trunk for feature evaluation.
      FREEZE_TRUNK_ONLY: False
      # if you want to evaluate the full self-supervised model including the trunk and heads,
      # and want to freeze trunk and head both, set this to True
      FREEZE_TRUNK_AND_HEAD: False
      # if you want to extract features of trunk only, set this to True
      EXTRACT_TRUNK_FEATURES_ONLY: False
      # if we want to evaluate the full model, this requires loading the head weights as well
      # from model weights file. In this case, set the following to True.
      EVAL_TRUNK_AND_HEAD: False
      # whether features should be flattened to result in N x D feature shape
      SHOULD_FLATTEN_FEATS: True
      # model features that should be evaluated for linear classification and what
      # pooling to apply on features. Could be any pooling operation or Identity.
      #
      # Example: for evaluating 5 layers of ResNet-50,
      #       LINEAR_EVAL_FEAT_POOL_OPS_MAP: [
      #           ["conv1", ["AvgPool2d", [[10, 10], 10, 4]]],
      #           ["res2", ["AvgPool2d", [[16, 16], 8, 0]]],
      #           ["res3", ["AvgPool2d", [[13, 13], 5, 0]]],
      #           ["res4", ["AvgPool2d", [[8, 8], 3, 0]]],
      #           ["res5", ["AvgPool2d", [[6, 6], 1, 0]]],
      #       ]
      LINEAR_EVAL_FEAT_POOL_OPS_MAP: []
    # ----------------------------------------------------------------------------------- #
    # MODEL TRUNK
    # ----------------------------------------------------------------------------------- #
    TRUNK:
      NAME: "resnet"
      # for any extra params that the model requires, pass them in the trunk_params
      TRUNK_PARAMS:
        # ------------------------------------------------------------- #
        # ResNe(X)t params
        # ------------------------------------------------------------- #
        RESNETS:
          DEPTH: 50
          WIDTH_MULTIPLIER: 1
          NORM: BatchNorm    # BatchNorm | LayerNorm
          GROUPS: 1
          ZERO_INIT_RESIDUAL: False
          WIDTH_PER_GROUP: 64
          # Colorization model uses stride=1 for last layer to retain higher spatial resolution
          # for the pixel-wise task. Torchvision default is stride=2 and all other models
          # use this so we set the default as 2.
          LAYER4_STRIDE: 2

        # ------------------------------------------------------------- #
        # EfficientNet params
        # ------------------------------------------------------------- #
        # follow classy vision for efficientNet settings
        EFFICIENT_NETS: {}

        # ------------------------------------------------------------- #
        # RegNet params
        # ------------------------------------------------------------- #
        REGNETS: {}
    # ----------------------------------------------------------------------------------- #
    # MODEL HEAD
    # ----------------------------------------------------------------------------------- #
    HEAD:
      # PARAMS is a List of Pairs:
      #   Pair[0] = Name of Head.
      #   Pair[1] = kwargs passed to head constructor.
      # Example of heads:
      # Case1: Simple Head containing single module - Single Input, Single output
      #          PARAMS: [
      #            ["mlp", {"dims": [2048, 128]}]
      #          ]
      # Case2: Complex Head containing chain of head modules - Single Input, Single output
      #          PARAMS: [
      #              ["mlp", {"dims": [2048, 1000], "use_bn": False, "use_relu": False}],
      #              ["siamese_concat_view", {"num_towers": 9}],
      #              ["mlp", {"dims": [9000, 128]}]
      #          ]
      # Case3: Multiple Heads (example 2 heads) - Single input, multiple output
      #        Can be used for multi-task learning
      #          PARAMS: [
      #            # head 0
      #            [
      #              ["mlp", {"dims": [2048, 128], "use_bn": False, "use_relu": False}],
      #              ["siamese_concat_view", {"num_towers": 9}],
      #              ["mlp", {"dims": [1152, 128]}],
      #            ],
      #            # head 1
      #            [
      #              ["mlp", {"dims": [2048, 128]}]
      #            ],
      #          ]
      # Case4: Multiple Heads (example 5 simple heads) - Single input, multiple output.
      #        PARAMS: [
      #          ["eval_mlp", {"in_channels": 64, "dims": [9216, 1000]}],
      #          ["eval_mlp", {"in_channels": 256, "dims": [9216, 1000]}],
      #          ["eval_mlp", {"in_channels": 512, "dims": [8192, 1000]}],
      #          ["eval_mlp", {"in_channels": 1024, "dims": [9216, 1000]}],
      #          ["eval_mlp", {"in_channels": 2048, "dims": [8192, 1000]}],
      #        ]
      PARAMS: []
      BATCHNORM_EPS: 1e-5
      BATCHNORM_MOMENTUM: 0.1
    # ----------------------------------------------------------------------------------- #
    # Synchronized BatchNorm Setup
    # ----------------------------------------------------------------------------------- #
    # if we want to convert all the batch norm layers in the model to use SyncBN.
    # There are two options: APEX syncBN and PyTorch SyncBN.
    SYNC_BN_CONFIG:
      CONVERT_BN_TO_SYNC_BN: False
      SYNC_BN_TYPE: "pytorch"  # apex | pytorch
      # if group_size=-1, will set group_size=num_gpus
      # if group_size>0, will set group_size=value set by user
      # if group_size=0, will set process_group=None
      GROUP_SIZE: -1
    # ----------------------------------------------------------------------------------- #
    # MIXED PRECISION SETUP
    # ----------------------------------------------------------------------------------- #
    AMP_PARAMS:
      USE_AMP: False
      # Use O1 as it is robust and stable than O3. If you want to use O3, we recommend
      # the following setting:
      # {"opt_level": "O3", "keep_batchnorm_fp32": True, "master_weights": True, "loss_scale": "dynamic"}
      AMP_ARGS: {"opt_level": "O1"}
    MODEL_COMPLEXITY:
      # set this to True if you want to compute flops, params, activations in your model.
      COMPUTE_COMPLEXITY: False
      INPUT_SHAPE: [3, 224, 224]
    # parameters for initializing a model from a pre-trained model file
    WEIGHTS_INIT:
      # path to the .torch weights files
      PARAMS_FILE: ""
      # name of the state dict. checkpoint = {"classy_state_dict": {layername:value}}. Options:
      #   1. classy_state_dict - if model is trained and checkpointed with VISSL.
      #      checkpoint = {"classy_state_dict": {layername:value}}
      #   2. "" - if the model_file is not a nested dictionary for model weights i.e.
      #      checkpoint = {layername:value}
      #   3. key name that your model checkpoint uses for state_dict key name.
      #      checkpoint = {"your_key_name": {layername:value}}
      STATE_DICT_KEY_NAME: "classy_state_dict"
      # specify what layer should not be loaded. Layer names with this key are not copied
      # By default, set to BatchNorm stats "num_batches_tracked" to be skipped.
      SKIP_LAYERS: ["num_batches_tracked"]
      ####### If loading a non-VISSL trained model, set the following two args carefully #########
      # to make the checkpoint compatible with VISSL, if you need to remove some names
      # from the checkpoint keys, specify the name
      REMOVE_PREFIX: ""
      # In order to load the model (if not trained with VISSL) with VISSL, there are 2 scenarios:
      #    1. If you are interested in evaluating the model features and freeze the trunk.
      #       Set APPEND_PREFIX="trunk.base_model." This assumes that your model is compatible
      #       with the VISSL trunks. The VISSL trunks start with "_feature_blocks." prefix. If
      #       your model doesn't have these prefix you can append them. For example:
      #       For TorchVision ResNet trunk, set APPEND_PREFIX="trunk.base_model._feature_blocks."
      #    2. where you want to load the model simply and finetune the full model.
      #       Set APPEND_PREFIX="trunk."
      #       This assumes that your model is compatible with the VISSL trunks. The VISSL
      #       trunks start with "_feature_blocks." prefix. If your model doesn't have these
      #       prefix you can append them.
      #       For TorchVision ResNet trunk, set APPEND_PREFIX="trunk._feature_blocks."
      # NOTE: the prefix is appended to all the layers in the model
      APPEND_PREFIX: ""

  # ----------------------------------------------------------------------------------- #
  # LOSS
  # ----------------------------------------------------------------------------------- #
  LOSS:
    name: "CrossEntropyLoss"

    # ----------------------------------------------------------------------------------- #
    # Standard PyTorch Cross-Entropy Loss. Use the loss name exactly as in PyTorch.
    # pass any variables that the loss takes.
    # ----------------------------------------------------------------------------------- #
    CrossEntropyLoss:
      ignore_index: -1

    # ----------------------------------------------------------------------------------- #
    # Cross-Entropy Loss for multiple input and same target
    # ----------------------------------------------------------------------------------- #
    cross_entropy_multiple_output_single_target:
      weight: null
      reduction: "mean"
      ignore_index: -1
      # generic flag to enable L2 normalization in a loss function. Currently supported
      # for cross_entropy_multiple_output_single_target loss only.
      normalize_output: False

    # ----------------------------------------------------------------------------------- #
    # NCE LOSS (Noise Contrastive Estimator)
    # ----------------------------------------------------------------------------------- #
    nce_loss_with_memory:
      # setting below to "cross_entropy" yields the InfoNCE loss
      loss_type: "nce"
      norm_embedding: True
      temperature: 0.07
      # if the NCE loss is computed between multiple pairs, we can set a loss weight per term
      # can be used to weight different pair contributions differently.
      loss_weights: [1.0]
      norm_constant: -1
      update_mem_with_emb_index: -100
      negative_sampling_params:
        num_negatives: 16000
        type: "random"
      memory_params:
        memory_size: -1
        embedding_dim: 128
        momentum: 0.5
        norm_init: True
        update_mem_on_forward: True
      # following parameters are auto-filled before the loss is created.
      num_train_samples: -1    # @auto-filled

    # ----------------------------------------------------------------------------------- #
    # SimCLR InfoNCE LOSS (Specific to SimCLR https://arxiv.org/abs/2002.05709)
    # ----------------------------------------------------------------------------------- #
    simclr_info_nce_loss:
      temperature: 0.1
      buffer_params:
        world_size: 64
        embedding_dim: 128
        effective_batch_size: 4096

    # ----------------------------------------------------------------------------------- #
    # Multi-crop version of SimCLR InfoNCE LOSS (supports multicrop augmentation proposed
    # in https://arxiv.org/abs/2006.09882)
    # ----------------------------------------------------------------------------------- #
    multicrop_simclr_info_nce_loss:
      temperature: 0.1
      num_crops: 2
      buffer_params:
        world_size: 64
        embedding_dim: 128
        effective_batch_size: 4096

    # ----------------------------------------------------------------------------------- #
    # SwAV LOSS (Specific to SwAV https://arxiv.org/abs/2006.09882)
    # ----------------------------------------------------------------------------------- #
    swav_loss:
      embedding_dim: 128
      temperature: 0.1
      use_double_precision: False
      normalize_last_layer: True
      num_iters: 3
      epsilon: 0.05
      num_crops: 2
      crops_for_assign: [0, 1]
      num_prototypes: [3000]
      queue:
        queue_length: 0
        start_iter: 0
        local_queue_length: 0

    # -----------------------------------------------------------------------------------#
    # DeepCluster V2 LOSS (baselines in SwAV https://arxiv.org/abs/2006.09882)
    # -----------------------------------------------------------------------------------#
    deepclusterv2_loss:
      DROP_LAST: True
      BATCHSIZE_PER_REPLICA: 256
      num_crops: 2
      temperature: 0.1
      num_clusters: [3000, 3000, 3000]
      kmeans_iters: 10
      memory_params:
        crops_for_mb: [0]
        embedding_dim: 128
      # following parameters are auto-filled before the loss is created.
      num_train_samples: -1    # @auto-filled

    # ----------------------------------------------------------------------------------- #
    #  MoCo Loss (http://arxiv.org/abs/1911.05722)
    # ----------------------------------------------------------------------------------- #
    moco_loss:
      embedding_dim: 128
      queue_size: 65536
      momentum: 0.999
      temperature: 0.2

  # ----------------------------------------------------------------------------------- #
  # OPTIMIZER
  # ----------------------------------------------------------------------------------- #
  OPTIMIZER:
    name: "sgd"
    use_larc: False  # supported for SGD only for now
    larc_config:
      clip: False
      eps: 1e-08
      trust_coefficient: 0.001
    weight_decay: 0.0001
    momentum: 0.9
    nesterov: False
    num_epochs: 90
    regularize_bn: False
    regularize_bias: True
    param_schedulers:
      lr:
        auto_lr_scaling:
          auto_scale: False
          base_value: 0.1
          base_lr_batch_size: 256
        name: "multistep"
        update_interval: "epoch"
        values: [0.1, 0.01, 0.001]
        milestones: [30, 60]
        # The below parameters are valid for lr.name = "composite". Various schedulers
        # can then be composed together for the training. For example: linear warmup +
        # multistep schedule after warmup.
        schedulers: []
        interval_scaling: []
        lengths: []
        # =====cosine learning rate specific =======
        start_value: 0.1
        end_value: 0.0
        # =====constant learning rate specific =======
        value: 0.1
  # ----------------------------------------------------------------------------------- #
  # CLUSTERFIT APPROACH (https://arxiv.org/abs/1912.03330)
  # ----------------------------------------------------------------------------------- #
  CLUSTERFIT:
    NUM_CLUSTERS: 16000
    # currently we only support faiss backend for clustering.
    CLUSTER_BACKEND: "faiss"
    # how many iterations to use for faiss
    N_ITER: 50
    FEATURES:
      DATA_PARTITION: "TRAIN"
      DATASET_NAME: ""
      LAYER_NAME: ""

  # ----------------------------------------------------------------------------------- #
  # TRAINER (define your train step)
  # ----------------------------------------------------------------------------------- #
  TRAINER:
    TRAIN_STEP_NAME: "standard_train_step"

  # ----------------------------------------------------------------------------------- #
  # CHECKPOINT
  # ----------------------------------------------------------------------------------- #
  CHECKPOINT:
    DIR: "."
    # for the checkpoinint, we can append the RUN_ID if we want
    APPEND_DISTR_RUN_ID: False
    BACKEND: "disk"
    # In case of distributed multi-node training, simply use the same RUN_ID and DIR
    AUTO_RESUME: True
    CHECKPOINT_FREQUENCY: 1
    # if we want to checkpoint model at various iterations as well and not just phase
    CHECKPOINT_ITER_FREQUENCY: -1
    # if we want to restart a training even if it has already succeeded on this machine
    OVERWRITE_EXISTING: False
    # we can specify what "latest" checkpoint to use to resume training. This is only valid
    # in case a training that needs to be resumed. If the training that has already finished
    # this parameter is useless.  Sometimes the latest checkpoints could be corrupt so this
    # option helps to resume from instead a few checkpoints before the last checkpoint.
    # Possibilities:
    #   1) LATEST_CHECKPOINT_RESUME_FILE_NUM = 1 -> resume from the latest checkpoint
    #   2) LATEST_CHECKPOINT_RESUME_FILE_NUM = 2 -> resume from the second latest checkpoint
    #   2) LATEST_CHECKPOINT_RESUME_FILE_NUM = N -> resume from the Nth latest checkpoint
    LATEST_CHECKPOINT_RESUME_FILE_NUM: 1

  # ----------------------------------------------------------------------------------- #
  # DISTRIBUTED TRAINING (1-gpu, multi-gpu, multi-node)
  # ----------------------------------------------------------------------------------- #
  DISTRIBUTED:
    # backend for communication across gpus. Use nccl by default. For cpu training, set
    # gloo as the backend.
    BACKEND: "nccl"
    NCCL_DEBUG: False
    # whether model buffers are BN buffers are broadcast in every forward pass
    BROADCAST_BUFFERS: True
    # number of machines to use in training
    NUM_NODES: 1
    # set this to the number of gpus per machine. This ensrures that each gpu of the
    # node has a process attached to it.
    NUM_PROC_PER_NODE: 8
    # this could be: tcp | env | file or any other pytorch supported methods
    INIT_METHOD: "tcp"
    # every training run should have a unique id. Following are the options:
    #   1. If using INIT_METHOD=env, RUN_ID="" is fine.
    #   2. If using INIT_METHOD=tcp,
    #      - if you use > 1 machine, set port yourself. RUN_ID="localhost:{port}".
    #      - If using 1 machine, set RUN_ID=auto and a free port will be automatically selected
    #   3. IF using INIT_METHOD=file, RUN_ID={file_path}
    RUN_ID: "auto"
    # if True, does the gradient reduction in DDP
    MANUAL_GRADIENT_REDUCTION: False

  # ----------------------------------------------------------------------------------- #
  # SVM (benchmark)
  # ----------------------------------------------------------------------------------- #
  SVM:
    normalize: True
    cls_list: []
    loss: "squared_hinge"
    penalty: "l2"
    dual: True
    max_iter: 2000
    cross_val_folds: 3
    costs:
      costs_list: [0.1, 0.01]
      base: -1.0
      power_range: [4, 20]
    force_retrain: False
    low_shot:
      dataset_name: "voc"
      sample_inds: [1, 2, 3, 4, 5]
      k_values: [1, 2, 4, 8, 16, 32, 64, 96]

  # ----------------------------------------------------------------------------------- #
  # INSTANCE RETRIEVAL (benchmark)
  # ----------------------------------------------------------------------------------- #
  IMG_RETRIEVAL:
    # Resize larger side of image to RESIZE_IMG pixels (e.g. 800)
    RESIZE_IMG: 1024
    # Use spatial levels (e.g. 3)
    SPATIAL_LEVELS: 3
    # output dimension of PCA
    N_PCA: 512
    # Data path and names of train/eval data: Oxford | Paris | whitening
    DATASET_PATH: ""
    TRAIN_DATASET_NAME: "Oxford"
    EVAL_DATASET_NAME: "Paris"
    # Path to the compute_ap binary to evaluate Oxford / Paris
    EVAL_BINARY_PATH: ""
    # Path to a temporary directory to store features and scores
    TEMP_DIR: "/tmp/instance_retrieval/"
    # Whether to apply PCA/whitening or not
    SHOULD_TRAIN_PCA_OR_WHITENING: True
    # gem | rmac | l2_norm
    FEATS_PROCESSING_TYPE: ""
    # valid only for GeM pooling of features
    GEM_POOL_POWER: 4.0
    # valid only if we are training whitening on the whitening dataset
    WHITEN_IMG_LIST: ""

  # ----------------------------------------------------------------------------------- #
  # K-NEAREST NEIGHBOR (benchmark)
  # ----------------------------------------------------------------------------------- #
  NEAREST_NEIGHBOR:
    # temperature value to use
    SIGMA: 0.1
    TOPK: 200
    # if the features should be l2 normalized, set this to True
    L2_NORM_FEATS: False

  # ----------------------------------------------------------------------------------- #
  # TENSORBOARD (visualization)
  # ----------------------------------------------------------------------------------- #
  TENSORBOARD_SETUP:
    USE_TENSORBOARD: False
    LOG_DIR: "."
    EXPERIMENT_LOG_DIR: ""
    LOG_ACTIVATIONS: True
    # flush logs every n minutes
    FLUSH_EVERY_N_MIN: 5

# VISSL uses hydra for configuration management. The usage looks like:
#    python tools/<binary-name>.py config=<config path>
# Example:
#    python tools/run_distributed_engines.py config=pretrain/simclr/simclr_8node_resnet
#
#
# If you create sub-folders in config folder to override parameters, you can use the
# config files in the subfolder by adding at a "+" sign to the command line input.
# For example:
#    python tools/run_distributed_engines.py \
#        config=pretrain/simclr/simclr_8node_resnet \
#        +config/pretrain/simclr/optimization=bs32_16nodes \
#        +config/pretrain/simclr/my_new_subfolder=my_file_in_subfolder \
#
#
# If you want to override single values in the config, you can achieve that with:
#    python tools/run_distributed_engines.py \
#        config=pretrain/simclr/simclr_8node_resnet \
#        +config/pretrain/simclr/my_sub_folder=my_file_name \
#        config.MODEL.WEIGHTS_INIT.PARAMS_FILE=<weights_path.torch>
#
defaults:
  # you must specify the base config you want to run
  - config: ???
