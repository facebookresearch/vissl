{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ndZ6XwI7MYA"
      },
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates. All rights reserved."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XzxTZfKwFNo"
      },
      "source": [
        "# Feature Extraction\n",
        "\n",
        "In this tutorial, we look at a simple example of how to use VISSL to extract features for [ResNet-50 Torchvision pre-trained model](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L16).\n",
        "\n",
        "You can make a copy of this tutorial by `File -> Open in playground mode` and make changes there. DO NOT request access to this tutorial.\n",
        "\n",
        "**NOTE:** Please ensure your Collab Notebook has GPU available. To ensure/select this, simple follow: `Edit -> Notebook Settings -> select GPU`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VohdWhBSw69e"
      },
      "source": [
        "## Install VISSL\n",
        "\n",
        "Installing VISSL is pretty straightfoward. We will use pip binaries of VISSL and follow instructions from [here](https://github.com/facebookresearch/vissl/blob/master/INSTALL.md#install-vissl-pip-package)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5ISg59KTOqU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52e6fb2e-6bd2-4564-b01d-f946e8449f37"
      },
      "source": [
        "# Install: PyTorch (we assume 1.5.1 but VISSL works with all PyTorch versions >=1.4)\n",
        "!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install opencv\n",
        "!pip install opencv-python\n",
        "\n",
        "# install apex by checking system settings: cuda version, pytorch version, python version\n",
        "import sys\n",
        "import torch\n",
        "version_str=\"\".join([\n",
        "    f\"py3{sys.version_info.minor}_cu\",\n",
        "    torch.version.cuda.replace(\".\",\"\"),\n",
        "    f\"_pyt{torch.__version__[0:5:2]}\"\n",
        "])\n",
        "print(version_str)\n",
        "\n",
        "# install apex (pre-compiled with optimizer C++ extensions and CUDA kernels)\n",
        "!pip install apex -f https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/{version_str}/download.html\n",
        "\n",
        "# install VISSL\n",
        "!pip install vissl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (704.4MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 34.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.19.5)\n",
            "py36_cu101_pyt151\n",
            "Looking in links: https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/py36_cu101_pyt151/download.html\n",
            "Collecting apex\n",
            "\u001b[?25l  Downloading https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/py36_cu101_pyt151/apex-0.1-cp36-cp36m-linux_x86_64.whl (11.4MB)\n",
            "\u001b[K     |████████████████████████████████| 11.4MB 4.7MB/s \n",
            "\u001b[?25hInstalling collected packages: apex\n",
            "Successfully installed apex-0.1\n",
            "Collecting vissl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/6f/e908efc4ab7e1d2178feb6a86c1d6955526e4f9da4d1d235779125940c04/vissl-0.1.5-py3-none-any.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from vissl) (0.8.7)\n",
            "Collecting parameterized==0.7.4\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/6b/73dfed0ab5299070cf98451af50130989901f50de41fe85d605437a0210f/parameterized-0.7.4-py2.py3-none-any.whl\n",
            "Collecting hydra-core>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/6e/6298e4099ecf7344fb6621e83ec92ba4384699397b2d9b2d17819f869a1d/hydra_core-1.0.5-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 16.7MB/s \n",
            "\u001b[?25hCollecting tensorboard==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 21.2MB/s \n",
            "\u001b[?25hCollecting faiss>=1.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/1c/4ae6cb87cf0c09c25561ea48db11e25713b25c580909902a92c090b377c0/faiss-1.5.3-cp36-cp36m-manylinux1_x86_64.whl (4.7MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7MB 59.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycocotools>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from vissl) (2.0.2)\n",
            "Collecting fairscale\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/4a/ad1d1e1bce9004d9fb694dd96ed71c291dfa3ef2d95964dc7a94af2248c3/fairscale-0.1.4.tar.gz (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 13.6MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from vissl) (1.19.5)\n",
            "Collecting fvcore\n",
            "  Downloading https://files.pythonhosted.org/packages/d9/fa/80051880c86698764d09a87c0523c43e058047adc060d0590bbd46132c23/fvcore-0.1.2.post20210115.tar.gz\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from vissl) (0.22.2.post1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from vissl) (0.29.21)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 46.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from hydra-core>=1.0->vissl) (4.1.1)\n",
            "Collecting omegaconf<2.1,>=2.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/eb/9d63ce09dd8aa85767c65668d5414958ea29648a0eec80a4a7d311ec2684/omegaconf-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->vissl) (3.3.3)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->vissl) (1.32.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->vissl) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->vissl) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->vissl) (3.12.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->vissl) (51.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->vissl) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->vissl) (0.36.2)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.1->vissl) (3.2.2)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from fairscale->vissl) (1.5.1+cu101)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n",
            "Collecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/5b/bc0b5ab38247bba158504a410112b6c03f153c652734ece1849749e5f518/PyYAML-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (640kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 54.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fvcore->vissl) (4.41.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from fvcore->vissl) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fvcore->vissl) (7.0.0)\n",
            "Collecting iopath>=0.1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/c8/1830019bcecf26e76c3fdc36e2a6fa454388a233894dcf6f5eb00a881468/iopath-0.1.3.tar.gz\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->vissl) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->vissl) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core>=1.0->vissl) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from omegaconf<2.1,>=2.0.5->hydra-core>=1.0->vissl) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses; python_version == \"3.6\" in /usr/local/lib/python3.6/dist-packages (from omegaconf<2.1,>=2.0.5->hydra-core>=1.0->vissl) (0.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard==1.15.0->vissl) (3.3.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl) (1.3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->fairscale->vissl) (0.16.0)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/28/94/690880aa6cd96130fc0abf82ee8087b8de2d3c55515a3e42793c58d8a353/portalocker-2.1.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: fairscale\n",
            "  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.1.4-cp36-cp36m-linux_x86_64.whl size=1855477 sha256=a9bd2c5d4b6519476a88ddedcfe19bc71a0fb8d9c9cb66c15738c81b307b183c\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/7e/5b/346be647e3144fd896edcd1ab23cf034bdd16d5c137b2d3388\n",
            "Successfully built fairscale\n",
            "Building wheels for collected packages: fvcore, antlr4-python3-runtime, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.2.post20210115-cp36-none-any.whl size=40892 sha256=4b446ec4c937b93f1f3b05816460ad111dffc3d6f2cacb8fd47af6817201c6cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/0f/bc/fb742771f4a877f1211dd6ed36283b0db9c0ceb2b409b4a039\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp36-none-any.whl size=141231 sha256=9ef7f29426f07cdd8ecca1bb7b0abce6fa0116fa12802950145f938bfc36144f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.3-cp36-none-any.whl size=11169 sha256=ba807aff053f32dbbb2cb9206f13abf3a480939d97a207ea730f96cfbba1c1a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/1d/55/94a55e032409ac7617f9cbb88a0fa2cf4e7208806c29730804\n",
            "Successfully built fvcore antlr4-python3-runtime iopath\n",
            "\u001b[31mERROR: tensorflow 2.4.0 has requirement tensorboard~=2.4, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: parameterized, antlr4-python3-runtime, pyyaml, omegaconf, hydra-core, tensorboard, faiss, fairscale, yacs, portalocker, iopath, fvcore, vissl\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "Successfully installed antlr4-python3-runtime-4.8 fairscale-0.1.4 faiss-1.5.3 fvcore-0.1.2.post20210115 hydra-core-1.0.5 iopath-0.1.3 omegaconf-2.0.6 parameterized-0.7.4 portalocker-2.1.0 pyyaml-5.4.1 tensorboard-1.15.0 vissl-0.1.5 yacs-0.1.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Fxe3MWxqsI"
      },
      "source": [
        "VISSL should be successfuly installed by now and all the dependencies should be available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np6atgoOTPrA"
      },
      "source": [
        "import vissl\n",
        "import tensorboard\n",
        "import apex\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFEHZ4KdxzWq"
      },
      "source": [
        "## YAML config file for Feature Extraction\n",
        "\n",
        "VISSL provides yaml configuration files for extracting features [here](https://github.com/facebookresearch/vissl/tree/master/configs/config/feature_extraction). \n",
        "\n",
        "For the purpose of this tutorial, we will use the config file for extracting features from several layers in the trunk of ResNet-50 supervised model on 1-gpu. Let's go ahead and download the [example config file](https://github.com/facebookresearch/vissl/blob/master/configs/config/feature_extraction/extract_resnet_in1k_8gpu.yaml) and [feature settings for trunk layers](https://github.com/facebookresearch/vissl/blob/master/configs/config/feature_extraction/trunk_only/rn50_layers.yaml).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ufyNAeUaDSs"
      },
      "source": [
        "!mkdir -p configs/config/trunk_only\n",
        "!wget -q -O configs/__init__.py https://dl.fbaipublicfiles.com/vissl/tutorials/configs/__init__.py \n",
        "!wget -q -O configs/config/extract_resnet_in1k_8gpu.yaml https://dl.fbaipublicfiles.com/vissl/tutorials/configs/extract_resnet_in1k_8gpu.yaml\n",
        "!wget -q -O configs/config/trunk_only/rn50_layers.yaml https://dl.fbaipublicfiles.com/vissl/tutorials/configs/trunk_only/rn50_layers.yaml"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxMXLYLpsJXj"
      },
      "source": [
        "## Download the ResNet-50 weights from Torchvision\n",
        "\n",
        "We download the weights from the [torchvision ResNet50 model](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L16):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv0quZwFsWxs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b305ee47-9e98-4acb-a0c1-8dace35152da"
      },
      "source": [
        "!wget https://download.pytorch.org/models/resnet50-19c8e357.pth"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-25 20:14:03--  https://download.pytorch.org/models/resnet50-19c8e357.pth\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 99.86.35.85, 99.86.35.44, 99.86.35.29, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|99.86.35.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102502400 (98M) [application/octet-stream]\n",
            "Saving to: ‘resnet50-19c8e357.pth’\n",
            "\n",
            "resnet50-19c8e357.p 100%[===================>]  97.75M   279MB/s    in 0.4s    \n",
            "\n",
            "2021-01-25 20:14:03 (279 MB/s) - ‘resnet50-19c8e357.pth’ saved [102502400/102502400]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndNMJGSRyffl"
      },
      "source": [
        "## Builtin feature extraction tool in VISSL\n",
        "\n",
        "VISSL also provides a [helper python tool](https://github.com/facebookresearch/vissl/blob/master/tools/run_distributed_engines.py) that allows to use VISSL for training purposes. This tool offers:\n",
        "- allows training and feature extraction both using VISSL. \n",
        "- also allows training on 1-gpu or multi-gpu. \n",
        "- can be used to launch multi-machine distributed training.\n",
        "\n",
        "Let's go ahead and download this tool directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6io7qQWzCbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "333c4319-442d-4fbd-9cc8-559c627644cf"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/vissl/tutorials/run_distributed_engines.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-25 20:14:09--  https://dl.fbaipublicfiles.com/vissl/tutorials/run_distributed_engines.py\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6568 (6.4K) [text/x-python]\n",
            "Saving to: ‘run_distributed_engines.py’\n",
            "\n",
            "\r          run_distr   0%[                    ]       0  --.-KB/s               \rrun_distributed_eng 100%[===================>]   6.41K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-01-25 20:14:09 (87.7 MB/s) - ‘run_distributed_engines.py’ saved [6568/6568]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0hng2EPY7pr"
      },
      "source": [
        "## Creating a custom data\n",
        "\n",
        "For the purpose of this tutorial, since we don't have ImageNet on the disk, we will create a dummy dataset by copying an image from COCO dataset in ImageNet dataset folder style as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-sy6nD-RfwB"
      },
      "source": [
        "!mkdir -p dummy_data/train/class1\n",
        "!mkdir -p dummy_data/train/class2\n",
        "!mkdir -p dummy_data/val/class1\n",
        "!mkdir -p dummy_data/val/class2\n",
        "\n",
        "# create 2 classes in train and add 5 images per class\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img5.jpg\n",
        "\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img5.jpg\n",
        "\n",
        "# create 2 classes in val and add 5 images per class\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img5.jpg\n",
        "\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img5.jpg\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPGCiTsXZeW3"
      },
      "source": [
        "## Using the custom data in VISSL\n",
        "\n",
        "Next step for us is to register the dummy data we created above with VISSL. Registering the dataset involves telling VISSL about the dataset name and the paths for the dataset. For this, we create a simple json file with the metadata and save it to `configs/config/dataset_catalog.py` file.\n",
        "\n",
        "**NOTE**: VISSL uses the specific `dataset_catalog.json` under the path `configs/config/dataset_catalog.json`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8Q6LCqaWjl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c65a7997-8035-4b92-b4e8-c4c3cb3c0c0c"
      },
      "source": [
        "json_data = {\n",
        "    \"dummy_data_folder\": {\n",
        "      \"train\": [\n",
        "        \"/content/dummy_data/train\", \"/content/dummy_data/train\"\n",
        "      ],\n",
        "      \"val\": [\n",
        "        \"/content/dummy_data/val\", \"/content/dummy_data/val\"\n",
        "      ]\n",
        "    }\n",
        "}\n",
        "\n",
        "# use VISSL's api to save or you can use your custom code.\n",
        "from vissl.utils.io import save_file\n",
        "save_file(json_data, \"/content/configs/config/dataset_catalog.json\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otN1pB32cBHK"
      },
      "source": [
        "Next, we verify that the dataset is registered with VISSL. For that we query VISSL's dataset catalog as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZBhH-s5bcHd",
        "outputId": "e6081633-3cc0-414a-e558-0bcaf9d9e364"
      },
      "source": [
        "from vissl.data.dataset_catalog import VisslDatasetCatalog\n",
        "\n",
        "# list all the datasets that exist in catalog\n",
        "print(VisslDatasetCatalog.list())\n",
        "\n",
        "# get the metadata of dummy_data_folder dataset\n",
        "print(VisslDatasetCatalog.get(\"dummy_data_folder\"))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dummy_data_folder']\n",
            "{'train': ['/content/dummy_data/train', '/content/dummy_data/train'], 'val': ['/content/dummy_data/val', '/content/dummy_data/val']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaUMDwMdzYHN"
      },
      "source": [
        "## Extract the features\n",
        "\n",
        "We are ready to extract features now. For the purpose of this tutorial, we will use synthetic dataset and train on dummy images. VISSL supports training on wide range of datasets and allows adding custom datasets. Please see VISSL documentation on how to use the datasets. To train on ImageNet instead: assuming your ImageNet dataset folder path is `/path/to/my/imagenet/folder/`, you can add the following command line \n",
        "input to your training command: \n",
        "```\n",
        "config.DATA.TRAIN.DATASET_NAMES=[imagenet1k_folder] \\\n",
        "config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "config.DATA.TRAIN.DATA_PATHS=[\"/path/to/my/imagenet/folder/train\"] \\\n",
        "config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM7IigSpONW0"
      },
      "source": [
        "The feature extraction command looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v0HvauIj9S2",
        "outputId": "c67440f6-893d-41bc-c537-12a26a4b9439"
      },
      "source": [
        "!python3 run_distributed_engines.py \\\n",
        "    hydra.verbose=true \\\n",
        "    config=extract_resnet_in1k_8gpu \\\n",
        "    +config/trunk_only=rn50_layers \\\n",
        "    config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DATA.TEST.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TEST.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DISTRIBUTED.NUM_NODES=1 \\\n",
        "    config.DISTRIBUTED.NUM_PROC_PER_NODE=1 \\\n",
        "    config.CHECKPOINT.DIR=\"./checkpoints\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.PARAMS_FILE=\"/content/resnet50-19c8e357.pth\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=\"trunk.base_model._feature_blocks.\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=\"\"\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "####### overrides: ['hydra.verbose=true', 'config=extract_resnet_in1k_8gpu', '+config/trunk_only=rn50_layers', 'config.DATA.TRAIN.DATA_SOURCES=[disk_folder]', 'config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]', 'config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2', 'config.DATA.TEST.DATA_SOURCES=[disk_folder]', 'config.DATA.TEST.LABEL_SOURCES=[disk_folder]', 'config.DATA.TEST.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TEST.BATCHSIZE_PER_REPLICA=2', 'config.DISTRIBUTED.NUM_NODES=1', 'config.DISTRIBUTED.NUM_PROC_PER_NODE=1', 'config.CHECKPOINT.DIR=./checkpoints', 'config.MODEL.WEIGHTS_INIT.PARAMS_FILE=/content/resnet50-19c8e357.pth', 'config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=trunk.base_model._feature_blocks.', 'config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=', 'hydra.verbose=true']\n",
            "INFO 2021-01-25 20:14:58,443 __init__.py:  32: Provided Config has latest version: 1\n",
            "[PathManager] Attempting to register prefix 'http://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 194, in <module>\n",
            "    hydra_main(overrides=overrides)\n",
            "  File \"run_distributed_engines.py\", line 179, in hydra_main\n",
            "    hook_generator=default_hook_generator,\n",
            "  File \"run_distributed_engines.py\", line 77, in launch_distributed\n",
            "    set_env_vars(local_rank=0, node_id=node_id, cfg=cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'http://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "[PathManager] Attempting to register prefix 'https://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 194, in <module>\n",
            "    hydra_main(overrides=overrides)\n",
            "  File \"run_distributed_engines.py\", line 179, in hydra_main\n",
            "    hook_generator=default_hook_generator,\n",
            "  File \"run_distributed_engines.py\", line 77, in launch_distributed\n",
            "    set_env_vars(local_rank=0, node_id=node_id, cfg=cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'https://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "[PathManager] Attempting to register prefix 'ftp://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 194, in <module>\n",
            "    hydra_main(overrides=overrides)\n",
            "  File \"run_distributed_engines.py\", line 179, in hydra_main\n",
            "    hook_generator=default_hook_generator,\n",
            "  File \"run_distributed_engines.py\", line 77, in launch_distributed\n",
            "    set_env_vars(local_rank=0, node_id=node_id, cfg=cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'ftp://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "INFO 2021-01-25 20:14:58,444 run_distributed_engines.py: 163: Spawning process for node_id: 0, local_rank: 0, dist_rank: 0, dist_run_id: localhost:54097\n",
            "[PathManager] Attempting to register prefix 'http://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 123, in launch_distributed\n",
            "    hook_generator=hook_generator,\n",
            "  File \"run_distributed_engines.py\", line 166, in _distributed_worker\n",
            "    process_main(cfg, dist_run_id, local_rank=local_rank, node_id=node_id)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/engines/extract_features.py\", line 40, in extract_main\n",
            "    set_env_vars(local_rank, node_id, cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'http://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "[PathManager] Attempting to register prefix 'https://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 123, in launch_distributed\n",
            "    hook_generator=hook_generator,\n",
            "  File \"run_distributed_engines.py\", line 166, in _distributed_worker\n",
            "    process_main(cfg, dist_run_id, local_rank=local_rank, node_id=node_id)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/engines/extract_features.py\", line 40, in extract_main\n",
            "    set_env_vars(local_rank, node_id, cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'https://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "[PathManager] Attempting to register prefix 'ftp://' from the following call stack:\n",
            "  File \"run_distributed_engines.py\", line 123, in launch_distributed\n",
            "    hook_generator=hook_generator,\n",
            "  File \"run_distributed_engines.py\", line 166, in _distributed_worker\n",
            "    process_main(cfg, dist_run_id, local_rank=local_rank, node_id=node_id)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/engines/extract_features.py\", line 40, in extract_main\n",
            "    set_env_vars(local_rank, node_id, cfg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/vissl/utils/env.py\", line 31, in set_env_vars\n",
            "    PathManager.register_handler(HTTPURLHandler(), allow_override=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fvcore/common/file_io.py\", line 287, in register_handler\n",
            "    + \"\".join(traceback.format_stack(limit=5))\n",
            "\n",
            "[PathManager] Prefix 'ftp://' is already registered by <class 'iopath.common.file_io.HTTPURLHandler'>. We will override the old handler. To avoid such conflicts, create a project-specific PathManager instead.\n",
            "INFO 2021-01-25 20:14:58,445 misc.py:  86: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-01-25 20:14:58,445 extract_features.py:  47: Setting seed....\n",
            "INFO 2021-01-25 20:14:58,445 misc.py:  99: MACHINE SEED: 0\n",
            "INFO 2021-01-25 20:14:58,480 hydra_config.py: 140: Training with config:\n",
            "INFO 2021-01-25 20:14:58,485 hydra_config.py: 144: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,\n",
            "                'AUTO_RESUME': True,\n",
            "                'BACKEND': 'disk',\n",
            "                'CHECKPOINT_FREQUENCY': 1,\n",
            "                'CHECKPOINT_ITER_FREQUENCY': -1,\n",
            "                'DIR': './checkpoints',\n",
            "                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,\n",
            "                'OVERWRITE_EXISTING': False,\n",
            "                'USE_SYMLINK_CHECKPOINT_FOR_RESUME': False},\n",
            " 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',\n",
            "                'FEATURES': {'DATASET_NAME': '',\n",
            "                             'DATA_PARTITION': 'TRAIN',\n",
            "                             'LAYER_NAME': ''},\n",
            "                'NUM_CLUSTERS': 16000,\n",
            "                'N_ITER': 50},\n",
            " 'DATA': {'DDP_BUCKET_CAP_MB': 25,\n",
            "          'ENABLE_ASYNC_GPU_COPY': True,\n",
            "          'NUM_DATALOADER_WORKERS': 5,\n",
            "          'PIN_MEMORY': True,\n",
            "          'TEST': {'BATCHSIZE_PER_REPLICA': 2,\n",
            "                   'COLLATE_FUNCTION': 'default_collate',\n",
            "                   'COLLATE_FUNCTION_PARAMS': {},\n",
            "                   'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',\n",
            "                   'COPY_TO_LOCAL_DISK': False,\n",
            "                   'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                   'DATA_LIMIT': -1,\n",
            "                   'DATA_PATHS': [],\n",
            "                   'DATA_SOURCES': ['disk_folder'],\n",
            "                   'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                   'DROP_LAST': False,\n",
            "                   'ENABLE_QUEUE_DATASET': False,\n",
            "                   'INPUT_KEY_NAMES': ['data'],\n",
            "                   'LABEL_PATHS': [],\n",
            "                   'LABEL_SOURCES': ['disk_folder'],\n",
            "                   'LABEL_TYPE': 'standard',\n",
            "                   'MMAP_MODE': False,\n",
            "                   'TARGET_KEY_NAMES': ['label'],\n",
            "                   'TRANSFORMS': [{'name': 'Resize', 'size': 256},\n",
            "                                  {'name': 'CenterCrop', 'size': 224},\n",
            "                                  {'name': 'ToTensor'},\n",
            "                                  {'mean': [0.485, 0.456, 0.406],\n",
            "                                   'name': 'Normalize',\n",
            "                                   'std': [0.229, 0.224, 0.225]}],\n",
            "                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},\n",
            "          'TRAIN': {'BATCHSIZE_PER_REPLICA': 2,\n",
            "                    'COLLATE_FUNCTION': 'default_collate',\n",
            "                    'COLLATE_FUNCTION_PARAMS': {},\n",
            "                    'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',\n",
            "                    'COPY_TO_LOCAL_DISK': False,\n",
            "                    'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                    'DATA_LIMIT': -1,\n",
            "                    'DATA_PATHS': [],\n",
            "                    'DATA_SOURCES': ['disk_folder'],\n",
            "                    'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                    'DROP_LAST': False,\n",
            "                    'ENABLE_QUEUE_DATASET': False,\n",
            "                    'INPUT_KEY_NAMES': ['data'],\n",
            "                    'LABEL_PATHS': [],\n",
            "                    'LABEL_SOURCES': ['disk_folder'],\n",
            "                    'LABEL_TYPE': 'standard',\n",
            "                    'MMAP_MODE': False,\n",
            "                    'TARGET_KEY_NAMES': ['label'],\n",
            "                    'TRANSFORMS': [{'name': 'Resize', 'size': 256},\n",
            "                                   {'name': 'CenterCrop', 'size': 224},\n",
            "                                   {'name': 'ToTensor'},\n",
            "                                   {'mean': [0.485, 0.456, 0.406],\n",
            "                                    'name': 'Normalize',\n",
            "                                    'std': [0.229, 0.224, 0.225]}],\n",
            "                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},\n",
            " 'DISTRIBUTED': {'BACKEND': 'nccl',\n",
            "                 'BROADCAST_BUFFERS': True,\n",
            "                 'INIT_METHOD': 'tcp',\n",
            "                 'MANUAL_GRADIENT_REDUCTION': False,\n",
            "                 'NCCL_DEBUG': False,\n",
            "                 'NCCL_SOCKET_NTHREADS': '',\n",
            "                 'NUM_NODES': 1,\n",
            "                 'NUM_PROC_PER_NODE': 1,\n",
            "                 'RUN_ID': 'auto'},\n",
            " 'IMG_RETRIEVAL': {'DATASET_PATH': '',\n",
            "                   'EVAL_BINARY_PATH': '',\n",
            "                   'EVAL_DATASET_NAME': 'Paris',\n",
            "                   'FEATS_PROCESSING_TYPE': '',\n",
            "                   'GEM_POOL_POWER': 4.0,\n",
            "                   'N_PCA': 512,\n",
            "                   'RESIZE_IMG': 1024,\n",
            "                   'SHOULD_TRAIN_PCA_OR_WHITENING': True,\n",
            "                   'SPATIAL_LEVELS': 3,\n",
            "                   'TEMP_DIR': '/tmp/instance_retrieval/',\n",
            "                   'TRAIN_DATASET_NAME': 'Oxford',\n",
            "                   'WHITEN_IMG_LIST': ''},\n",
            " 'LOG_FREQUENCY': 10,\n",
            " 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},\n",
            "          'bce_logits_multiple_output_single_target': {'normalize_output': False,\n",
            "                                                       'reduction': 'none',\n",
            "                                                       'world_size': 1},\n",
            "          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,\n",
            "                                                          'normalize_output': False,\n",
            "                                                          'reduction': 'mean',\n",
            "                                                          'temperature': 1.0,\n",
            "                                                          'weight': None},\n",
            "          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,\n",
            "                                 'DROP_LAST': True,\n",
            "                                 'kmeans_iters': 10,\n",
            "                                 'memory_params': {'crops_for_mb': [0],\n",
            "                                                   'embedding_dim': 128},\n",
            "                                 'num_clusters': [3000, 3000, 3000],\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_train_samples': -1,\n",
            "                                 'temperature': 0.1},\n",
            "          'moco_loss': {'embedding_dim': 128,\n",
            "                        'momentum': 0.999,\n",
            "                        'queue_size': 65536,\n",
            "                        'temperature': 0.2},\n",
            "          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                               'embedding_dim': 128,\n",
            "                                                               'world_size': 64},\n",
            "                                             'num_crops': 2,\n",
            "                                             'temperature': 0.1},\n",
            "          'name': 'CrossEntropyLoss',\n",
            "          'nce_loss_with_memory': {'loss_type': 'nce',\n",
            "                                   'loss_weights': [1.0],\n",
            "                                   'memory_params': {'embedding_dim': 128,\n",
            "                                                     'memory_size': -1,\n",
            "                                                     'momentum': 0.5,\n",
            "                                                     'norm_init': True,\n",
            "                                                     'update_mem_on_forward': True},\n",
            "                                   'negative_sampling_params': {'num_negatives': 16000,\n",
            "                                                                'type': 'random'},\n",
            "                                   'norm_constant': -1,\n",
            "                                   'norm_embedding': True,\n",
            "                                   'num_train_samples': -1,\n",
            "                                   'temperature': 0.07,\n",
            "                                   'update_mem_with_emb_index': -100},\n",
            "          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                     'embedding_dim': 128,\n",
            "                                                     'world_size': 64},\n",
            "                                   'temperature': 0.1},\n",
            "          'swav_loss': {'crops_for_assign': [0, 1],\n",
            "                        'embedding_dim': 128,\n",
            "                        'epsilon': 0.05,\n",
            "                        'normalize_last_layer': True,\n",
            "                        'num_crops': 2,\n",
            "                        'num_iters': 3,\n",
            "                        'num_prototypes': [3000],\n",
            "                        'output_dir': '',\n",
            "                        'queue': {'local_queue_length': 0,\n",
            "                                  'queue_length': 0,\n",
            "                                  'start_iter': 0},\n",
            "                        'temp_hard_assignment_iters': 0,\n",
            "                        'temperature': 0.1,\n",
            "                        'use_double_precision': False},\n",
            "          'swav_momentum_loss': {'crops_for_assign': [0, 1],\n",
            "                                 'embedding_dim': 128,\n",
            "                                 'epsilon': 0.05,\n",
            "                                 'momentum': 0.99,\n",
            "                                 'momentum_eval_mode_iter_start': 0,\n",
            "                                 'normalize_last_layer': True,\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_iters': 3,\n",
            "                                 'num_prototypes': [3000],\n",
            "                                 'queue': {'local_queue_length': 0,\n",
            "                                           'queue_length': 0,\n",
            "                                           'start_iter': 0},\n",
            "                                 'temperature': 0.1,\n",
            "                                 'use_double_precision': False}},\n",
            " 'MACHINE': {'DEVICE': 'gpu'},\n",
            " 'METERS': {'accuracy_list_meter': {'meter_names': [],\n",
            "                                    'num_meters': 1,\n",
            "                                    'topk_values': [1]},\n",
            "            'enable_training_meter': True,\n",
            "            'mean_ap_list_meter': {'max_cpu_capacity': -1,\n",
            "                                   'meter_names': [],\n",
            "                                   'num_classes': 9605,\n",
            "                                   'num_meters': 1},\n",
            "            'name': ''},\n",
            " 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,\n",
            "                                        'USE_ACTIVATION_CHECKPOINTING': False},\n",
            "           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'},\n",
            "                          'AMP_TYPE': 'apex',\n",
            "                          'USE_AMP': False},\n",
            "           'CUDA_CACHE': {'CLEAR_CUDA_CACHE': False, 'CLEAR_FREQ': 100},\n",
            "           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': True,\n",
            "                                     'EVAL_TRUNK_AND_HEAD': False,\n",
            "                                     'EXTRACT_TRUNK_FEATURES_ONLY': True,\n",
            "                                     'FREEZE_TRUNK_AND_HEAD': False,\n",
            "                                     'FREEZE_TRUNK_ONLY': True,\n",
            "                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [['conv1',\n",
            "                                                                        ['AvgPool2d',\n",
            "                                                                         [[10,\n",
            "                                                                           10],\n",
            "                                                                          10,\n",
            "                                                                          4]]],\n",
            "                                                                       ['res2',\n",
            "                                                                        ['AvgPool2d',\n",
            "                                                                         [[16,\n",
            "                                                                           16],\n",
            "                                                                          8,\n",
            "                                                                          0]]],\n",
            "                                                                       ['res3',\n",
            "                                                                        ['AvgPool2d',\n",
            "                                                                         [[13,\n",
            "                                                                           13],\n",
            "                                                                          5,\n",
            "                                                                          0]]],\n",
            "                                                                       ['res4',\n",
            "                                                                        ['AvgPool2d',\n",
            "                                                                         [[8,\n",
            "                                                                           8],\n",
            "                                                                          3,\n",
            "                                                                          0]]],\n",
            "                                                                       ['res5',\n",
            "                                                                        ['AvgPool2d',\n",
            "                                                                         [[6,\n",
            "                                                                           6],\n",
            "                                                                          1,\n",
            "                                                                          0]]],\n",
            "                                                                       ['res5avg',\n",
            "                                                                        ['Identity',\n",
            "                                                                         []]]],\n",
            "                                     'SHOULD_FLATTEN_FEATS': False},\n",
            "           'HEAD': {'BATCHNORM_EPS': 1e-05,\n",
            "                    'BATCHNORM_MOMENTUM': 0.1,\n",
            "                    'PARAMS': [],\n",
            "                    'PARAMS_MULTIPLIER': 1.0},\n",
            "           'INPUT_TYPE': 'rgb',\n",
            "           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,\n",
            "                                'INPUT_SHAPE': [3, 224, 224]},\n",
            "           'MULTI_INPUT_HEAD_MAPPING': [],\n",
            "           'NON_TRAINABLE_PARAMS': [],\n",
            "           'SINGLE_PASS_EVERY_CROP': False,\n",
            "           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': False,\n",
            "                              'GROUP_SIZE': -1,\n",
            "                              'SYNC_BN_TYPE': 'pytorch'},\n",
            "           'TEMP_FROZEN_PARAMS_ITER_MAP': [],\n",
            "           'TRUNK': {'NAME': 'resnet',\n",
            "                     'TRUNK_PARAMS': {'EFFICIENT_NETS': {},\n",
            "                                      'REGNET': {},\n",
            "                                      'RESNETS': {'DEPTH': 50,\n",
            "                                                  'GROUPS': 1,\n",
            "                                                  'LAYER4_STRIDE': 2,\n",
            "                                                  'NORM': 'BatchNorm',\n",
            "                                                  'WIDTH_MULTIPLIER': 1,\n",
            "                                                  'WIDTH_PER_GROUP': 64,\n",
            "                                                  'ZERO_INIT_RESIDUAL': False}}},\n",
            "           'WEIGHTS_INIT': {'APPEND_PREFIX': 'trunk.base_model._feature_blocks.',\n",
            "                            'PARAMS_FILE': '/content/resnet50-19c8e357.pth',\n",
            "                            'REMOVE_PREFIX': '',\n",
            "                            'SKIP_LAYERS': ['num_batches_tracked'],\n",
            "                            'STATE_DICT_KEY_NAME': ''}},\n",
            " 'MONITOR_PERF_STATS': False,\n",
            " 'MULTI_PROCESSING_METHOD': 'forkserver',\n",
            " 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},\n",
            " 'OPTIMIZER': {'head_optimizer_params': {'use_different_lr': False,\n",
            "                                         'use_different_wd': False,\n",
            "                                         'weight_decay': 0.0001},\n",
            "               'larc_config': {'clip': False,\n",
            "                               'eps': 1e-08,\n",
            "                               'trust_coefficient': 0.001},\n",
            "               'momentum': 0.9,\n",
            "               'name': 'sgd',\n",
            "               'nesterov': False,\n",
            "               'num_epochs': 90,\n",
            "               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': False,\n",
            "                                                               'base_lr_batch_size': 256,\n",
            "                                                               'base_value': 0.1},\n",
            "                                           'end_value': 0.0,\n",
            "                                           'interval_scaling': [],\n",
            "                                           'lengths': [],\n",
            "                                           'milestones': [30, 60],\n",
            "                                           'name': 'multistep',\n",
            "                                           'schedulers': [],\n",
            "                                           'start_value': 0.1,\n",
            "                                           'update_interval': 'epoch',\n",
            "                                           'value': 0.1,\n",
            "                                           'values': [0.1, 0.01, 0.001]},\n",
            "                                    'lr_head': {'auto_lr_scaling': {'auto_scale': False,\n",
            "                                                                    'base_lr_batch_size': 256,\n",
            "                                                                    'base_value': 0.1},\n",
            "                                                'end_value': 0.0,\n",
            "                                                'interval_scaling': [],\n",
            "                                                'lengths': [],\n",
            "                                                'milestones': [30, 60],\n",
            "                                                'name': 'multistep',\n",
            "                                                'schedulers': [],\n",
            "                                                'start_value': 0.1,\n",
            "                                                'update_interval': 'epoch',\n",
            "                                                'value': 0.1,\n",
            "                                                'values': [0.1, 0.01, 0.001]}},\n",
            "               'regularize_bias': True,\n",
            "               'regularize_bn': False,\n",
            "               'use_larc': False,\n",
            "               'weight_decay': 0.0001},\n",
            " 'PERF_STAT_FREQUENCY': -1,\n",
            " 'ROLLING_BTIME_FREQ': -1,\n",
            " 'SEED_VALUE': 0,\n",
            " 'SVM': {'cls_list': [],\n",
            "         'costs': {'base': -1.0,\n",
            "                   'costs_list': [0.1, 0.01],\n",
            "                   'power_range': [4, 20]},\n",
            "         'cross_val_folds': 3,\n",
            "         'dual': True,\n",
            "         'force_retrain': False,\n",
            "         'loss': 'squared_hinge',\n",
            "         'low_shot': {'dataset_name': 'voc',\n",
            "                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],\n",
            "                      'sample_inds': [1, 2, 3, 4, 5]},\n",
            "         'max_iter': 2000,\n",
            "         'normalize': True,\n",
            "         'penalty': 'l2'},\n",
            " 'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': 'tensorboard',\n",
            "                       'FLUSH_EVERY_N_MIN': 5,\n",
            "                       'LOG_DIR': '.',\n",
            "                       'LOG_PARAMS': True,\n",
            "                       'LOG_PARAMS_EVERY_N_ITERS': 310,\n",
            "                       'LOG_PARAMS_GRADIENTS': True,\n",
            "                       'USE_TENSORBOARD': False},\n",
            " 'TEST_EVERY_NUM_EPOCH': 1,\n",
            " 'TEST_MODEL': True,\n",
            " 'TEST_ONLY': False,\n",
            " 'TRAINER': {'TASK_NAME': 'self_supervision_task',\n",
            "             'TRAIN_STEP_NAME': 'standard_train_step'},\n",
            " 'VERBOSE': False}\n",
            "INFO 2021-01-25 20:14:58,801 extract_features.py:  54: System config:\n",
            "-------------------  ---------------------------------------------------------------\n",
            "sys.platform         linux\n",
            "Python               3.6.9 (default, Oct  8 2020, 12:12:24) [GCC 8.4.0]\n",
            "numpy                1.19.5\n",
            "Pillow               7.0.0\n",
            "vissl                0.1.5 @/usr/local/lib/python3.6/dist-packages/vissl\n",
            "GPU available        True\n",
            "GPU 0                Tesla T4\n",
            "CUDA_HOME            /usr/local/cuda\n",
            "torchvision          0.6.1+cu101 @/usr/local/lib/python3.6/dist-packages/torchvision\n",
            "hydra                1.0.5 @/usr/local/lib/python3.6/dist-packages/hydra\n",
            "classy_vision        0.6.0.dev @/usr/local/lib/python3.6/dist-packages/classy_vision\n",
            "tensorboard          1.15.0\n",
            "apex                 0.1 @/usr/local/lib/python3.6/dist-packages/apex\n",
            "cv2                  4.1.2\n",
            "PyTorch              1.5.1+cu101 @/usr/local/lib/python3.6/dist-packages/torch\n",
            "PyTorch debug build  False\n",
            "-------------------  ---------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 10.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "CPU info:\n",
            "-------------------  ------------------------------\n",
            "Architecture         x86_64\n",
            "CPU op-mode(s)       32-bit, 64-bit\n",
            "Byte Order           Little Endian\n",
            "CPU(s)               2\n",
            "On-line CPU(s) list  0,1\n",
            "Thread(s) per core   2\n",
            "Core(s) per socket   1\n",
            "Socket(s)            1\n",
            "NUMA node(s)         1\n",
            "Vendor ID            GenuineIntel\n",
            "CPU family           6\n",
            "Model                79\n",
            "Model name           Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping             0\n",
            "CPU MHz              2199.998\n",
            "BogoMIPS             4399.99\n",
            "Hypervisor vendor    KVM\n",
            "Virtualization type  full\n",
            "L1d cache            32K\n",
            "L1i cache            32K\n",
            "L2 cache             256K\n",
            "L3 cache             56320K\n",
            "NUMA node0 CPU(s)    0,1\n",
            "-------------------  ------------------------------\n",
            "INFO 2021-01-25 20:14:58,801 train_task.py: 192: Not using Automatic Mixed Precision\n",
            "INFO 2021-01-25 20:14:58,802 trainer_main.py: 109: Using Distributed init method: tcp://localhost:54097, world_size: 1, rank: 0\n",
            "INFO 2021-01-25 20:14:58,804 trainer_main.py: 130: | initialized host fd49e07ea80e as rank 0 (0)\n",
            "INFO 2021-01-25 20:14:58,804 ssl_dataset.py: 130: Rank: 0 split: TEST Data files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-01-25 20:14:58,804 ssl_dataset.py: 133: Rank: 0 split: TEST Label files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-01-25 20:14:58,805 disk_dataset.py:  81: Loaded 10 samples from folder /content/dummy_data/val\n",
            "INFO 2021-01-25 20:14:58,805 ssl_dataset.py: 130: Rank: 0 split: TRAIN Data files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-01-25 20:14:58,805 ssl_dataset.py: 133: Rank: 0 split: TRAIN Label files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-01-25 20:14:58,805 disk_dataset.py:  81: Loaded 10 samples from folder /content/dummy_data/train\n",
            "INFO 2021-01-25 20:14:58,805 misc.py:  86: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-01-25 20:14:58,805 __init__.py:  91: Created the Distributed Sampler....\n",
            "INFO 2021-01-25 20:14:58,805 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "INFO 2021-01-25 20:14:58,806 __init__.py: 155: Wrapping the dataloader to async device copies\n",
            "INFO 2021-01-25 20:15:08,736 misc.py:  86: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-01-25 20:15:08,736 __init__.py:  91: Created the Distributed Sampler....\n",
            "INFO 2021-01-25 20:15:08,736 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True}\n",
            "INFO 2021-01-25 20:15:08,736 __init__.py: 155: Wrapping the dataloader to async device copies\n",
            "INFO 2021-01-25 20:15:08,737 train_task.py: 419: Building model....\n",
            "INFO 2021-01-25 20:15:08,737 feature_extractor.py:  23: Creating Feature extractor trunk...\n",
            "INFO 2021-01-25 20:15:08,737 resnext.py:  63: ResNeXT trunk, supports activation checkpointing. Deactivated\n",
            "INFO 2021-01-25 20:15:08,737 resnext.py:  83: Building model: ResNeXt50-1x64d-w1-BatchNorm2d\n",
            "INFO 2021-01-25 20:15:09,363 feature_extractor.py:  46: Freezing model trunk...\n",
            "INFO 2021-01-25 20:15:09,363 train_task.py: 437: config.MODEL.FEATURE_EVAL_SETTINGS.FREEZE_TRUNK_ONLY=True, will freeze trunk...\n",
            "INFO 2021-01-25 20:15:09,364 base_ssl_model.py: 181: Freezing model trunk...\n",
            "INFO 2021-01-25 20:15:09,364 train_task.py: 378: Initializing model from: /content/resnet50-19c8e357.pth\n",
            "INFO 2021-01-25 20:15:09,364 util.py: 277: Attempting to load checkpoint from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-01-25 20:15:09,587 util.py: 282: Loaded checkpoint from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-01-25 20:15:09,587 util.py: 241: Broadcasting checkpoint loaded from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-01-25 20:15:12,333 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,333 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,333 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,333 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,333 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,333 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,333 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,333 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,333 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,333 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,334 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,334 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,334 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,334 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,334 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,334 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,334 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,334 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,334 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,334 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,334 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,334 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,334 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,334 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,334 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,334 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,335 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,335 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,335 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,335 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,335 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,335 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,335 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,335 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,335 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,335 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,335 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,335 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,335 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,335 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,335 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,335 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,336 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,336 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,336 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,336 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,336 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,336 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,336 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,336 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,336 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,336 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,336 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,336 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,336 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,336 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,336 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,336 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,337 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,337 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,337 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,337 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,337 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,337 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,337 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,337 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,337 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,337 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,337 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,337 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,337 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,337 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,337 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,338 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,338 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,338 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,338 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,338 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,338 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,338 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,338 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,338 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,338 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,338 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,338 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,338 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,339 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,339 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,339 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,339 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,339 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,339 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,339 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,339 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,339 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,339 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,339 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,339 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,339 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,410 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,410 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,410 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,410 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,410 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,410 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,411 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,411 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,411 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,411 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,411 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,411 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,411 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,411 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,411 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,412 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,412 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,412 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,412 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,412 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,412 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,412 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,412 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,412 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,413 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,413 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,413 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,413 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,413 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,413 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,413 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,413 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,413 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.3.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,413 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,414 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,414 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,414 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,414 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,414 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.3.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,414 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,414 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,414 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,414 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,414 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,415 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.3.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,415 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,415 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,415 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,415 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,415 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,415 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,416 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,416 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,416 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,416 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,416 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,416 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,416 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,416 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,416 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,417 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,417 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,417 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,417 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,417 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,417 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,417 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,417 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,417 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,418 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,418 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,418 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,418 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,418 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,418 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,418 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,419 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,419 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,419 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,419 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,419 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,419 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,419 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,419 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,419 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,419 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,419 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,420 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,420 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,420 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,420 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,420 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,420 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,420 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,420 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,421 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,421 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,421 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,421 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,421 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,421 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,421 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,421 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,421 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,421 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,422 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,422 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,422 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,422 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,422 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,422 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.3.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,422 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,422 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,422 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,422 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,423 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,423 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.3.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,423 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,423 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,423 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,423 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,423 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,423 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.3.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,423 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,424 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,424 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,424 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,424 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,424 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.4.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,424 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,424 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,424 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,424 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,425 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,425 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.4.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,425 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,425 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,425 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,425 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,425 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,425 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.4.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,425 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,425 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,426 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,426 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,426 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,426 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.5.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,426 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,426 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,516 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,516 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,516 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,516 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.5.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,517 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,517 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,517 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,517 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,517 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,517 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.5.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,518 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,518 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,518 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,518 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,518 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,518 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,520 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,520 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,520 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,520 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,520 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,520 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,521 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,521 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,521 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,521 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,521 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,521 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,523 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,523 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,523 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,523 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,523 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,523 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,524 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,524 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,524 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,524 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,524 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,524 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.1.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,526 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,526 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,526 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,526 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,526 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,526 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.1.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,527 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,527 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,527 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,527 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,527 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,527 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.1.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,528 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,528 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,528 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,528 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,528 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,529 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.2.bn1.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,531 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,531 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,531 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,531 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,531 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,531 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.2.bn2.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,532 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,532 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,532 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,532 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,532 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-01-25 20:15:12,532 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.2.bn3.num_batches_tracked\n",
            "INFO 2021-01-25 20:15:12,532 checkpoint.py: 470: Extra layers not loaded from checkpoint: ['trunk.base_model._feature_blocks.fc.weight', 'trunk.base_model._feature_blocks.fc.bias']\n",
            "INFO 2021-01-25 20:15:12,587 trainer_main.py: 324: Model is:\n",
            " Classy <class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'>:\n",
            "BaseSSLMultiInputOutputModel(\n",
            "  (_heads): ModuleDict()\n",
            "  (trunk): FeatureExtractorModel(\n",
            "    (base_model): ResNeXt(\n",
            "      (_feature_blocks): ModuleDict(\n",
            "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv1_relu): ReLU(inplace=True)\n",
            "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "        (layer1): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (layer2): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (layer3): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (4): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (5): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (layer4): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), bias=False)\n",
            "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "        (flatten): Flatten()\n",
            "      )\n",
            "    )\n",
            "    (feature_pool_ops): ModuleList(\n",
            "      (0): AvgPool2d(kernel_size=[10, 10], stride=10, padding=4)\n",
            "      (1): AvgPool2d(kernel_size=[16, 16], stride=8, padding=0)\n",
            "      (2): AvgPool2d(kernel_size=[13, 13], stride=5, padding=0)\n",
            "      (3): AvgPool2d(kernel_size=[8, 8], stride=3, padding=0)\n",
            "      (4): AvgPool2d(kernel_size=[6, 6], stride=1, padding=0)\n",
            "      (5): Identity()\n",
            "    )\n",
            "  )\n",
            "  (heads): ModuleList()\n",
            "  (dummy_layer): Linear(in_features=4, out_features=4, bias=True)\n",
            ")\n",
            "INFO 2021-01-25 20:15:12,619 trainer_main.py: 335: Extracting features for partition: test\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-25 20:15:18,924 trainer_main.py: 362: Model set to eval mode during feature extraction...\n",
            "INFO 2021-01-25 20:15:19,402 trainer_main.py: 340: Done getting features for partition: test\n",
            "INFO 2021-01-25 20:15:19,402 trainer_main.py: 335: Extracting features for partition: train\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "INFO 2021-01-25 20:15:25,288 trainer_main.py: 362: Model set to eval mode during feature extraction...\n",
            "INFO 2021-01-25 20:15:25,391 trainer_main.py: 340: Done getting features for partition: train\n",
            "INFO 2021-01-25 20:15:25,477 extract_features.py:  61: ============== Split: test =======================\n",
            "INFO 2021-01-25 20:15:25,478 extract_features.py:  73: Saving extracted features: conv1 (10, 9216) to: ./checkpoints/rank0_test_conv1_features.npy\n",
            "INFO 2021-01-25 20:15:25,478 io.py:  56: Saving data to file: ./checkpoints/rank0_test_conv1_features.npy\n",
            "INFO 2021-01-25 20:15:25,478 io.py:  70: Saved data to file: ./checkpoints/rank0_test_conv1_features.npy\n",
            "INFO 2021-01-25 20:15:25,479 extract_features.py:  79: Saving extracted targets: (10, 1) to: ./checkpoints/rank0_test_conv1_targets.npy\n",
            "INFO 2021-01-25 20:15:25,479 io.py:  56: Saving data to file: ./checkpoints/rank0_test_conv1_targets.npy\n",
            "INFO 2021-01-25 20:15:25,479 io.py:  70: Saved data to file: ./checkpoints/rank0_test_conv1_targets.npy\n",
            "INFO 2021-01-25 20:15:25,479 extract_features.py:  85: Saving extracted indices: (10,) to: ./checkpoints/rank0_test_conv1_inds.npy\n",
            "INFO 2021-01-25 20:15:25,479 io.py:  56: Saving data to file: ./checkpoints/rank0_test_conv1_inds.npy\n",
            "INFO 2021-01-25 20:15:25,479 io.py:  70: Saved data to file: ./checkpoints/rank0_test_conv1_inds.npy\n",
            "INFO 2021-01-25 20:15:25,479 extract_features.py:  73: Saving extracted features: res2 (10, 9216) to: ./checkpoints/rank0_test_res2_features.npy\n",
            "INFO 2021-01-25 20:15:25,480 io.py:  56: Saving data to file: ./checkpoints/rank0_test_res2_features.npy\n",
            "INFO 2021-01-25 20:15:25,480 io.py:  70: Saved data to file: ./checkpoints/rank0_test_res2_features.npy\n",
            "INFO 2021-01-25 20:15:25,480 extract_features.py:  79: Saving extracted targets: (10, 1) to: ./checkpoints/rank0_test_res2_targets.npy\n",
            "INFO 2021-01-25 20:15:25,480 io.py:  56: Saving data to file: ./checkpoints/rank0_test_res2_targets.npy\n",
            "INFO 2021-01-25 20:15:25,481 io.py:  70: Saved data to file: ./checkpoints/rank0_test_res2_targets.npy\n",
            "INFO 2021-01-25 20:15:25,481 extract_features.py:  85: Saving extracted indices: (10,) to: ./checkpoints/rank0_test_res2_inds.npy\n",
            "INFO 2021-01-25 20:15:25,481 io.py:  56: Saving data to file: ./checkpoints/rank0_test_res2_inds.npy\n",
            "INFO 2021-01-25 20:15:25,481 io.py:  70: Saved data to file: ./checkpoints/rank0_test_res2_inds.npy\n",
            "INFO 2021-01-25 20:15:25,481 extract_features.py:  73: Saving extracted features: res3 (10, 8192) to: ./checkpoints/rank0_test_res3_features.npy\n",
            "INFO 2021-01-25 20:15:25,481 io.py:  56: Saving data to file: ./checkpoints/rank0_test_res3_features.npy\n",
            "INFO 2021-01-25 20:15:25,482 io.py:  70: Saved data to file: ./checkpoints/rank0_test_res3_features.npy\n",
            "INFO 2021-01-25 20:15:25,482 extract_features.py:  79: Saving extracted targets: (10, 1) to: ./checkpoints/rank0_test_res3_targets.npy\n",
            "INFO 2021-01-25 20:15:25,482 io.py:  56: Saving data to file: ./checkpoints/rank0_test_res3_targets.npy\n",
            "INFO 2021-01-25 20:15:25,482 io.py:  70: Saved data to file: ./checkpoints/rank0_test_res3_targets.npy\n",
            "INFO 2021-01-25 20:15:25,482 extract_features.py:  85: Saving extracted indices: (10,) to: ./checkpoints/rank0_test_res3_inds.npy\n",
            "INFO 2021-01-25 20:15:25,482 io.py:  56: Saving data to file: ./checkpoints/rank0_test_res3_inds.npy\n",
            "INFO 2021-01-25 20:15:25,483 io.py:  70: Saved data to file: ./checkpoints/rank0_test_res3_inds.npy\n",
            "INFO 2021-01-25 20:15:25,483 extract_features.py:  73: Saving extracted features: res4 (10, 9216) to: ./checkpoints/rank0_test_res4_features.npy\n",
            "INFO 2021-01-25 20:15:25,483 io.py:  56: Saving data to file: ./checkpoints/rank0_test_res4_features.npy\n",
            "INFO 2021-01-25 20:15:25,483 io.py:  70: Saved data to file: ./checkpoints/rank0_test_res4_features.npy\n",
            "INFO 2021-01-25 20:15:25,483 extract_features.py:  79: Saving extracted targets: (10, 1) to: ./checkpoints/rank0_test_res4_targets.npy\n",
            "INFO 2021-01-25 20:15:25,483 io.py:  56: Saving data to file: ./checkpoints/rank0_test_res4_targets.npy\n",
            "INFO 2021-01-25 20:15:25,484 io.py:  70: Saved data to file: ./checkpoints/rank0_test_res4_targets.npy\n",
            "INFO 2021-01-25 20:15:25,484 extract_features.py:  85: Saving extracted indices: (10,) to: ./checkpoints/rank0_test_res4_inds.npy\n",
            "INFO 2021-01-25 20:15:25,484 io.py:  56: Saving data to file: ./checkpoints/rank0_test_res4_inds.npy\n",
            "INFO 2021-01-25 20:15:25,484 io.py:  70: Saved data to file: ./checkpoints/rank0_test_res4_inds.npy\n",
            "INFO 2021-01-25 20:15:25,484 extract_features.py:  73: Saving extracted features: res5 (10, 8192) to: ./checkpoints/rank0_test_res5_features.npy\n",
            "INFO 2021-01-25 20:15:25,484 io.py:  56: Saving data to file: ./checkpoints/rank0_test_res5_features.npy\n",
            "INFO 2021-01-25 20:15:25,485 io.py:  70: Saved data to file: ./checkpoints/rank0_test_res5_features.npy\n",
            "INFO 2021-01-25 20:15:25,485 extract_features.py:  79: Saving extracted targets: (10, 1) to: ./checkpoints/rank0_test_res5_targets.npy\n",
            "INFO 2021-01-25 20:15:25,485 io.py:  56: Saving data to file: ./checkpoints/rank0_test_res5_targets.npy\n",
            "INFO 2021-01-25 20:15:25,485 io.py:  70: Saved data to file: ./checkpoints/rank0_test_res5_targets.npy\n",
            "INFO 2021-01-25 20:15:25,485 extract_features.py:  85: Saving extracted indices: (10,) to: ./checkpoints/rank0_test_res5_inds.npy\n",
            "INFO 2021-01-25 20:15:25,485 io.py:  56: Saving data to file: ./checkpoints/rank0_test_res5_inds.npy\n",
            "INFO 2021-01-25 20:15:25,486 io.py:  70: Saved data to file: ./checkpoints/rank0_test_res5_inds.npy\n",
            "INFO 2021-01-25 20:15:25,486 extract_features.py:  73: Saving extracted features: res5avg (10, 2048) to: ./checkpoints/rank0_test_res5avg_features.npy\n",
            "INFO 2021-01-25 20:15:25,486 io.py:  56: Saving data to file: ./checkpoints/rank0_test_res5avg_features.npy\n",
            "INFO 2021-01-25 20:15:25,486 io.py:  70: Saved data to file: ./checkpoints/rank0_test_res5avg_features.npy\n",
            "INFO 2021-01-25 20:15:25,486 extract_features.py:  79: Saving extracted targets: (10, 1) to: ./checkpoints/rank0_test_res5avg_targets.npy\n",
            "INFO 2021-01-25 20:15:25,486 io.py:  56: Saving data to file: ./checkpoints/rank0_test_res5avg_targets.npy\n",
            "INFO 2021-01-25 20:15:25,487 io.py:  70: Saved data to file: ./checkpoints/rank0_test_res5avg_targets.npy\n",
            "INFO 2021-01-25 20:15:25,487 extract_features.py:  85: Saving extracted indices: (10,) to: ./checkpoints/rank0_test_res5avg_inds.npy\n",
            "INFO 2021-01-25 20:15:25,487 io.py:  56: Saving data to file: ./checkpoints/rank0_test_res5avg_inds.npy\n",
            "INFO 2021-01-25 20:15:25,487 io.py:  70: Saved data to file: ./checkpoints/rank0_test_res5avg_inds.npy\n",
            "INFO 2021-01-25 20:15:25,487 extract_features.py:  61: ============== Split: train =======================\n",
            "INFO 2021-01-25 20:15:25,487 extract_features.py:  73: Saving extracted features: conv1 (10, 9216) to: ./checkpoints/rank0_train_conv1_features.npy\n",
            "INFO 2021-01-25 20:15:25,487 io.py:  56: Saving data to file: ./checkpoints/rank0_train_conv1_features.npy\n",
            "INFO 2021-01-25 20:15:25,488 io.py:  70: Saved data to file: ./checkpoints/rank0_train_conv1_features.npy\n",
            "INFO 2021-01-25 20:15:25,488 extract_features.py:  79: Saving extracted targets: (10, 1) to: ./checkpoints/rank0_train_conv1_targets.npy\n",
            "INFO 2021-01-25 20:15:25,488 io.py:  56: Saving data to file: ./checkpoints/rank0_train_conv1_targets.npy\n",
            "INFO 2021-01-25 20:15:25,488 io.py:  70: Saved data to file: ./checkpoints/rank0_train_conv1_targets.npy\n",
            "INFO 2021-01-25 20:15:25,488 extract_features.py:  85: Saving extracted indices: (10,) to: ./checkpoints/rank0_train_conv1_inds.npy\n",
            "INFO 2021-01-25 20:15:25,488 io.py:  56: Saving data to file: ./checkpoints/rank0_train_conv1_inds.npy\n",
            "INFO 2021-01-25 20:15:25,489 io.py:  70: Saved data to file: ./checkpoints/rank0_train_conv1_inds.npy\n",
            "INFO 2021-01-25 20:15:25,489 extract_features.py:  73: Saving extracted features: res2 (10, 9216) to: ./checkpoints/rank0_train_res2_features.npy\n",
            "INFO 2021-01-25 20:15:25,489 io.py:  56: Saving data to file: ./checkpoints/rank0_train_res2_features.npy\n",
            "INFO 2021-01-25 20:15:25,489 io.py:  70: Saved data to file: ./checkpoints/rank0_train_res2_features.npy\n",
            "INFO 2021-01-25 20:15:25,489 extract_features.py:  79: Saving extracted targets: (10, 1) to: ./checkpoints/rank0_train_res2_targets.npy\n",
            "INFO 2021-01-25 20:15:25,489 io.py:  56: Saving data to file: ./checkpoints/rank0_train_res2_targets.npy\n",
            "INFO 2021-01-25 20:15:25,490 io.py:  70: Saved data to file: ./checkpoints/rank0_train_res2_targets.npy\n",
            "INFO 2021-01-25 20:15:25,490 extract_features.py:  85: Saving extracted indices: (10,) to: ./checkpoints/rank0_train_res2_inds.npy\n",
            "INFO 2021-01-25 20:15:25,490 io.py:  56: Saving data to file: ./checkpoints/rank0_train_res2_inds.npy\n",
            "INFO 2021-01-25 20:15:25,490 io.py:  70: Saved data to file: ./checkpoints/rank0_train_res2_inds.npy\n",
            "INFO 2021-01-25 20:15:25,490 extract_features.py:  73: Saving extracted features: res3 (10, 8192) to: ./checkpoints/rank0_train_res3_features.npy\n",
            "INFO 2021-01-25 20:15:25,490 io.py:  56: Saving data to file: ./checkpoints/rank0_train_res3_features.npy\n",
            "INFO 2021-01-25 20:15:25,491 io.py:  70: Saved data to file: ./checkpoints/rank0_train_res3_features.npy\n",
            "INFO 2021-01-25 20:15:25,491 extract_features.py:  79: Saving extracted targets: (10, 1) to: ./checkpoints/rank0_train_res3_targets.npy\n",
            "INFO 2021-01-25 20:15:25,491 io.py:  56: Saving data to file: ./checkpoints/rank0_train_res3_targets.npy\n",
            "INFO 2021-01-25 20:15:25,491 io.py:  70: Saved data to file: ./checkpoints/rank0_train_res3_targets.npy\n",
            "INFO 2021-01-25 20:15:25,491 extract_features.py:  85: Saving extracted indices: (10,) to: ./checkpoints/rank0_train_res3_inds.npy\n",
            "INFO 2021-01-25 20:15:25,491 io.py:  56: Saving data to file: ./checkpoints/rank0_train_res3_inds.npy\n",
            "INFO 2021-01-25 20:15:25,492 io.py:  70: Saved data to file: ./checkpoints/rank0_train_res3_inds.npy\n",
            "INFO 2021-01-25 20:15:25,492 extract_features.py:  73: Saving extracted features: res4 (10, 9216) to: ./checkpoints/rank0_train_res4_features.npy\n",
            "INFO 2021-01-25 20:15:25,492 io.py:  56: Saving data to file: ./checkpoints/rank0_train_res4_features.npy\n",
            "INFO 2021-01-25 20:15:25,492 io.py:  70: Saved data to file: ./checkpoints/rank0_train_res4_features.npy\n",
            "INFO 2021-01-25 20:15:25,492 extract_features.py:  79: Saving extracted targets: (10, 1) to: ./checkpoints/rank0_train_res4_targets.npy\n",
            "INFO 2021-01-25 20:15:25,493 io.py:  56: Saving data to file: ./checkpoints/rank0_train_res4_targets.npy\n",
            "INFO 2021-01-25 20:15:25,493 io.py:  70: Saved data to file: ./checkpoints/rank0_train_res4_targets.npy\n",
            "INFO 2021-01-25 20:15:25,493 extract_features.py:  85: Saving extracted indices: (10,) to: ./checkpoints/rank0_train_res4_inds.npy\n",
            "INFO 2021-01-25 20:15:25,493 io.py:  56: Saving data to file: ./checkpoints/rank0_train_res4_inds.npy\n",
            "INFO 2021-01-25 20:15:25,493 io.py:  70: Saved data to file: ./checkpoints/rank0_train_res4_inds.npy\n",
            "INFO 2021-01-25 20:15:25,493 extract_features.py:  73: Saving extracted features: res5 (10, 8192) to: ./checkpoints/rank0_train_res5_features.npy\n",
            "INFO 2021-01-25 20:15:25,493 io.py:  56: Saving data to file: ./checkpoints/rank0_train_res5_features.npy\n",
            "INFO 2021-01-25 20:15:25,494 io.py:  70: Saved data to file: ./checkpoints/rank0_train_res5_features.npy\n",
            "INFO 2021-01-25 20:15:25,494 extract_features.py:  79: Saving extracted targets: (10, 1) to: ./checkpoints/rank0_train_res5_targets.npy\n",
            "INFO 2021-01-25 20:15:25,494 io.py:  56: Saving data to file: ./checkpoints/rank0_train_res5_targets.npy\n",
            "INFO 2021-01-25 20:15:25,494 io.py:  70: Saved data to file: ./checkpoints/rank0_train_res5_targets.npy\n",
            "INFO 2021-01-25 20:15:25,494 extract_features.py:  85: Saving extracted indices: (10,) to: ./checkpoints/rank0_train_res5_inds.npy\n",
            "INFO 2021-01-25 20:15:25,495 io.py:  56: Saving data to file: ./checkpoints/rank0_train_res5_inds.npy\n",
            "INFO 2021-01-25 20:15:25,495 io.py:  70: Saved data to file: ./checkpoints/rank0_train_res5_inds.npy\n",
            "INFO 2021-01-25 20:15:25,495 extract_features.py:  73: Saving extracted features: res5avg (10, 2048) to: ./checkpoints/rank0_train_res5avg_features.npy\n",
            "INFO 2021-01-25 20:15:25,495 io.py:  56: Saving data to file: ./checkpoints/rank0_train_res5avg_features.npy\n",
            "INFO 2021-01-25 20:15:25,495 io.py:  70: Saved data to file: ./checkpoints/rank0_train_res5avg_features.npy\n",
            "INFO 2021-01-25 20:15:25,495 extract_features.py:  79: Saving extracted targets: (10, 1) to: ./checkpoints/rank0_train_res5avg_targets.npy\n",
            "INFO 2021-01-25 20:15:25,496 io.py:  56: Saving data to file: ./checkpoints/rank0_train_res5avg_targets.npy\n",
            "INFO 2021-01-25 20:15:25,496 io.py:  70: Saved data to file: ./checkpoints/rank0_train_res5avg_targets.npy\n",
            "INFO 2021-01-25 20:15:25,496 extract_features.py:  85: Saving extracted indices: (10,) to: ./checkpoints/rank0_train_res5avg_inds.npy\n",
            "INFO 2021-01-25 20:15:25,496 io.py:  56: Saving data to file: ./checkpoints/rank0_train_res5avg_inds.npy\n",
            "INFO 2021-01-25 20:15:25,496 io.py:  70: Saved data to file: ./checkpoints/rank0_train_res5avg_inds.npy\n",
            "INFO 2021-01-25 20:15:25,496 extract_features.py:  89: All Done!\n",
            "INFO 2021-01-25 20:15:25,496 logger.py:  66: Shutting down loggers...\n",
            "INFO 2021-01-25 20:15:25,497 run_distributed_engines.py: 133: All Done!\n",
            "INFO 2021-01-25 20:15:25,497 logger.py:  66: Shutting down loggers...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8fILq7VzyOu"
      },
      "source": [
        "And we are done!! We have the features for layers `conv1, res2, res3, res4, res5, res5avg` in `checkpoints/*.npy`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otUmgl4ms96M",
        "outputId": "79e7faa8-ca0a-43f5-b943-574478ae83f9"
      },
      "source": [
        "ls checkpoints/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rank0_test_conv1_features.npy    rank0_train_conv1_features.npy\n",
            "rank0_test_conv1_inds.npy        rank0_train_conv1_inds.npy\n",
            "rank0_test_conv1_targets.npy     rank0_train_conv1_targets.npy\n",
            "rank0_test_res2_features.npy     rank0_train_res2_features.npy\n",
            "rank0_test_res2_inds.npy         rank0_train_res2_inds.npy\n",
            "rank0_test_res2_targets.npy      rank0_train_res2_targets.npy\n",
            "rank0_test_res3_features.npy     rank0_train_res3_features.npy\n",
            "rank0_test_res3_inds.npy         rank0_train_res3_inds.npy\n",
            "rank0_test_res3_targets.npy      rank0_train_res3_targets.npy\n",
            "rank0_test_res4_features.npy     rank0_train_res4_features.npy\n",
            "rank0_test_res4_inds.npy         rank0_train_res4_inds.npy\n",
            "rank0_test_res4_targets.npy      rank0_train_res4_targets.npy\n",
            "rank0_test_res5avg_features.npy  rank0_train_res5avg_features.npy\n",
            "rank0_test_res5avg_inds.npy      rank0_train_res5avg_inds.npy\n",
            "rank0_test_res5avg_targets.npy   rank0_train_res5avg_targets.npy\n",
            "rank0_test_res5_features.npy     rank0_train_res5_features.npy\n",
            "rank0_test_res5_inds.npy         rank0_train_res5_inds.npy\n",
            "rank0_test_res5_targets.npy      rank0_train_res5_targets.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xFUcTj00B_a"
      },
      "source": [
        "# Loading Pre-trained models in VISSL\n",
        "\n",
        "VISSL supports Torchvision models out of the box. Generally, for loading any non-VISSL model, one needs to correctly set the following configuration options:\n",
        "\n",
        "```yaml\n",
        "WEIGHTS_INIT:\n",
        "  # path to the .torch weights files\n",
        "  PARAMS_FILE: \"\"\n",
        "  # name of the state dict. checkpoint = {\"classy_state_dict\": {layername:value}}. Options:\n",
        "  #   1. classy_state_dict - if model is trained and checkpointed with VISSL.\n",
        "  #      checkpoint = {\"classy_state_dict\": {layername:value}}\n",
        "  #   2. \"\" - if the model_file is not a nested dictionary for model weights i.e.\n",
        "  #      checkpoint = {layername:value}\n",
        "  #   3. key name that your model checkpoint uses for state_dict key name.\n",
        "  #      checkpoint = {\"your_key_name\": {layername:value}}\n",
        "  STATE_DICT_KEY_NAME: \"classy_state_dict\"\n",
        "  # specify what layer should not be loaded. Layer names with this key are not copied\n",
        "  # By default, set to BatchNorm stats \"num_batches_tracked\" to be skipped.\n",
        "  SKIP_LAYERS: [\"num_batches_tracked\"]\n",
        "  ####### If loading a non-VISSL trained model, set the following two args carefully #########\n",
        "  # to make the checkpoint compatible with VISSL, if you need to remove some names\n",
        "  # from the checkpoint keys, specify the name\n",
        "  REMOVE_PREFIX: \"\"\n",
        "  # In order to load the model (if not trained with VISSL) with VISSL, there are 2 scenarios:\n",
        "  #    1. If you are interested in evaluating the model features and freeze the trunk.\n",
        "  #       Set APPEND_PREFIX=\"trunk.base_model.\" This assumes that your model is compatible\n",
        "  #       with the VISSL trunks. The VISSL trunks start with \"_feature_blocks.\" prefix. If\n",
        "  #       your model doesn't have these prefix you can append them. For example:\n",
        "  #       For TorchVision ResNet trunk, set APPEND_PREFIX=\"trunk.base_model._feature_blocks.\"\n",
        "  #    2. where you want to load the model simply and finetune the full model.\n",
        "  #       Set APPEND_PREFIX=\"trunk.\"\n",
        "  #       This assumes that your model is compatible with the VISSL trunks. The VISSL\n",
        "  #       trunks start with \"_feature_blocks.\" prefix. If your model doesn't have these\n",
        "  #       prefix you can append them.\n",
        "  #       For TorchVision ResNet trunk, set APPEND_PREFIX=\"trunk._feature_blocks.\"\n",
        "  # NOTE: the prefix is appended to all the layers in the model\n",
        "  APPEND_PREFIX: \"\"\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc9YxGbNtFg6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}