VERBOSE: False
LOG_FREQUENCY: 10
TEST_ONLY: False
TEST_MODEL: False
SEED_VALUE: 0
MULTI_PROCESSING_METHOD: fork
MONITOR_PERF_STATS: False
DATA:
  TRAIN:
    DATA_SOURCES: [disk]
    DATASET_NAMES: [imagenet1k]
    DATA_PATHS: ['/private/home/mathilde/ssl_scaling/datasets/imagenet1k/train_images.npy']
    BATCHSIZE_PER_REPLICA: 64
    LABEL_TYPE: sample_index    # just an implementation detail. Label isn't used
    TRANSFORMS:
      - name: ImgPilToMultiResCrops
        nmb_duplicates: 10
        size_crops: [224]
        type_crops: [0]
        nmb_crops: [10]
        crop_scales: [[0.08, 1]]
        crop_size_typePIRL: 255
      - name: RandomHorizontalFlip
        p: 0.5
      - name: ImgPilColorDistortion
        strength: 1.0
      - name: ImgPilGaussianBlur
        kernel: 23
        p: 0.5
        radius_min: 0.1
        radius_max: 2.0
      - name: ImgToTensor
      - name: Normalize
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]
    COLLATE_FUNCTION: flatten_collator
    MMAP_MODE: True
    # COPY_TO_LOCAL_DISK: True
    COPY_TO_LOCAL_DISK: False
    COPY_DESTINATION_DIR: /tmp/imagenet1k/
    DATA_LIMIT: 50000
    DROP_LAST: True
TRAINER:
  TRAIN_STEP_NAME: standard
METERS: {}
MODEL:
  TRUNK:
    NAME: resnet50
  #TEMP_FROZEN_PARAMS_ITER_MAP: [['heads.0.prototypes0.weight', 80], ['heads.0.prototypes1.weight', 80], ['heads.0.prototypes2.weight', 80]]
  HEAD:
    PARAMS: [
    ["oto_head", {"dims": [2048, 2048, 128], "use_bn": True, "nmb_clusters": [3000, 3000, 3000]}],
    ]
  SYNC_BN_CONFIG:
    CONVERT_BN_TO_SYNC_BN: True
    SYNC_BN_TYPE: apex
    #SYNC_BN_TYPE: pytorch
  AMP_PARAMS:
    USE_AMP: True
    AMP_ARGS: {"opt_level": "O1"}
CRITERION:
    name: oto_loss
    MUL_TARGET_DATA_VALID: True
    SINKHORN_KNOPP_LOSS:
      NORMALIZE_LAST_LAYER: True
      USE_DOUBLE_PRECISION: False
      FILTER_INVALID_IMAGES: False
      TEMPERATURE: 0.1
      LAMBDA: 10
      MAX_ITERS: 3
      DUPLICATES_FOR_ASSIGN: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
      EPSILON: 0.000001
      QUEUE:
        QUEUE_LENGTH: 0
        #QUEUE_TYPE: 'scores'
        QUEUE_TYPE: 'embeddings'
        START_ITER: 0
OPTIMIZER:
    name: sgd
    use_larc: True
    larc_config:
      clip: False
      trust_coefficient: 0.001
      eps: 0.00000001
    weight_decay: 0.000001
    momentum: 0.9
    nesterov: False
    # num_epochs: 10
    num_epochs: 2
    regularize_bn: False
    regularize_bias: True
    # param_schedulers:
    #   lr:
    #     base_value: 4.8
    #     name: composite
    #     schedulers:
    #       - name: linear
    #         start_value: 0.6
    #         end_value: 4.8
    #       - name: cosine
    #         start_value: 4.8
    #         end_value: 0.0000
    #     update_interval: epoch
    #     interval_scaling: [rescaled, fixed]
    #     lengths: [0.1, 0.9]
    param_schedulers:
      lr:
        name: cosine
        start_value: 0.15   # LR for batch size 256
        end_value: 0.0000
        update_interval: step
DISTRIBUTED:
  DISTR_ON: True
  BACKEND: nccl
  NUM_NODES: 1
  NUM_PROC_PER_NODE: 8
  INIT_METHOD: env
MACHINE:
  NUM_DATALOADER_WORKERS: 5
  DEVICE: gpu
CHECKPOINT:
  DIR: "/checkpoint/mathilde/scratch"
  AUTO_RESUME: True
  CHECKPOINT_FREQUENCY: 5
