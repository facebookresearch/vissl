VERBOSE: False
LOG_FREQUENCY: 10
TEST_ONLY: False
TEST_MODEL: False
SEED_VALUE: 0
MULTI_PROCESSING_METHOD: forkserver
MONITOR_PERF_STATS: True
DATA:
  TRAIN:
    DATA_SOURCES: [disk]
    DATASET_NAMES: [imagenet1k]
    DATA_PATHS: ['/datasets01_101/imagenet_full_size/061417/train']
    BATCHSIZE_PER_REPLICA: 32
    LABEL_TYPE: sample_index    # just an implementation detail. Label isn't used
    TRANSFORMS:
      - name: ImgReplicatePil
        num_times: 2
      - name: RandomResizedCrop
        size: 224
      - name: RandomHorizontalFlip
        p: 0.5
      - name: ImgPilColorDistortion
        strength: 1.0
      - name: ImgPilGaussianBlur
        kernel: 23
        p: 0.5
        radius_min: 0.1
        radius_max: 2.0
      - name: ToTensor
      - name: Normalize
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]
    COLLATE_FUNCTION: flatten_collator
    MMAP_MODE: True
    COPY_TO_LOCAL_DISK: True
    # COPY_TO_LOCAL_DISK: False
    COPY_DESTINATION_DIR: /scratch/prigoyal/imagenet1k/
    # DATA_LIMIT: 50000
    DATA_LIMIT: 5000
    DROP_LAST: True
TRAINER:
  TRAIN_STEP_NAME: standard
METERS: {}
MODEL:
  TRUNK:
    NAME: resnet50
  HEAD:
    PARAMS: [
      ["mlp", {"dims": [2048, 2048], "use_relu": True}],
      ["mlp", {"dims": [2048, 128]}],
      # ["mlp", {"dims": [4096, 4096], "use_relu": True}],
      # ["mlp", {"dims": [4096, 128]}],
    ]
  #   PARAMS: [
  #     ["mlp", {"dims": [2048, 2048], "use_relu": True, "use_bn": True, "use_bias": False}],
  #     # ["mlp", {"dims": [2048, 128], "use_relu": False, "use_bn": True, "use_bias": False}],
  #     ["mlp", {"dims": [2048, 128], "use_relu": False, "use_bn": False, "use_bias": False}],
  #   ]
  # NON_TRAINABLE_PARAMS: ["heads.1.clf.1.bias"]
  SYNC_BN_CONFIG:
    CONVERT_BN_TO_SYNC_BN: True
    SYNC_BN_TYPE: apex
    # SYNC_BN_TYPE: pytorch
CRITERION:
    name: info_nce_loss
    MUL_TARGET_DATA_VALID: True
    INFO_NCE_LOSS:
      FILTER_INVALID_IMAGES: False
      TEMPERATURE: 0.1
      NUM_POSITIVES: 2
      BUFFER_PARAMS:
        EMBEDDING_DIM: 128
OPTIMIZER:
    name: sgd
    use_larc: True
    larc_config:
      clip: False
      trust_coefficient: 0.001
      eps: 0.00000001
    weight_decay: 0.000001
    momentum: 0.9
    nesterov: False
    # num_epochs: 10
    num_epochs: 2
    regularize_bn: False
    regularize_bias: True
    # param_schedulers:
    #   lr:
    #     base_value: 4.8
    #     name: composite
    #     schedulers:
    #       - name: linear
    #         start_value: 0.6
    #         end_value: 4.8
    #       - name: cosine
    #         start_value: 4.8
    #         end_value: 0.0000
    #     update_interval: epoch
    #     interval_scaling: [rescaled, fixed]
    #     lengths: [0.1, 0.9]
    param_schedulers:
      lr:
        name: cosine
        start_value: 0.15   # LR for batch size 256
        end_value: 0.0000
        update_interval: step
DISTRIBUTED:
  DISTR_ON: True
  BACKEND: nccl
  NUM_NODES: 1
  NUM_PROC_PER_NODE: 2
  INIT_METHOD: env
MACHINE:
  NUM_DATALOADER_WORKERS: 5
  DEVICE: gpu
CHECKPOINT:
  DIR: "."
  AUTO_RESUME: True
  CHECKPOINT_FREQUENCY: 5
